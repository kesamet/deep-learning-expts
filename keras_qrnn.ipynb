{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "keras_qrnn.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.8"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "avH46cmYnuIz"
      },
      "source": [
        "# Quasi-recurrent neural networks\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Qtz21akInthW",
        "outputId": "50c41436-c72c-4ad8-8ec9-c1dee81c4a50",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "import tensorflow as tf\n",
        "device_name = tf.test.gpu_device_name()\n",
        "if device_name != '/device:GPU:0':\n",
        "    raise SystemError('GPU device not found')\n",
        "print('Found GPU at: {}'.format(device_name))\n",
        "print('TensorFlow Version: {}'.format(tf.__version__))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found GPU at: /device:GPU:0\n",
            "TensorFlow Version: 2.2.0-rc3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "gtR26r8Z_itm",
        "outputId": "b018111c-6d8e-4619-c0b5-49c4d8d6d6da",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "from keras import activations, objectives\n",
        "from keras import backend as K\n",
        "from keras.datasets import imdb\n",
        "from keras.preprocessing import sequence\n",
        "from keras.models import Model\n",
        "from keras.layers import (\n",
        "    Input, Dense, Embedding, Lambda, Flatten, Reshape, Dropout,\n",
        "    LSTM, GRU, RepeatVector, Conv2D, Conv2DTranspose, MaxPooling2D,\n",
        "    UpSampling2D, Conv1D, concatenate)\n",
        "from keras.layers.advanced_activations import LeakyReLU\n",
        "from keras.optimizers import Adam\n",
        "from keras.callbacks import EarlyStopping, ModelCheckpoint"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
            "  import pandas.util.testing as tm\n",
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DyEAed3acf7Q",
        "colab_type": "text"
      },
      "source": [
        "## Load data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "sXVeD06CvREJ",
        "outputId": "765af2fd-318e-4b2f-a4f7-9b010a06f352",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "def get_imdb_data(maxlen=100, max_features=20000):\n",
        "    (X_train, y_train), (X_test, y_test) = imdb.load_data(num_words=max_features)\n",
        "    print(len(X_train), 'train sequences')\n",
        "    print(len(X_test), 'test sequences')\n",
        "    \n",
        "    print('... Padding sequences (samples x time)')\n",
        "    X_train = sequence.pad_sequences(X_train, maxlen=maxlen)\n",
        "    X_test = sequence.pad_sequences(X_test, maxlen=maxlen)\n",
        "    print('X_train shape:', X_train.shape)\n",
        "    print('X_test shape:', X_test.shape)\n",
        "    \n",
        "    return (X_train, y_train), (X_test, y_test)\n",
        "\n",
        "(X_train, y_train), (X_test, y_test) = get_imdb_data()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://s3.amazonaws.com/text-datasets/imdb.npz\n",
            "17465344/17464789 [==============================] - 1s 0us/step\n",
            "25000 train sequences\n",
            "25000 test sequences\n",
            "... Padding sequences (samples x time)\n",
            "X_train shape: (25000, 100)\n",
            "X_test shape: (25000, 100)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "2t23FJz66IwH"
      },
      "source": [
        "## QRNN layer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "qaLeDjHLJnLa",
        "colab": {}
      },
      "source": [
        "from keras import backend as K\n",
        "from keras import activations, initializers, regularizers, constraints\n",
        "from keras.layers import Layer, InputSpec\n",
        "from keras.utils.conv_utils import conv_output_length\n",
        "\n",
        "\n",
        "def _dropout(x, level, noise_shape=None, seed=None):\n",
        "    x = K.dropout(x, level, noise_shape, seed)\n",
        "    x *= (1. - level) # compensate for the scaling by the dropout\n",
        "    return x\n",
        "\n",
        "\n",
        "class QRNN(Layer):\n",
        "    '''Quasi RNN\n",
        "    # Arguments\n",
        "        units: dimension of the internal projections and the final output.\n",
        "    # References\n",
        "        - [Quasi-recurrent Neural Networks](http://arxiv.org/abs/1611.01576)\n",
        "    '''\n",
        "    def __init__(self, units, window_size=2, stride=1,\n",
        "                 return_sequences=False, go_backwards=False, \n",
        "                 stateful=False, unroll=False, activation='tanh',\n",
        "                 kernel_initializer='uniform', bias_initializer='zero',\n",
        "                 kernel_regularizer=None, bias_regularizer=None,\n",
        "                 activity_regularizer=None,\n",
        "                 kernel_constraint=None, bias_constraint=None, \n",
        "                 dropout=0, use_bias=True, input_dim=None, input_length=None,\n",
        "                 **kwargs):\n",
        "        self.return_sequences = return_sequences\n",
        "        self.go_backwards = go_backwards\n",
        "        self.stateful = stateful\n",
        "        self.unroll = unroll\n",
        "\n",
        "        self.units = units \n",
        "        self.window_size = window_size\n",
        "        self.strides = (stride, 1)\n",
        "\n",
        "        self.use_bias = use_bias\n",
        "        self.activation = activations.get(activation)\n",
        "        self.kernel_initializer = initializers.get(kernel_initializer)\n",
        "        self.bias_initializer = initializers.get(bias_initializer)\n",
        "        self.kernel_regularizer = regularizers.get(kernel_regularizer)\n",
        "        self.bias_regularizer = regularizers.get(bias_regularizer)\n",
        "        self.activity_regularizer = regularizers.get(activity_regularizer)\n",
        "        self.kernel_constraint = constraints.get(kernel_constraint)\n",
        "        self.bias_constraint = constraints.get(bias_constraint)\n",
        "\n",
        "        self.dropout = dropout\n",
        "        self.supports_masking = True\n",
        "        self.input_spec = [InputSpec(ndim=3)]\n",
        "        self.input_dim = input_dim\n",
        "        self.input_length = input_length\n",
        "        if self.input_dim:\n",
        "            kwargs['input_shape'] = (self.input_length, self.input_dim)\n",
        "        super(QRNN, self).__init__(**kwargs)\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        if isinstance(input_shape, list):\n",
        "            input_shape = input_shape[0]\n",
        "\n",
        "        batch_size = input_shape[0] if self.stateful else None\n",
        "        self.input_dim = input_shape[2]\n",
        "        self.input_spec = InputSpec(shape=(batch_size, None, self.input_dim))\n",
        "        self.state_spec = InputSpec(shape=(batch_size, self.units))\n",
        "\n",
        "        self.states = [None]\n",
        "        if self.stateful:\n",
        "            self.reset_states()\n",
        "\n",
        "        kernel_shape = (self.window_size, 1, self.input_dim, self.units * 3)\n",
        "        self.kernel = self.add_weight(name='kernel',\n",
        "                                      shape=kernel_shape,\n",
        "                                      initializer=self.kernel_initializer,\n",
        "                                      regularizer=self.kernel_regularizer,\n",
        "                                      constraint=self.kernel_constraint)\n",
        "        if self.use_bias:\n",
        "            self.bias = self.add_weight(name='bias', \n",
        "                                        shape=(self.units * 3,),\n",
        "                                        initializer=self.bias_initializer,\n",
        "                                        regularizer=self.bias_regularizer,\n",
        "                                        constraint=self.bias_constraint)\n",
        "\n",
        "        self.built = True\n",
        "\n",
        "    def compute_output_shape(self, input_shape):\n",
        "        if isinstance(input_shape, list):\n",
        "            input_shape = input_shape[0]\n",
        "\n",
        "        length = input_shape[1]\n",
        "        if length:\n",
        "            length = conv_output_length(length + self.window_size - 1,\n",
        "                                        self.window_size, 'valid',\n",
        "                                        self.strides[0])\n",
        "        if self.return_sequences:\n",
        "            return (input_shape[0], length, self.units)\n",
        "        else:\n",
        "            return (input_shape[0], self.units)\n",
        "\n",
        "    def compute_mask(self, inputs, mask):\n",
        "        if self.return_sequences:\n",
        "            return mask\n",
        "        else:\n",
        "            return None\n",
        "\n",
        "    def get_initial_states(self, inputs):\n",
        "        # build an all-zero tensor of shape (samples, units)\n",
        "        initial_state = K.zeros_like(inputs)  # (samples, timesteps, input_dim)\n",
        "        initial_state = K.sum(initial_state, axis=(1, 2))  # (samples,)\n",
        "        initial_state = K.expand_dims(initial_state)  # (samples, 1)\n",
        "        initial_state = K.tile(initial_state, [1, self.units])  # (samples, units)\n",
        "        initial_states = [initial_state for _ in range(len(self.states))]\n",
        "        return initial_states\n",
        "\n",
        "    def reset_states(self, states=None):\n",
        "        if not self.stateful:\n",
        "            raise AttributeError('Layer must be stateful.')\n",
        "        if not self.input_spec:\n",
        "            raise RuntimeError('Layer has never been called '\n",
        "                               'and thus has no states.')\n",
        "\n",
        "        batch_size = self.input_spec.shape[0]\n",
        "        if not batch_size:\n",
        "            raise ValueError('If a QRNN is stateful, it needs to know '\n",
        "                             'its batch size. Specify the batch size '\n",
        "                             'of your input tensors: \\n'\n",
        "                             '- If using a Sequential model, '\n",
        "                             'specify the batch size by passing '\n",
        "                             'a `batch_input_shape` '\n",
        "                             'argument to your first layer.\\n'\n",
        "                             '- If using the functional API, specify '\n",
        "                             'the time dimension by passing a '\n",
        "                             '`batch_shape` argument to your Input layer.')\n",
        "\n",
        "        if self.states[0] is None:\n",
        "            self.states = [K.zeros((batch_size, self.units))\n",
        "                           for _ in self.states]\n",
        "        elif states is None:\n",
        "            for state in self.states:\n",
        "                K.set_value(state, np.zeros((batch_size, self.units)))\n",
        "        else:\n",
        "            if not isinstance(states, (list, tuple)):\n",
        "                states = [states]\n",
        "            if len(states) != len(self.states):\n",
        "                raise ValueError('Layer ' + self.name + ' expects ' +\n",
        "                                 str(len(self.states)) + ' states, '\n",
        "                                 'but it received ' + str(len(states)) +\n",
        "                                 'state values. Input received: ' +\n",
        "                                 str(states))\n",
        "            for index, (value, state) in enumerate(zip(states, self.states)):\n",
        "                if value.shape != (batch_size, self.units):\n",
        "                    raise ValueError('State ' + str(index) +\n",
        "                                     ' is incompatible with layer ' +\n",
        "                                     self.name + ': expected shape=' +\n",
        "                                     str((batch_size, self.units)) +\n",
        "                                     ', found shape=' + str(value.shape))\n",
        "                K.set_value(state, value)\n",
        "\n",
        "    def __call__(self, inputs, initial_state=None, **kwargs):\n",
        "        # If `initial_state` is specified,\n",
        "        # and if it a Keras tensor,\n",
        "        # then add it to the inputs and temporarily\n",
        "        # modify the input spec to include the state.\n",
        "        if initial_state is not None:\n",
        "            if hasattr(initial_state, '_keras_history'):\n",
        "                # Compute the full input spec, including state\n",
        "                input_spec = self.input_spec\n",
        "                state_spec = self.state_spec\n",
        "                if not isinstance(state_spec, list):\n",
        "                    state_spec = [state_spec]\n",
        "                self.input_spec = [input_spec] + state_spec\n",
        "\n",
        "                # Compute the full inputs, including state\n",
        "                if not isinstance(initial_state, (list, tuple)):\n",
        "                    initial_state = [initial_state]\n",
        "                inputs = [inputs] + list(initial_state)\n",
        "\n",
        "                # Perform the call\n",
        "                output = super(QRNN, self).__call__(inputs, **kwargs)\n",
        "\n",
        "                # Restore original input spec\n",
        "                self.input_spec = input_spec\n",
        "                return output\n",
        "            else:\n",
        "                kwargs['initial_state'] = initial_state\n",
        "        return super(QRNN, self).__call__(inputs, **kwargs)\n",
        "\n",
        "    def call(self, inputs, mask=None, initial_state=None, training=None):\n",
        "        # input shape: `(samples, time (padded with zeros), input_dim)`\n",
        "        # note that the .build() method of subclasses MUST define\n",
        "        # self.input_spec and self.state_spec with complete input shapes.\n",
        "        if isinstance(inputs, list):\n",
        "            initial_states = inputs[1:]\n",
        "            inputs = inputs[0]\n",
        "        elif initial_state is not None:\n",
        "            pass\n",
        "        elif self.stateful:\n",
        "            initial_states = self.states\n",
        "        else:\n",
        "            initial_states = self.get_initial_states(inputs)\n",
        "\n",
        "        if len(initial_states) != len(self.states):\n",
        "            raise ValueError('Layer has ' + str(len(self.states)) +\n",
        "                             ' states but was passed ' +\n",
        "                             str(len(initial_states)) +\n",
        "                             ' initial states.')\n",
        "        input_shape = K.int_shape(inputs)\n",
        "        if self.unroll and input_shape[1] is None:\n",
        "            raise ValueError('Cannot unroll a RNN if the '\n",
        "                             'time dimension is undefined. \\n'\n",
        "                             '- If using a Sequential model, '\n",
        "                             'specify the time dimension by passing '\n",
        "                             'an `input_shape` or `batch_input_shape` '\n",
        "                             'argument to your first layer. If your '\n",
        "                             'first layer is an Embedding, you can '\n",
        "                             'also use the `input_length` argument.\\n'\n",
        "                             '- If using the functional API, specify '\n",
        "                             'the time dimension by passing a `shape` '\n",
        "                             'or `batch_shape` argument to your Input layer.')\n",
        "        constants = self.get_constants(inputs, training=None)\n",
        "        preprocessed_input = self.preprocess_input(inputs, training=None)\n",
        "\n",
        "        last_output, outputs, states = K.rnn(self.step, preprocessed_input,\n",
        "                                            initial_states,\n",
        "                                            go_backwards=self.go_backwards,\n",
        "                                            mask=mask,\n",
        "                                            constants=constants,\n",
        "                                            unroll=self.unroll,\n",
        "                                            input_length=input_shape[1])\n",
        "        if self.stateful:\n",
        "            updates = []\n",
        "            for i in range(len(states)):\n",
        "                updates.append((self.states[i], states[i]))\n",
        "            self.add_update(updates, inputs)\n",
        "\n",
        "        # Properly set learning phase\n",
        "        if 0 < self.dropout < 1:\n",
        "            last_output._uses_learning_phase = True\n",
        "            outputs._uses_learning_phase = True\n",
        "\n",
        "        if self.return_sequences:\n",
        "            return outputs\n",
        "        else:\n",
        "            return last_output\n",
        "\n",
        "    def preprocess_input(self, inputs, training=None):\n",
        "        if self.window_size > 1:\n",
        "            inputs = K.temporal_padding(inputs, (self.window_size-1, 0))\n",
        "        inputs = K.expand_dims(inputs, 2)  # add a dummy dimension\n",
        "\n",
        "        output = K.conv2d(inputs, self.kernel, strides=self.strides,\n",
        "                          padding='valid',\n",
        "                          data_format='channels_last')\n",
        "        output = K.squeeze(output, 2)  # remove the dummy dimension\n",
        "        if self.use_bias:\n",
        "            output = K.bias_add(output, self.bias, data_format='channels_last')\n",
        "\n",
        "        if self.dropout is not None and 0. < self.dropout < 1.:\n",
        "            z = output[:, :, :self.units]\n",
        "            f = output[:, :, self.units:2 * self.units]\n",
        "            o = output[:, :, 2 * self.units:]\n",
        "            f = K.in_train_phase(1 - _dropout(1 - f, self.dropout), f, training=training)\n",
        "            return K.concatenate([z, f, o], -1)\n",
        "        else:\n",
        "            return output\n",
        "\n",
        "    def step(self, inputs, states):\n",
        "        prev_output = states[0]\n",
        "\n",
        "        z = inputs[:, :self.units]\n",
        "        f = inputs[:, self.units:2 * self.units]\n",
        "        o = inputs[:, 2 * self.units:]\n",
        "\n",
        "        z = self.activation(z)\n",
        "        f = f if self.dropout is not None and 0. < self.dropout < 1. else K.sigmoid(f)\n",
        "        o = K.sigmoid(o)\n",
        "\n",
        "        output = f * prev_output + (1 - f) * z\n",
        "        output = o * output\n",
        "\n",
        "        return output, [output]\n",
        "\n",
        "    def get_constants(self, inputs, training=None):\n",
        "        return []\n",
        " \n",
        "    def get_config(self):\n",
        "        config = {'units': self.units,\n",
        "                  'window_size': self.window_size,\n",
        "                  'stride': self.strides[0],\n",
        "                  'return_sequences': self.return_sequences,\n",
        "                  'go_backwards': self.go_backwards,\n",
        "                  'stateful': self.stateful,\n",
        "                  'unroll': self.unroll,\n",
        "                  'use_bias': self.use_bias,\n",
        "                  'dropout': self.dropout,\n",
        "                  'activation': activations.serialize(self.activation),\n",
        "                  'kernel_initializer': initializers.serialize(self.kernel_initializer),\n",
        "                  'bias_initializer': initializers.serialize(self.bias_initializer),\n",
        "                  'kernel_regularizer': regularizers.serialize(self.kernel_regularizer),\n",
        "                  'bias_regularizer': regularizers.serialize(self.bias_regularizer),\n",
        "                  'activity_regularizer': regularizers.serialize(self.activity_regularizer),\n",
        "                  'kernel_constraint': constraints.serialize(self.kernel_constraint),\n",
        "                  'bias_constraint': constraints.serialize(self.bias_constraint),\n",
        "                  'input_dim': self.input_dim,\n",
        "                  'input_length': self.input_length}\n",
        "        base_config = super(QRNN, self).get_config()\n",
        "        return dict(list(base_config.items()) + list(config.items()))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "HYw4EFQD5REW",
        "outputId": "cec31ca2-47f9-4597-8ee2-cdcba9baa34b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 527
        }
      },
      "source": [
        "def build_model(input_length=100, max_features=20000, embed_size=300):\n",
        "    inputs = Input(shape=(input_length, ))\n",
        "    x = Embedding(max_features, embed_size, trainable=False)(inputs)\n",
        "    x = Dropout(0.3)(x)\n",
        "    for _ in range(3):\n",
        "        x = QRNN(256, window_size=3, dropout=0, return_sequences=True)(x)\n",
        "        x = Dropout(0.3)(x)\n",
        "        \n",
        "    x = QRNN(256, window_size=3, dropout=0, return_sequences=False)(x)\n",
        "    outputs = Dense(1, activation='sigmoid')(x)\n",
        "    model = Model(inputs, outputs)\n",
        "    \n",
        "    model.compile(loss='binary_crossentropy',\n",
        "                  optimizer='adam',\n",
        "                  metrics=['accuracy'])\n",
        "    print(model.summary())\n",
        "    return model\n",
        "\n",
        "model = build_model()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         (None, 100)               0         \n",
            "_________________________________________________________________\n",
            "embedding_1 (Embedding)      (None, 100, 300)          6000000   \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 100, 300)          0         \n",
            "_________________________________________________________________\n",
            "qrnn_1 (QRNN)                (None, 100, 256)          691968    \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 100, 256)          0         \n",
            "_________________________________________________________________\n",
            "qrnn_2 (QRNN)                (None, 100, 256)          590592    \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 100, 256)          0         \n",
            "_________________________________________________________________\n",
            "qrnn_3 (QRNN)                (None, 100, 256)          590592    \n",
            "_________________________________________________________________\n",
            "dropout_4 (Dropout)          (None, 100, 256)          0         \n",
            "_________________________________________________________________\n",
            "qrnn_4 (QRNN)                (None, 256)               590592    \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 1)                 257       \n",
            "=================================================================\n",
            "Total params: 8,464,001\n",
            "Trainable params: 2,464,001\n",
            "Non-trainable params: 6,000,000\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "0xdCwe-b5Q9x",
        "outputId": "184ca60f-271e-44ab-b9c3-9bf59166c174",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1411
        }
      },
      "source": [
        "epochs = 20\n",
        "batch_size = 1024\n",
        "\n",
        "file_path = 'weights.h5'\n",
        "checkpoint = ModelCheckpoint(file_path, monitor='val_loss', verbose=1,\n",
        "                             save_best_only=True, mode='min')\n",
        "early = EarlyStopping(monitor='val_loss', mode='min', patience=5)\n",
        "\n",
        "model.fit(X_train, y_train,\n",
        "          shuffle=True,\n",
        "          batch_size=batch_size, \n",
        "          epochs=epochs,\n",
        "          validation_data=(X_test, y_test),\n",
        "          callbacks=[checkpoint, early])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 25000 samples, validate on 25000 samples\n",
            "Epoch 1/20\n",
            "25000/25000 [==============================] - 50s 2ms/step - loss: 0.6929 - acc: 0.5114 - val_loss: 0.6897 - val_acc: 0.5620\n",
            "\n",
            "Epoch 00001: val_loss improved from inf to 0.68971, saving model to weights.h5\n",
            "Epoch 2/20\n",
            "25000/25000 [==============================] - 46s 2ms/step - loss: 0.6725 - acc: 0.5800 - val_loss: 0.6577 - val_acc: 0.6027\n",
            "\n",
            "Epoch 00002: val_loss improved from 0.68971 to 0.65767, saving model to weights.h5\n",
            "Epoch 3/20\n",
            "25000/25000 [==============================] - 46s 2ms/step - loss: 0.6539 - acc: 0.6097 - val_loss: 0.6389 - val_acc: 0.6334\n",
            "\n",
            "Epoch 00003: val_loss improved from 0.65767 to 0.63891, saving model to weights.h5\n",
            "Epoch 4/20\n",
            "25000/25000 [==============================] - 46s 2ms/step - loss: 0.6398 - acc: 0.6274 - val_loss: 0.6361 - val_acc: 0.6313\n",
            "\n",
            "Epoch 00004: val_loss improved from 0.63891 to 0.63614, saving model to weights.h5\n",
            "Epoch 5/20\n",
            "25000/25000 [==============================] - 46s 2ms/step - loss: 0.6298 - acc: 0.6353 - val_loss: 0.6261 - val_acc: 0.6397\n",
            "\n",
            "Epoch 00005: val_loss improved from 0.63614 to 0.62608, saving model to weights.h5\n",
            "Epoch 6/20\n",
            "25000/25000 [==============================] - 46s 2ms/step - loss: 0.6214 - acc: 0.6446 - val_loss: 0.6234 - val_acc: 0.6456\n",
            "\n",
            "Epoch 00006: val_loss improved from 0.62608 to 0.62337, saving model to weights.h5\n",
            "Epoch 7/20\n",
            "25000/25000 [==============================] - 46s 2ms/step - loss: 0.6183 - acc: 0.6476 - val_loss: 0.6219 - val_acc: 0.6421\n",
            "\n",
            "Epoch 00007: val_loss improved from 0.62337 to 0.62185, saving model to weights.h5\n",
            "Epoch 8/20\n",
            "25000/25000 [==============================] - 46s 2ms/step - loss: 0.6162 - acc: 0.6495 - val_loss: 0.6185 - val_acc: 0.6456\n",
            "\n",
            "Epoch 00008: val_loss improved from 0.62185 to 0.61852, saving model to weights.h5\n",
            "Epoch 9/20\n",
            "25000/25000 [==============================] - 46s 2ms/step - loss: 0.6087 - acc: 0.6559 - val_loss: 0.6166 - val_acc: 0.6448\n",
            "\n",
            "Epoch 00009: val_loss improved from 0.61852 to 0.61658, saving model to weights.h5\n",
            "Epoch 10/20\n",
            "25000/25000 [==============================] - 46s 2ms/step - loss: 0.6032 - acc: 0.6579 - val_loss: 0.6126 - val_acc: 0.6458\n",
            "\n",
            "Epoch 00010: val_loss improved from 0.61658 to 0.61259, saving model to weights.h5\n",
            "Epoch 11/20\n",
            "25000/25000 [==============================] - 46s 2ms/step - loss: 0.5941 - acc: 0.6644 - val_loss: 0.6057 - val_acc: 0.6498\n",
            "\n",
            "Epoch 00011: val_loss improved from 0.61259 to 0.60568, saving model to weights.h5\n",
            "Epoch 12/20\n",
            "25000/25000 [==============================] - 46s 2ms/step - loss: 0.5902 - acc: 0.6683 - val_loss: 0.6062 - val_acc: 0.6488\n",
            "\n",
            "Epoch 00012: val_loss did not improve from 0.60568\n",
            "Epoch 13/20\n",
            "25000/25000 [==============================] - 47s 2ms/step - loss: 0.5838 - acc: 0.6753 - val_loss: 0.6006 - val_acc: 0.6535\n",
            "\n",
            "Epoch 00013: val_loss improved from 0.60568 to 0.60059, saving model to weights.h5\n",
            "Epoch 14/20\n",
            "25000/25000 [==============================] - 47s 2ms/step - loss: 0.5799 - acc: 0.6788 - val_loss: 0.5992 - val_acc: 0.6518\n",
            "\n",
            "Epoch 00014: val_loss improved from 0.60059 to 0.59924, saving model to weights.h5\n",
            "Epoch 15/20\n",
            "25000/25000 [==============================] - 47s 2ms/step - loss: 0.5747 - acc: 0.6801 - val_loss: 0.5995 - val_acc: 0.6489\n",
            "\n",
            "Epoch 00015: val_loss did not improve from 0.59924\n",
            "Epoch 16/20\n",
            "25000/25000 [==============================] - 47s 2ms/step - loss: 0.5705 - acc: 0.6820 - val_loss: 0.5947 - val_acc: 0.6534\n",
            "\n",
            "Epoch 00016: val_loss improved from 0.59924 to 0.59472, saving model to weights.h5\n",
            "Epoch 17/20\n",
            "25000/25000 [==============================] - 47s 2ms/step - loss: 0.5662 - acc: 0.6860 - val_loss: 0.5942 - val_acc: 0.6530\n",
            "\n",
            "Epoch 00017: val_loss improved from 0.59472 to 0.59418, saving model to weights.h5\n",
            "Epoch 18/20\n",
            "25000/25000 [==============================] - 47s 2ms/step - loss: 0.5589 - acc: 0.6935 - val_loss: 0.5893 - val_acc: 0.6593\n",
            "\n",
            "Epoch 00018: val_loss improved from 0.59418 to 0.58930, saving model to weights.h5\n",
            "Epoch 19/20\n",
            "25000/25000 [==============================] - 47s 2ms/step - loss: 0.5572 - acc: 0.6944 - val_loss: 0.5891 - val_acc: 0.6566\n",
            "\n",
            "Epoch 00019: val_loss improved from 0.58930 to 0.58906, saving model to weights.h5\n",
            "Epoch 20/20\n",
            "25000/25000 [==============================] - 47s 2ms/step - loss: 0.5574 - acc: 0.6963 - val_loss: 0.5884 - val_acc: 0.6551\n",
            "\n",
            "Epoch 00020: val_loss improved from 0.58906 to 0.58844, saving model to weights.h5\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f212fa62ef0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "dliF_Yvq5c4T"
      },
      "source": [
        "## Comparison with other methods"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "BDHqd2i9mjqx",
        "outputId": "8c432db9-5fd4-46f1-c525-ac1eccebed52",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 544
        }
      },
      "source": [
        "def build_model(input_length=100, max_features=20000, embed_size=300):\n",
        "    inputs = Input(shape=(input_length, ))\n",
        "    x = Embedding(max_features, embed_size, trainable=False)(inputs)\n",
        "    x = Dropout(0.3)(x)\n",
        "    for _ in range(3):\n",
        "        x = GRU(256, return_sequences=True)(x)\n",
        "        x = Dropout(0.3)(x)\n",
        "        \n",
        "    x = GRU(256)(x)\n",
        "    outputs = Dense(1, activation='sigmoid')(x)\n",
        "    model = Model(inputs, outputs)\n",
        "    \n",
        "    model.compile(loss='binary_crossentropy',\n",
        "                  optimizer='adam',\n",
        "                  metrics=['accuracy'])\n",
        "    print(model.summary())\n",
        "    return model\n",
        "\n",
        "model = build_model()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_4\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_4 (InputLayer)         (None, 100)               0         \n",
            "_________________________________________________________________\n",
            "embedding_4 (Embedding)      (None, 100, 300)          6000000   \n",
            "_________________________________________________________________\n",
            "dropout_10 (Dropout)         (None, 100, 300)          0         \n",
            "_________________________________________________________________\n",
            "gru_1 (GRU)                  (None, 100, 256)          427776    \n",
            "_________________________________________________________________\n",
            "dropout_11 (Dropout)         (None, 100, 256)          0         \n",
            "_________________________________________________________________\n",
            "gru_2 (GRU)                  (None, 100, 256)          393984    \n",
            "_________________________________________________________________\n",
            "dropout_12 (Dropout)         (None, 100, 256)          0         \n",
            "_________________________________________________________________\n",
            "gru_3 (GRU)                  (None, 100, 256)          393984    \n",
            "_________________________________________________________________\n",
            "dropout_13 (Dropout)         (None, 100, 256)          0         \n",
            "_________________________________________________________________\n",
            "gru_4 (GRU)                  (None, 256)               393984    \n",
            "_________________________________________________________________\n",
            "dense_7 (Dense)              (None, 1)                 257       \n",
            "=================================================================\n",
            "Total params: 7,609,985\n",
            "Trainable params: 1,609,985\n",
            "Non-trainable params: 6,000,000\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "OMCmaA7BmDif",
        "outputId": "8347675c-53f4-4e06-fd19-84ce4898770d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 731
        }
      },
      "source": [
        "epochs = 10\n",
        "batch_size = 1024\n",
        "\n",
        "file_path = 'weights.h5'\n",
        "checkpoint = ModelCheckpoint(file_path, monitor='val_loss', verbose=1,\n",
        "                             save_best_only=True, mode='min')\n",
        "early = EarlyStopping(monitor='val_loss', mode='min', patience=5)\n",
        "\n",
        "model.fit(X_train,\n",
        "          y_train,\n",
        "          shuffle=True,\n",
        "          batch_size=batch_size, \n",
        "          epochs=epochs,\n",
        "          validation_data=(X_test, y_test),\n",
        "          callbacks=[checkpoint, early])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 25000 samples, validate on 25000 samples\n",
            "Epoch 1/10\n",
            "25000/25000 [==============================] - 51s 2ms/step - loss: 0.6731 - acc: 0.5750 - val_loss: 0.6435 - val_acc: 0.6329\n",
            "\n",
            "Epoch 00001: val_loss improved from inf to 0.64348, saving model to weights.h5\n",
            "Epoch 2/10\n",
            "25000/25000 [==============================] - 47s 2ms/step - loss: 0.6307 - acc: 0.6450 - val_loss: 0.5913 - val_acc: 0.6903\n",
            "\n",
            "Epoch 00002: val_loss improved from 0.64348 to 0.59132, saving model to weights.h5\n",
            "Epoch 3/10\n",
            "25000/25000 [==============================] - 47s 2ms/step - loss: 0.6019 - acc: 0.6746 - val_loss: 0.6378 - val_acc: 0.6184\n",
            "\n",
            "Epoch 00003: val_loss did not improve from 0.59132\n",
            "Epoch 4/10\n",
            "25000/25000 [==============================] - 47s 2ms/step - loss: 0.6105 - acc: 0.6654 - val_loss: 0.5929 - val_acc: 0.6975\n",
            "\n",
            "Epoch 00004: val_loss did not improve from 0.59132\n",
            "Epoch 5/10\n",
            "25000/25000 [==============================] - 47s 2ms/step - loss: 0.5889 - acc: 0.6831 - val_loss: 0.5671 - val_acc: 0.7028\n",
            "\n",
            "Epoch 00005: val_loss improved from 0.59132 to 0.56709, saving model to weights.h5\n",
            "Epoch 6/10\n",
            "25000/25000 [==============================] - 47s 2ms/step - loss: 0.5742 - acc: 0.6962 - val_loss: 0.5438 - val_acc: 0.7200\n",
            "\n",
            "Epoch 00006: val_loss improved from 0.56709 to 0.54380, saving model to weights.h5\n",
            "Epoch 7/10\n",
            "25000/25000 [==============================] - 47s 2ms/step - loss: 0.5619 - acc: 0.7063 - val_loss: 0.5453 - val_acc: 0.7212\n",
            "\n",
            "Epoch 00007: val_loss did not improve from 0.54380\n",
            "Epoch 8/10\n",
            "25000/25000 [==============================] - 47s 2ms/step - loss: 0.5570 - acc: 0.7125 - val_loss: 0.5358 - val_acc: 0.7280\n",
            "\n",
            "Epoch 00008: val_loss improved from 0.54380 to 0.53584, saving model to weights.h5\n",
            "Epoch 9/10\n",
            "25000/25000 [==============================] - 47s 2ms/step - loss: 0.5522 - acc: 0.7149 - val_loss: 0.5330 - val_acc: 0.7353\n",
            "\n",
            "Epoch 00009: val_loss improved from 0.53584 to 0.53300, saving model to weights.h5\n",
            "Epoch 10/10\n",
            "25000/25000 [==============================] - 47s 2ms/step - loss: 0.5521 - acc: 0.7176 - val_loss: 0.5291 - val_acc: 0.7339\n",
            "\n",
            "Epoch 00010: val_loss improved from 0.53300 to 0.52912, saving model to weights.h5\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f211f36b908>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "DoxD6L-vqmcF",
        "outputId": "a4e1afe7-a3ed-443a-fc20-f242216ebc1c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 527
        }
      },
      "source": [
        "def build_model(input_length=100, max_features=20000, embed_size=300):\n",
        "    inputs = Input(shape=(input_length, ))\n",
        "    x = Embedding(max_features, embed_size, trainable=False)(inputs)\n",
        "    x = Dropout(0.3)(x)\n",
        "    for _ in range(3):\n",
        "        x = LSTM(256, return_sequences=True)(x)\n",
        "        x = Dropout(0.3)(x)\n",
        "        \n",
        "    x = LSTM(256)(x)\n",
        "    outputs = Dense(1, activation='sigmoid')(x)\n",
        "    model = Model(inputs, outputs)\n",
        "    \n",
        "    model.compile(loss='binary_crossentropy',\n",
        "                  optimizer='adam',\n",
        "                  metrics=['accuracy'])\n",
        "    print(model.summary())\n",
        "    return model\n",
        "\n",
        "model = build_model()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_7 (InputLayer)         (None, 100)               0         \n",
            "_________________________________________________________________\n",
            "embedding_7 (Embedding)      (None, 100, 300)          6000000   \n",
            "_________________________________________________________________\n",
            "dropout_19 (Dropout)         (None, 100, 300)          0         \n",
            "_________________________________________________________________\n",
            "lstm_1 (LSTM)                (None, 100, 256)          570368    \n",
            "_________________________________________________________________\n",
            "dropout_20 (Dropout)         (None, 100, 256)          0         \n",
            "_________________________________________________________________\n",
            "lstm_2 (LSTM)                (None, 100, 256)          525312    \n",
            "_________________________________________________________________\n",
            "dropout_21 (Dropout)         (None, 100, 256)          0         \n",
            "_________________________________________________________________\n",
            "lstm_3 (LSTM)                (None, 100, 256)          525312    \n",
            "_________________________________________________________________\n",
            "dropout_22 (Dropout)         (None, 100, 256)          0         \n",
            "_________________________________________________________________\n",
            "lstm_4 (LSTM)                (None, 256)               525312    \n",
            "_________________________________________________________________\n",
            "dense_9 (Dense)              (None, 1)                 257       \n",
            "=================================================================\n",
            "Total params: 8,146,561\n",
            "Trainable params: 2,146,561\n",
            "Non-trainable params: 6,000,000\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "XEvO9-AlmjiQ",
        "outputId": "4aac1a6e-fde3-46de-98b6-e4ab2e94bea5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 731
        }
      },
      "source": [
        "epochs = 10\n",
        "batch_size = 1024\n",
        "\n",
        "file_path = 'weights.h5'\n",
        "checkpoint = ModelCheckpoint(file_path, monitor='val_loss', verbose=1,\n",
        "                             save_best_only=True, mode='min')\n",
        "early = EarlyStopping(monitor='val_loss', mode='min', patience=5)\n",
        "\n",
        "model.fit(X_train, y_train,\n",
        "          shuffle=True,\n",
        "          batch_size=batch_size, \n",
        "          epochs=epochs,\n",
        "          validation_data=(X_test, y_test),\n",
        "          callbacks=[checkpoint, early])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 25000 samples, validate on 25000 samples\n",
            "Epoch 1/10\n",
            "25000/25000 [==============================] - 65s 3ms/step - loss: 0.6819 - acc: 0.5472 - val_loss: 0.6620 - val_acc: 0.6026\n",
            "\n",
            "Epoch 00001: val_loss improved from inf to 0.66197, saving model to weights.h5\n",
            "Epoch 2/10\n",
            "25000/25000 [==============================] - 60s 2ms/step - loss: 0.6554 - acc: 0.6170 - val_loss: 0.6502 - val_acc: 0.6069\n",
            "\n",
            "Epoch 00002: val_loss improved from 0.66197 to 0.65025, saving model to weights.h5\n",
            "Epoch 3/10\n",
            "25000/25000 [==============================] - 60s 2ms/step - loss: 0.6401 - acc: 0.6381 - val_loss: 0.6238 - val_acc: 0.6894\n",
            "\n",
            "Epoch 00003: val_loss improved from 0.65025 to 0.62376, saving model to weights.h5\n",
            "Epoch 4/10\n",
            "25000/25000 [==============================] - 60s 2ms/step - loss: 0.6089 - acc: 0.6712 - val_loss: 0.5943 - val_acc: 0.6736\n",
            "\n",
            "Epoch 00004: val_loss improved from 0.62376 to 0.59432, saving model to weights.h5\n",
            "Epoch 5/10\n",
            "25000/25000 [==============================] - 60s 2ms/step - loss: 0.5961 - acc: 0.6864 - val_loss: 0.5668 - val_acc: 0.7062\n",
            "\n",
            "Epoch 00005: val_loss improved from 0.59432 to 0.56676, saving model to weights.h5\n",
            "Epoch 6/10\n",
            "25000/25000 [==============================] - 60s 2ms/step - loss: 0.5784 - acc: 0.6953 - val_loss: 0.5612 - val_acc: 0.7174\n",
            "\n",
            "Epoch 00006: val_loss improved from 0.56676 to 0.56117, saving model to weights.h5\n",
            "Epoch 7/10\n",
            "25000/25000 [==============================] - 60s 2ms/step - loss: 0.5735 - acc: 0.6990 - val_loss: 0.5540 - val_acc: 0.7193\n",
            "\n",
            "Epoch 00007: val_loss improved from 0.56117 to 0.55398, saving model to weights.h5\n",
            "Epoch 8/10\n",
            "25000/25000 [==============================] - 60s 2ms/step - loss: 0.5726 - acc: 0.7001 - val_loss: 0.5486 - val_acc: 0.7209\n",
            "\n",
            "Epoch 00008: val_loss improved from 0.55398 to 0.54865, saving model to weights.h5\n",
            "Epoch 9/10\n",
            "25000/25000 [==============================] - 60s 2ms/step - loss: 0.5700 - acc: 0.7054 - val_loss: 0.5581 - val_acc: 0.7244\n",
            "\n",
            "Epoch 00009: val_loss did not improve from 0.54865\n",
            "Epoch 10/10\n",
            "25000/25000 [==============================] - 60s 2ms/step - loss: 0.5569 - acc: 0.7137 - val_loss: 0.5309 - val_acc: 0.7300\n",
            "\n",
            "Epoch 00010: val_loss improved from 0.54865 to 0.53090, saving model to weights.h5\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f211bfe0b00>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "nE4J43atJnzg"
      },
      "source": [
        "<a id='qrnn-vae'></a>\n",
        "\n",
        "## QRNN VAE"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "A-uFNihNGzo7",
        "outputId": "be02f3fa-07dc-457a-ad16-7c1441936cc3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 476
        }
      },
      "source": [
        "def build_model(timesteps=80, input_dim=28, num_classes=2):\n",
        "    embed_size = 128\n",
        "    timesteps = 28  # timesteps\n",
        "    input_dim = 28\n",
        "    num_classes = 10\n",
        "    \n",
        "    inputs = Input(shape=(timesteps, input_dim))\n",
        "#     x = Embedding(max_features, embed_size)(inputs)\n",
        "#     x = Dropout(0.25)(x)\n",
        "#     x = Conv1D(2*embed_size, kernel_size=3)(inputs)\n",
        "#     x = Conv1D(2*embed_size, kernel_size=3)(x)\n",
        "    x = inputs\n",
        "    \n",
        "    # strides rate we use here for skip\n",
        "    for strides in [1]:#[1, 1, 2]:\n",
        "        x = QRNN(128*2**(strides), return_sequences=True, stride=strides,\n",
        "                 dropout=0.2)(x)\n",
        "    x_f = QRNN(512)(x)  \n",
        "    x_b = QRNN(512, go_backwards=True)(x)\n",
        "    x = concatenate([x_f, x_b])\n",
        "    x = Dropout(0.5)(x)\n",
        "    x = Dense(64, activation='relu')(x)\n",
        "    x = Dropout(0.1)(x)\n",
        "#     outputs = Dense(6, activation='sigmoid')(x)\n",
        "    outputs = Dense(num_classes, activation='softmax')(x)\n",
        "    model = Model(inputs, outputs)\n",
        "#     model.compile(loss='binary_crossentropy',\n",
        "#                   optimizer='adam',\n",
        "#                   metrics=['binary_accuracy'])\n",
        "    model.compile(loss='categorical_crossentropy',\n",
        "                  optimizer='rmsprop',\n",
        "                  metrics=['accuracy'])\n",
        "\n",
        "    return model\n",
        "\n",
        "model = build_model()\n",
        "print(model.summary())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            (None, 28, 28)       0                                            \n",
            "__________________________________________________________________________________________________\n",
            "qrnn_1 (QRNN)                   (None, 28, 256)      43776       input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "qrnn_2 (QRNN)                   (None, 512)          787968      qrnn_1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "qrnn_3 (QRNN)                   (None, 512)          787968      qrnn_1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_1 (Concatenate)     (None, 1024)         0           qrnn_2[0][0]                     \n",
            "                                                                 qrnn_3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1 (Dropout)             (None, 1024)         0           concatenate_1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, 64)           65600       dropout_1[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dropout_2 (Dropout)             (None, 64)           0           dense_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_2 (Dense)                 (None, 10)           650         dropout_2[0][0]                  \n",
            "==================================================================================================\n",
            "Total params: 1,685,962\n",
            "Trainable params: 1,685,962\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "B0OszOvI5U8p",
        "outputId": "ab032535-aea0-41e9-cf8d-f68d7eed2fff",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        }
      },
      "source": [
        "epochs = 5\n",
        "batch_size = 1024\n",
        "\n",
        "file_path = 'weights.h5'\n",
        "checkpoint = ModelCheckpoint(file_path, monitor='val_loss', verbose=1,\n",
        "                             save_best_only=True, mode='min')\n",
        "early = EarlyStopping(monitor='val_loss', mode='min', patience=5)\n",
        "\n",
        "model.fit(X_train,\n",
        "          y_train,\n",
        "          shuffle=True,\n",
        "          batch_size=batch_size,\n",
        "          epochs=epochs,\n",
        "          validation_data=(X_test, y_test),\n",
        "          callbacks=[checkpoint, early])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 45000 samples, validate on 15000 samples\n",
            "Epoch 1/5\n",
            "45000/45000 [==============================] - 809s 18ms/step - loss: 1.8990 - acc: 0.2944 - val_loss: 1.6506 - val_acc: 0.3665\n",
            "\n",
            "Epoch 00001: val_loss improved from inf to 1.65065, saving model to weights.h5\n",
            "Epoch 2/5\n",
            "45000/45000 [==============================] - 789s 18ms/step - loss: 1.5591 - acc: 0.4214 - val_loss: 1.4525 - val_acc: 0.4081\n",
            "\n",
            "Epoch 00002: val_loss improved from 1.65065 to 1.45250, saving model to weights.h5\n",
            "Epoch 3/5\n",
            "45000/45000 [==============================] - 788s 18ms/step - loss: 1.3850 - acc: 0.4746 - val_loss: 1.3008 - val_acc: 0.5083\n",
            "\n",
            "Epoch 00003: val_loss improved from 1.45250 to 1.30083, saving model to weights.h5\n",
            "Epoch 4/5\n",
            "45000/45000 [==============================] - 791s 18ms/step - loss: 1.2083 - acc: 0.5632 - val_loss: 1.1050 - val_acc: 0.6289\n",
            "\n",
            "Epoch 00004: val_loss improved from 1.30083 to 1.10504, saving model to weights.h5\n",
            "Epoch 5/5\n",
            "45000/45000 [==============================] - 799s 18ms/step - loss: 0.9704 - acc: 0.6700 - val_loss: 0.8337 - val_acc: 0.7319\n",
            "\n",
            "Epoch 00005: val_loss improved from 1.10504 to 0.83368, saving model to weights.h5\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f3d3c23ae50>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 87
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "pXFvMfi_fkgn",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}