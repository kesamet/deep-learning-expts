{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "avH46cmYnuIz"
   },
   "source": [
    "# Quasi-recurrent neural networks - \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "Qtz21akInthW",
    "outputId": "8685f8d2-8be9-4452-86f9-bd97f7e216b8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found GPU at: /device:GPU:0\n",
      "TensorFlow Version: 1.10.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "device_name = tf.test.gpu_device_name()\n",
    "if device_name != '/device:GPU:0':\n",
    "    raise SystemError('GPU device not found')\n",
    "print('Found GPU at: {}'.format(device_name))\n",
    "print('TensorFlow Version: {}'.format(tf.__version__))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2dMdCU28l7Ac"
   },
   "source": [
    "<a id='download'></a>\n",
    "\n",
    "## Downloading dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "gtR26r8Z_itm",
    "outputId": "3ae18307-fb37-4200-f139-8cb261990233"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense, Embedding, Dropout\n",
    "from keras.layers import Input, Dense, Lambda, Flatten, Reshape, Dropout\n",
    "from keras.layers import LSTM, GRU, RepeatVector\n",
    "from keras.layers import Conv2D, Conv2DTranspose, MaxPooling2D, UpSampling2D\n",
    "from keras.layers import Conv1D, concatenate\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "from keras import backend as K\n",
    "from keras.optimizers import Adam\n",
    "from keras import objectives\n",
    "from keras import activations\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "x0qlSSNr435a"
   },
   "outputs": [],
   "source": [
    "def show_images(images):\n",
    "    import matplotlib.gridspec as gridspec\n",
    "    \n",
    "    sqrtn = int(np.ceil(np.sqrt(len(images))))\n",
    "    fig = plt.figure(figsize=(sqrtn, sqrtn))\n",
    "    gs = gridspec.GridSpec(sqrtn, sqrtn)\n",
    "    gs.update(wspace=0.05, hspace=0.05)\n",
    "\n",
    "    for i, img in enumerate(images):\n",
    "        ax = plt.subplot(gs[i])\n",
    "        plt.axis('off')\n",
    "        ax.set_xticklabels([])\n",
    "        ax.set_yticklabels([])\n",
    "        ax.set_aspect('equal')\n",
    "        plt.imshow(img[:,:,0], cmap='gray')\n",
    "    plt.show()\n",
    "    \n",
    "\n",
    "class dataset_batches():\n",
    "    def __init__(self, x_train, shuffle=True):\n",
    "        self.shuffle = shuffle\n",
    "        self.x_train = self.scale(x_train)\n",
    "        \n",
    "    def batches(self, batch_size):\n",
    "        n = len(self.x_train)\n",
    "        if self.shuffle:\n",
    "            idx = np.arange(n)\n",
    "            np.random.shuffle(idx)\n",
    "            self.x_train = self.x_train[idx]\n",
    "            \n",
    "        n_batches = n // batch_size\n",
    "        for i in range(0, n, batch_size):\n",
    "            yield self.x_train[i:i+batch_size]\n",
    "\n",
    "    def scale(self, x_train):\n",
    "        return x_train * 2 - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 119
    },
    "colab_type": "code",
    "id": "Oq-wIxZ4SOMT",
    "outputId": "8b1a338d-c520-41c8-f065-f766e2adfbec"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://s3.amazonaws.com/img-datasets/mnist.npz\n",
      "11493376/11490434 [==============================] - 1s 0us/step\n",
      "60000 train samples\n",
      "10000 test samples\n",
      "X_train shape: (60000, 28, 28)\n",
      "X_test shape: (10000, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "def load_mnist_data(dim):\n",
    "    from keras.datasets import mnist\n",
    "    from keras.utils import to_categorical\n",
    "    num_classes = 10\n",
    "    \n",
    "    (X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "    print(len(X_train), 'train samples')\n",
    "    print(len(X_test), 'test samples')\n",
    "    \n",
    "    if dim == 3:\n",
    "        if K.image_data_format() == 'channels_first':\n",
    "            X_train = X_train.reshape(len(X_train), 1, 28, 28)\n",
    "            X_test = X_test.reshape(len(X_test), 1, 28, 28)\n",
    "        else:\n",
    "            X_train = X_train.reshape(len(X_train), 28, 28, 1)\n",
    "            X_test = X_test.reshape(len(X_test), 28, 28, 1)\n",
    "    elif dim == 1:\n",
    "        X_train = X_train.reshape(len(X_train), -1)\n",
    "        X_test = X_test.reshape(len(X_test), -1)\n",
    "\n",
    "    X_train = X_train.astype('float32') / 255.\n",
    "    X_test = X_test.astype('float32') / 255.\n",
    "    print('X_train shape:', X_train.shape)\n",
    "    print('X_test shape:', X_test.shape)\n",
    "\n",
    "    # convert class vectors to binary class matrices\n",
    "    y_train = to_categorical(y_train, num_classes)\n",
    "    y_test = to_categorical(y_test, num_classes)\n",
    "    return (X_train, y_train), (X_test, y_test)\n",
    "\n",
    "(X_train, y_train), (X_test, y_test) = load_mnist_data(dim=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 136
    },
    "colab_type": "code",
    "id": "sXVeD06CvREJ",
    "outputId": "f6e76a98-459a-451b-fa10-475260f48771"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://s3.amazonaws.com/text-datasets/imdb.npz\n",
      "17465344/17464789 [==============================] - 3s 0us/step\n",
      "25000 train sequences\n",
      "25000 test sequences\n",
      "... Padding sequences (samples x time)\n",
      "X_train shape: (25000, 100)\n",
      "X_test shape: (25000, 100)\n"
     ]
    }
   ],
   "source": [
    "def get_imdb_data(maxlen=100, max_features=20000):\n",
    "    from keras.datasets import imdb\n",
    "    from keras.preprocessing import sequence\n",
    "    \n",
    "    (X_train, y_train), (X_test, y_test) = imdb.load_data(num_words=max_features)\n",
    "    print(len(X_train), 'train sequences')\n",
    "    print(len(X_test), 'test sequences')\n",
    "    \n",
    "    print('... Padding sequences (samples x time)')\n",
    "    X_train = sequence.pad_sequences(X_train, maxlen=maxlen)\n",
    "    X_test = sequence.pad_sequences(X_test, maxlen=maxlen)\n",
    "    print('X_train shape:', X_train.shape)\n",
    "    print('X_test shape:', X_test.shape)\n",
    "    \n",
    "    return (X_train, y_train), (X_test, y_test)\n",
    "\n",
    "(X_train, y_train), (X_test, y_test) = get_imdb_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1yARWHpO8rHx"
   },
   "source": [
    "### Other datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7TagLdKj4pop"
   },
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/content/gdrive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "K7YOOhVw4pfQ"
   },
   "outputs": [],
   "source": [
    "list_sentences_train = pd.read_csv('gdrive/My Drive/Colab Notebooks/data/train.csv').values\n",
    "list_sentences_test = pd.read_csv('gdrive/My Drive/Colab Notebooks/data/test.csv').values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "l8tlFc3944E1"
   },
   "outputs": [],
   "source": [
    "# Sequence GenerationÂ¶\n",
    "# Here we take the data and generate sequences from the data\n",
    "\n",
    "tokenizer = text.Tokenizer(num_words=max_features)\n",
    "tokenizer.fit_on_texts(list(list_sentences_train))\n",
    "# train data\n",
    "list_tokenized_train = tokenizer.texts_to_sequences(list_sentences_train)\n",
    "X_t = sequence.pad_sequences(list_tokenized_train, maxlen=maxlen)\n",
    "# test data\n",
    "list_tokenized_test = tokenizer.texts_to_sequences(list_sentences_test)\n",
    "X_te = sequence.pad_sequences(list_tokenized_test, maxlen=maxlen)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2t23FJz66IwH"
   },
   "source": [
    "## QRNN layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qaLeDjHLJnLa"
   },
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "from keras import activations, initializers, regularizers, constraints\n",
    "from keras.layers import Layer, InputSpec\n",
    "from keras.utils.conv_utils import conv_output_length\n",
    "\n",
    "\n",
    "def _dropout(x, level, noise_shape=None, seed=None):\n",
    "    x = K.dropout(x, level, noise_shape, seed)\n",
    "    x *= (1. - level) # compensate for the scaling by the dropout\n",
    "    return x\n",
    "\n",
    "\n",
    "class QRNN(Layer):\n",
    "    '''Quasi RNN\n",
    "    # Arguments\n",
    "        units: dimension of the internal projections and the final output.\n",
    "    # References\n",
    "        - [Quasi-recurrent Neural Networks](http://arxiv.org/abs/1611.01576)\n",
    "    '''\n",
    "    def __init__(self, units, window_size=2, stride=1,\n",
    "                 return_sequences=False, go_backwards=False, \n",
    "                 stateful=False, unroll=False, activation='tanh',\n",
    "                 kernel_initializer='uniform', bias_initializer='zero',\n",
    "                 kernel_regularizer=None, bias_regularizer=None,\n",
    "                 activity_regularizer=None,\n",
    "                 kernel_constraint=None, bias_constraint=None, \n",
    "                 dropout=0, use_bias=True, input_dim=None, input_length=None,\n",
    "                 **kwargs):\n",
    "        self.return_sequences = return_sequences\n",
    "        self.go_backwards = go_backwards\n",
    "        self.stateful = stateful\n",
    "        self.unroll = unroll\n",
    "\n",
    "        self.units = units \n",
    "        self.window_size = window_size\n",
    "        self.strides = (stride, 1)\n",
    "\n",
    "        self.use_bias = use_bias\n",
    "        self.activation = activations.get(activation)\n",
    "        self.kernel_initializer = initializers.get(kernel_initializer)\n",
    "        self.bias_initializer = initializers.get(bias_initializer)\n",
    "        self.kernel_regularizer = regularizers.get(kernel_regularizer)\n",
    "        self.bias_regularizer = regularizers.get(bias_regularizer)\n",
    "        self.activity_regularizer = regularizers.get(activity_regularizer)\n",
    "        self.kernel_constraint = constraints.get(kernel_constraint)\n",
    "        self.bias_constraint = constraints.get(bias_constraint)\n",
    "\n",
    "        self.dropout = dropout\n",
    "        self.supports_masking = True\n",
    "        self.input_spec = [InputSpec(ndim=3)]\n",
    "        self.input_dim = input_dim\n",
    "        self.input_length = input_length\n",
    "        if self.input_dim:\n",
    "            kwargs['input_shape'] = (self.input_length, self.input_dim)\n",
    "        super(QRNN, self).__init__(**kwargs)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        if isinstance(input_shape, list):\n",
    "            input_shape = input_shape[0]\n",
    "\n",
    "        batch_size = input_shape[0] if self.stateful else None\n",
    "        self.input_dim = input_shape[2]\n",
    "        self.input_spec = InputSpec(shape=(batch_size, None, self.input_dim))\n",
    "        self.state_spec = InputSpec(shape=(batch_size, self.units))\n",
    "\n",
    "        self.states = [None]\n",
    "        if self.stateful:\n",
    "            self.reset_states()\n",
    "\n",
    "        kernel_shape = (self.window_size, 1, self.input_dim, self.units * 3)\n",
    "        self.kernel = self.add_weight(name='kernel',\n",
    "                                      shape=kernel_shape,\n",
    "                                      initializer=self.kernel_initializer,\n",
    "                                      regularizer=self.kernel_regularizer,\n",
    "                                      constraint=self.kernel_constraint)\n",
    "        if self.use_bias:\n",
    "            self.bias = self.add_weight(name='bias', \n",
    "                                        shape=(self.units * 3,),\n",
    "                                        initializer=self.bias_initializer,\n",
    "                                        regularizer=self.bias_regularizer,\n",
    "                                        constraint=self.bias_constraint)\n",
    "\n",
    "        self.built = True\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        if isinstance(input_shape, list):\n",
    "            input_shape = input_shape[0]\n",
    "\n",
    "        length = input_shape[1]\n",
    "        if length:\n",
    "            length = conv_output_length(length + self.window_size - 1,\n",
    "                                        self.window_size, 'valid',\n",
    "                                        self.strides[0])\n",
    "        if self.return_sequences:\n",
    "            return (input_shape[0], length, self.units)\n",
    "        else:\n",
    "            return (input_shape[0], self.units)\n",
    "\n",
    "    def compute_mask(self, inputs, mask):\n",
    "        if self.return_sequences:\n",
    "            return mask\n",
    "        else:\n",
    "            return None\n",
    "\n",
    "    def get_initial_states(self, inputs):\n",
    "        # build an all-zero tensor of shape (samples, units)\n",
    "        initial_state = K.zeros_like(inputs)  # (samples, timesteps, input_dim)\n",
    "        initial_state = K.sum(initial_state, axis=(1, 2))  # (samples,)\n",
    "        initial_state = K.expand_dims(initial_state)  # (samples, 1)\n",
    "        initial_state = K.tile(initial_state, [1, self.units])  # (samples, units)\n",
    "        initial_states = [initial_state for _ in range(len(self.states))]\n",
    "        return initial_states\n",
    "\n",
    "    def reset_states(self, states=None):\n",
    "        if not self.stateful:\n",
    "            raise AttributeError('Layer must be stateful.')\n",
    "        if not self.input_spec:\n",
    "            raise RuntimeError('Layer has never been called '\n",
    "                               'and thus has no states.')\n",
    "\n",
    "        batch_size = self.input_spec.shape[0]\n",
    "        if not batch_size:\n",
    "            raise ValueError('If a QRNN is stateful, it needs to know '\n",
    "                             'its batch size. Specify the batch size '\n",
    "                             'of your input tensors: \\n'\n",
    "                             '- If using a Sequential model, '\n",
    "                             'specify the batch size by passing '\n",
    "                             'a `batch_input_shape` '\n",
    "                             'argument to your first layer.\\n'\n",
    "                             '- If using the functional API, specify '\n",
    "                             'the time dimension by passing a '\n",
    "                             '`batch_shape` argument to your Input layer.')\n",
    "\n",
    "        if self.states[0] is None:\n",
    "            self.states = [K.zeros((batch_size, self.units))\n",
    "                           for _ in self.states]\n",
    "        elif states is None:\n",
    "            for state in self.states:\n",
    "                K.set_value(state, np.zeros((batch_size, self.units)))\n",
    "        else:\n",
    "            if not isinstance(states, (list, tuple)):\n",
    "                states = [states]\n",
    "            if len(states) != len(self.states):\n",
    "                raise ValueError('Layer ' + self.name + ' expects ' +\n",
    "                                 str(len(self.states)) + ' states, '\n",
    "                                 'but it received ' + str(len(states)) +\n",
    "                                 'state values. Input received: ' +\n",
    "                                 str(states))\n",
    "            for index, (value, state) in enumerate(zip(states, self.states)):\n",
    "                if value.shape != (batch_size, self.units):\n",
    "                    raise ValueError('State ' + str(index) +\n",
    "                                     ' is incompatible with layer ' +\n",
    "                                     self.name + ': expected shape=' +\n",
    "                                     str((batch_size, self.units)) +\n",
    "                                     ', found shape=' + str(value.shape))\n",
    "                K.set_value(state, value)\n",
    "\n",
    "    def __call__(self, inputs, initial_state=None, **kwargs):\n",
    "        # If `initial_state` is specified,\n",
    "        # and if it a Keras tensor,\n",
    "        # then add it to the inputs and temporarily\n",
    "        # modify the input spec to include the state.\n",
    "        if initial_state is not None:\n",
    "            if hasattr(initial_state, '_keras_history'):\n",
    "                # Compute the full input spec, including state\n",
    "                input_spec = self.input_spec\n",
    "                state_spec = self.state_spec\n",
    "                if not isinstance(state_spec, list):\n",
    "                    state_spec = [state_spec]\n",
    "                self.input_spec = [input_spec] + state_spec\n",
    "\n",
    "                # Compute the full inputs, including state\n",
    "                if not isinstance(initial_state, (list, tuple)):\n",
    "                    initial_state = [initial_state]\n",
    "                inputs = [inputs] + list(initial_state)\n",
    "\n",
    "                # Perform the call\n",
    "                output = super(QRNN, self).__call__(inputs, **kwargs)\n",
    "\n",
    "                # Restore original input spec\n",
    "                self.input_spec = input_spec\n",
    "                return output\n",
    "            else:\n",
    "                kwargs['initial_state'] = initial_state\n",
    "        return super(QRNN, self).__call__(inputs, **kwargs)\n",
    "\n",
    "    def call(self, inputs, mask=None, initial_state=None, training=None):\n",
    "        # input shape: `(samples, time (padded with zeros), input_dim)`\n",
    "        # note that the .build() method of subclasses MUST define\n",
    "        # self.input_spec and self.state_spec with complete input shapes.\n",
    "        if isinstance(inputs, list):\n",
    "            initial_states = inputs[1:]\n",
    "            inputs = inputs[0]\n",
    "        elif initial_state is not None:\n",
    "            pass\n",
    "        elif self.stateful:\n",
    "            initial_states = self.states\n",
    "        else:\n",
    "            initial_states = self.get_initial_states(inputs)\n",
    "\n",
    "        if len(initial_states) != len(self.states):\n",
    "            raise ValueError('Layer has ' + str(len(self.states)) +\n",
    "                             ' states but was passed ' +\n",
    "                             str(len(initial_states)) +\n",
    "                             ' initial states.')\n",
    "        input_shape = K.int_shape(inputs)\n",
    "        if self.unroll and input_shape[1] is None:\n",
    "            raise ValueError('Cannot unroll a RNN if the '\n",
    "                             'time dimension is undefined. \\n'\n",
    "                             '- If using a Sequential model, '\n",
    "                             'specify the time dimension by passing '\n",
    "                             'an `input_shape` or `batch_input_shape` '\n",
    "                             'argument to your first layer. If your '\n",
    "                             'first layer is an Embedding, you can '\n",
    "                             'also use the `input_length` argument.\\n'\n",
    "                             '- If using the functional API, specify '\n",
    "                             'the time dimension by passing a `shape` '\n",
    "                             'or `batch_shape` argument to your Input layer.')\n",
    "        constants = self.get_constants(inputs, training=None)\n",
    "        preprocessed_input = self.preprocess_input(inputs, training=None)\n",
    "\n",
    "        last_output, outputs, states = K.rnn(self.step, preprocessed_input,\n",
    "                                            initial_states,\n",
    "                                            go_backwards=self.go_backwards,\n",
    "                                            mask=mask,\n",
    "                                            constants=constants,\n",
    "                                            unroll=self.unroll,\n",
    "                                            input_length=input_shape[1])\n",
    "        if self.stateful:\n",
    "            updates = []\n",
    "            for i in range(len(states)):\n",
    "                updates.append((self.states[i], states[i]))\n",
    "            self.add_update(updates, inputs)\n",
    "\n",
    "        # Properly set learning phase\n",
    "        if 0 < self.dropout < 1:\n",
    "            last_output._uses_learning_phase = True\n",
    "            outputs._uses_learning_phase = True\n",
    "\n",
    "        if self.return_sequences:\n",
    "            return outputs\n",
    "        else:\n",
    "            return last_output\n",
    "\n",
    "    def preprocess_input(self, inputs, training=None):\n",
    "        if self.window_size > 1:\n",
    "            inputs = K.temporal_padding(inputs, (self.window_size-1, 0))\n",
    "        inputs = K.expand_dims(inputs, 2)  # add a dummy dimension\n",
    "\n",
    "        output = K.conv2d(inputs, self.kernel, strides=self.strides,\n",
    "                          padding='valid',\n",
    "                          data_format='channels_last')\n",
    "        output = K.squeeze(output, 2)  # remove the dummy dimension\n",
    "        if self.use_bias:\n",
    "            output = K.bias_add(output, self.bias, data_format='channels_last')\n",
    "\n",
    "        if self.dropout is not None and 0. < self.dropout < 1.:\n",
    "            z = output[:, :, :self.units]\n",
    "            f = output[:, :, self.units:2 * self.units]\n",
    "            o = output[:, :, 2 * self.units:]\n",
    "            f = K.in_train_phase(1 - _dropout(1 - f, self.dropout), f, training=training)\n",
    "            return K.concatenate([z, f, o], -1)\n",
    "        else:\n",
    "            return output\n",
    "\n",
    "    def step(self, inputs, states):\n",
    "        prev_output = states[0]\n",
    "\n",
    "        z = inputs[:, :self.units]\n",
    "        f = inputs[:, self.units:2 * self.units]\n",
    "        o = inputs[:, 2 * self.units:]\n",
    "\n",
    "        z = self.activation(z)\n",
    "        f = f if self.dropout is not None and 0. < self.dropout < 1. else K.sigmoid(f)\n",
    "        o = K.sigmoid(o)\n",
    "\n",
    "        output = f * prev_output + (1 - f) * z\n",
    "        output = o * output\n",
    "\n",
    "        return output, [output]\n",
    "\n",
    "    def get_constants(self, inputs, training=None):\n",
    "        return []\n",
    " \n",
    "    def get_config(self):\n",
    "        config = {'units': self.units,\n",
    "                  'window_size': self.window_size,\n",
    "                  'stride': self.strides[0],\n",
    "                  'return_sequences': self.return_sequences,\n",
    "                  'go_backwards': self.go_backwards,\n",
    "                  'stateful': self.stateful,\n",
    "                  'unroll': self.unroll,\n",
    "                  'use_bias': self.use_bias,\n",
    "                  'dropout': self.dropout,\n",
    "                  'activation': activations.serialize(self.activation),\n",
    "                  'kernel_initializer': initializers.serialize(self.kernel_initializer),\n",
    "                  'bias_initializer': initializers.serialize(self.bias_initializer),\n",
    "                  'kernel_regularizer': regularizers.serialize(self.kernel_regularizer),\n",
    "                  'bias_regularizer': regularizers.serialize(self.bias_regularizer),\n",
    "                  'activity_regularizer': regularizers.serialize(self.activity_regularizer),\n",
    "                  'kernel_constraint': constraints.serialize(self.kernel_constraint),\n",
    "                  'bias_constraint': constraints.serialize(self.bias_constraint),\n",
    "                  'input_dim': self.input_dim,\n",
    "                  'input_length': self.input_length}\n",
    "        base_config = super(QRNN, self).get_config()\n",
    "        return dict(list(base_config.items()) + list(config.items()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "u5HW_MP544ts"
   },
   "source": [
    "## First experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 680
    },
    "colab_type": "code",
    "id": "mlTlqcWA4361",
    "outputId": "6dfda931-b76b-443e-8221-a6051702aa92"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_8 (InputLayer)            (None, 100)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_8 (Embedding)         (None, 100, 300)     6000000     input_8[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_23 (Dropout)            (None, 100, 300)     0           embedding_8[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_5 (Conv1D)               (None, 98, 600)      540600      dropout_23[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_6 (Conv1D)               (None, 96, 600)      1080600     conv1d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "qrnn_20 (QRNN)                  (None, 96, 256)      922368      conv1d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "qrnn_21 (QRNN)                  (None, 96, 256)      393984      qrnn_20[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "qrnn_22 (QRNN)                  (None, 48, 512)      787968      qrnn_21[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "qrnn_23 (QRNN)                  (None, 512)          1574400     qrnn_22[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "qrnn_24 (QRNN)                  (None, 512)          1574400     qrnn_22[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_4 (Concatenate)     (None, 1024)         0           qrnn_23[0][0]                    \n",
      "                                                                 qrnn_24[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_24 (Dropout)            (None, 1024)         0           concatenate_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_10 (Dense)                (None, 64)           65600       dropout_24[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_25 (Dropout)            (None, 64)           0           dense_10[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_11 (Dense)                (None, 6)            390         dropout_25[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 12,940,310\n",
      "Trainable params: 12,940,310\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "def build_model(input_length=100, max_features=20000, embed_size=300):\n",
    "    inp = Input(shape=(input_length, ))\n",
    "    x = Embedding(max_features, embed_size)(inp)\n",
    "    x = Dropout(0.25)(x)\n",
    "    x = Conv1D(2*embed_size, kernel_size=3)(x)\n",
    "    x = Conv1D(2*embed_size, kernel_size=3)(x)\n",
    "    \n",
    "    # strides rate we use here for skip\n",
    "    for strides in [1, 1, 2]:\n",
    "        x = QRNN(128*2**(strides), return_sequences=True, stride=strides, dropout=0.2)(x)\n",
    "    x_f = QRNN(512)(x)  \n",
    "    x_b = QRNN(512, go_backwards=True)(x)\n",
    "    x = concatenate([x_f, x_b])\n",
    "    x = Dropout(0.5)(x)\n",
    "    x = Dense(64, activation='relu')(x)\n",
    "    x = Dropout(0.1)(x)\n",
    "    x = Dense(6, activation='sigmoid')(x)\n",
    "    model = Model(inputs=inp, outputs=x)\n",
    "    model.compile(loss='binary_crossentropy',\n",
    "                  optimizer='adam',\n",
    "                  metrics=['accuracy'])\n",
    "    print(model.summary())\n",
    "    return model\n",
    "\n",
    "model = build_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 527
    },
    "colab_type": "code",
    "id": "aA91rwkd5Eyj",
    "outputId": "68b85244-8c7f-47d7-b00e-036ea608505d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 25000 samples, validate on 25000 samples\n",
      "Epoch 1/20\n",
      "25000/25000 [==============================] - 80s 3ms/step - loss: 0.6658 - acc: 0.5628 - val_loss: 0.5951 - val_acc: 0.6783\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.59508, saving model to weights.h5\n",
      "Epoch 2/20\n",
      "25000/25000 [==============================] - 77s 3ms/step - loss: 0.5021 - acc: 0.7580 - val_loss: 0.5929 - val_acc: 0.7167\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.59508 to 0.59291, saving model to weights.h5\n",
      "Epoch 3/20\n",
      "25000/25000 [==============================] - 77s 3ms/step - loss: 0.3720 - acc: 0.8364 - val_loss: 0.6533 - val_acc: 0.7058\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.59291\n",
      "Epoch 4/20\n",
      "25000/25000 [==============================] - 77s 3ms/step - loss: 0.2578 - acc: 0.8958 - val_loss: 0.8122 - val_acc: 0.6955\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.59291\n",
      "Epoch 5/20\n",
      "25000/25000 [==============================] - 77s 3ms/step - loss: 0.1593 - acc: 0.9370 - val_loss: 1.1707 - val_acc: 0.6865\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.59291\n",
      "Epoch 6/20\n",
      "25000/25000 [==============================] - 76s 3ms/step - loss: 0.3093 - acc: 0.7964 - val_loss: 0.6932 - val_acc: 0.5000\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.59291\n",
      "Epoch 7/20\n",
      "25000/25000 [==============================] - 74s 3ms/step - loss: 0.6932 - acc: 0.5000 - val_loss: 0.6931 - val_acc: 0.5000\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.59291\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f2121fdee80>"
      ]
     },
     "execution_count": 15,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epochs = 10\n",
    "batch_size = 1024\n",
    "\n",
    "file_path = 'weights.h5'\n",
    "checkpoint = ModelCheckpoint(file_path, monitor='val_loss', verbose=1,\n",
    "                             save_best_only=True, mode='min')\n",
    "early = EarlyStopping(monitor='val_loss', mode='min', patience=5)\n",
    "\n",
    "callbacks_list = [checkpoint, early]\n",
    "model.fit(X_train, y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          shuffle=True,\n",
    "          #validation_split=0.25,\n",
    "          validation_data=(X_test, y_test),\n",
    "          callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_7qKLmAA5ErF"
   },
   "outputs": [],
   "source": [
    "# from google.colab import files\n",
    "\n",
    "# files.download('weights.h5') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dliF_Yvq5c4T"
   },
   "source": [
    "## Second experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 527
    },
    "colab_type": "code",
    "id": "BDHqd2i9mjqx",
    "outputId": "7e4cbc47-0533-4b5e-a5f8-8bba9747fc1c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_5 (InputLayer)         (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "embedding_5 (Embedding)      (None, 100, 300)          6000000   \n",
      "_________________________________________________________________\n",
      "dropout_14 (Dropout)         (None, 100, 300)          0         \n",
      "_________________________________________________________________\n",
      "gru_1 (GRU)                  (None, 100, 256)          427776    \n",
      "_________________________________________________________________\n",
      "dropout_15 (Dropout)         (None, 100, 256)          0         \n",
      "_________________________________________________________________\n",
      "gru_2 (GRU)                  (None, 100, 256)          393984    \n",
      "_________________________________________________________________\n",
      "dropout_16 (Dropout)         (None, 100, 256)          0         \n",
      "_________________________________________________________________\n",
      "gru_3 (GRU)                  (None, 100, 256)          393984    \n",
      "_________________________________________________________________\n",
      "dropout_17 (Dropout)         (None, 100, 256)          0         \n",
      "_________________________________________________________________\n",
      "gru_4 (GRU)                  (None, 256)               393984    \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 1)                 257       \n",
      "=================================================================\n",
      "Total params: 7,609,985\n",
      "Trainable params: 1,609,985\n",
      "Non-trainable params: 6,000,000\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "def build_model(input_length=100, max_features=20000, embed_size=300):\n",
    "    inputs = Input(shape=(input_length, ))\n",
    "    x = Embedding(max_features, embed_size, trainable=False)(inputs)\n",
    "    x = Dropout(0.3)(x)\n",
    "    for _ in range(3):\n",
    "        x = GRU(256, return_sequences=True)(x)\n",
    "        x = Dropout(0.3)(x)\n",
    "        \n",
    "    x = GRU(256)(x)\n",
    "    outputs = Dense(1, activation='sigmoid')(x)\n",
    "    model = Model(inputs, outputs)\n",
    "    \n",
    "    model.compile(loss='binary_crossentropy',\n",
    "                  optimizer='adam',\n",
    "                  metrics=['accuracy'])\n",
    "    print(model.summary())\n",
    "    return model\n",
    "\n",
    "model = build_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 731
    },
    "colab_type": "code",
    "id": "OMCmaA7BmDif",
    "outputId": "8347675c-53f4-4e06-fd19-84ce4898770d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 25000 samples, validate on 25000 samples\n",
      "Epoch 1/10\n",
      "25000/25000 [==============================] - 51s 2ms/step - loss: 0.6731 - acc: 0.5750 - val_loss: 0.6435 - val_acc: 0.6329\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.64348, saving model to weights.h5\n",
      "Epoch 2/10\n",
      "25000/25000 [==============================] - 47s 2ms/step - loss: 0.6307 - acc: 0.6450 - val_loss: 0.5913 - val_acc: 0.6903\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.64348 to 0.59132, saving model to weights.h5\n",
      "Epoch 3/10\n",
      "25000/25000 [==============================] - 47s 2ms/step - loss: 0.6019 - acc: 0.6746 - val_loss: 0.6378 - val_acc: 0.6184\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.59132\n",
      "Epoch 4/10\n",
      "25000/25000 [==============================] - 47s 2ms/step - loss: 0.6105 - acc: 0.6654 - val_loss: 0.5929 - val_acc: 0.6975\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.59132\n",
      "Epoch 5/10\n",
      "25000/25000 [==============================] - 47s 2ms/step - loss: 0.5889 - acc: 0.6831 - val_loss: 0.5671 - val_acc: 0.7028\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.59132 to 0.56709, saving model to weights.h5\n",
      "Epoch 6/10\n",
      "25000/25000 [==============================] - 47s 2ms/step - loss: 0.5742 - acc: 0.6962 - val_loss: 0.5438 - val_acc: 0.7200\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.56709 to 0.54380, saving model to weights.h5\n",
      "Epoch 7/10\n",
      "25000/25000 [==============================] - 47s 2ms/step - loss: 0.5619 - acc: 0.7063 - val_loss: 0.5453 - val_acc: 0.7212\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.54380\n",
      "Epoch 8/10\n",
      "25000/25000 [==============================] - 47s 2ms/step - loss: 0.5570 - acc: 0.7125 - val_loss: 0.5358 - val_acc: 0.7280\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.54380 to 0.53584, saving model to weights.h5\n",
      "Epoch 9/10\n",
      "25000/25000 [==============================] - 47s 2ms/step - loss: 0.5522 - acc: 0.7149 - val_loss: 0.5330 - val_acc: 0.7353\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.53584 to 0.53300, saving model to weights.h5\n",
      "Epoch 10/10\n",
      "25000/25000 [==============================] - 47s 2ms/step - loss: 0.5521 - acc: 0.7176 - val_loss: 0.5291 - val_acc: 0.7339\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.53300 to 0.52912, saving model to weights.h5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f211f36b908>"
      ]
     },
     "execution_count": 19,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epochs = 10\n",
    "batch_size = 1024\n",
    "\n",
    "file_path = 'weights.h5'\n",
    "checkpoint = ModelCheckpoint(file_path, monitor='val_loss', verbose=1,\n",
    "                             save_best_only=True, mode='min')\n",
    "early = EarlyStopping(monitor='val_loss', mode='min', patience=5)\n",
    "\n",
    "model.fit(X_train, y_train,\n",
    "          shuffle=True,\n",
    "          batch_size=batch_size, \n",
    "          epochs=epochs,\n",
    "          validation_data=(X_test, y_test),\n",
    "          callbacks=[checkpoint, early])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 527
    },
    "colab_type": "code",
    "id": "DoxD6L-vqmcF",
    "outputId": "a4e1afe7-a3ed-443a-fc20-f242216ebc1c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_7 (InputLayer)         (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "embedding_7 (Embedding)      (None, 100, 300)          6000000   \n",
      "_________________________________________________________________\n",
      "dropout_19 (Dropout)         (None, 100, 300)          0         \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 100, 256)          570368    \n",
      "_________________________________________________________________\n",
      "dropout_20 (Dropout)         (None, 100, 256)          0         \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 100, 256)          525312    \n",
      "_________________________________________________________________\n",
      "dropout_21 (Dropout)         (None, 100, 256)          0         \n",
      "_________________________________________________________________\n",
      "lstm_3 (LSTM)                (None, 100, 256)          525312    \n",
      "_________________________________________________________________\n",
      "dropout_22 (Dropout)         (None, 100, 256)          0         \n",
      "_________________________________________________________________\n",
      "lstm_4 (LSTM)                (None, 256)               525312    \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 1)                 257       \n",
      "=================================================================\n",
      "Total params: 8,146,561\n",
      "Trainable params: 2,146,561\n",
      "Non-trainable params: 6,000,000\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "def build_model(input_length=100, max_features=20000, embed_size=300):\n",
    "    inputs = Input(shape=(input_length, ))\n",
    "    x = Embedding(max_features, embed_size, trainable=False)(inputs)\n",
    "    x = Dropout(0.3)(x)\n",
    "    for _ in range(3):\n",
    "        x = LSTM(256, return_sequences=True)(x)\n",
    "        x = Dropout(0.3)(x)\n",
    "        \n",
    "    x = LSTM(256)(x)\n",
    "    outputs = Dense(1, activation='sigmoid')(x)\n",
    "    model = Model(inputs, outputs)\n",
    "    \n",
    "    model.compile(loss='binary_crossentropy',\n",
    "                  optimizer='adam',\n",
    "                  metrics=['accuracy'])\n",
    "    print(model.summary())\n",
    "    return model\n",
    "\n",
    "model = build_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 731
    },
    "colab_type": "code",
    "id": "XEvO9-AlmjiQ",
    "outputId": "4aac1a6e-fde3-46de-98b6-e4ab2e94bea5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 25000 samples, validate on 25000 samples\n",
      "Epoch 1/10\n",
      "25000/25000 [==============================] - 65s 3ms/step - loss: 0.6819 - acc: 0.5472 - val_loss: 0.6620 - val_acc: 0.6026\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.66197, saving model to weights.h5\n",
      "Epoch 2/10\n",
      "25000/25000 [==============================] - 60s 2ms/step - loss: 0.6554 - acc: 0.6170 - val_loss: 0.6502 - val_acc: 0.6069\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.66197 to 0.65025, saving model to weights.h5\n",
      "Epoch 3/10\n",
      "25000/25000 [==============================] - 60s 2ms/step - loss: 0.6401 - acc: 0.6381 - val_loss: 0.6238 - val_acc: 0.6894\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.65025 to 0.62376, saving model to weights.h5\n",
      "Epoch 4/10\n",
      "25000/25000 [==============================] - 60s 2ms/step - loss: 0.6089 - acc: 0.6712 - val_loss: 0.5943 - val_acc: 0.6736\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.62376 to 0.59432, saving model to weights.h5\n",
      "Epoch 5/10\n",
      "25000/25000 [==============================] - 60s 2ms/step - loss: 0.5961 - acc: 0.6864 - val_loss: 0.5668 - val_acc: 0.7062\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.59432 to 0.56676, saving model to weights.h5\n",
      "Epoch 6/10\n",
      "25000/25000 [==============================] - 60s 2ms/step - loss: 0.5784 - acc: 0.6953 - val_loss: 0.5612 - val_acc: 0.7174\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.56676 to 0.56117, saving model to weights.h5\n",
      "Epoch 7/10\n",
      "25000/25000 [==============================] - 60s 2ms/step - loss: 0.5735 - acc: 0.6990 - val_loss: 0.5540 - val_acc: 0.7193\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.56117 to 0.55398, saving model to weights.h5\n",
      "Epoch 8/10\n",
      "25000/25000 [==============================] - 60s 2ms/step - loss: 0.5726 - acc: 0.7001 - val_loss: 0.5486 - val_acc: 0.7209\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.55398 to 0.54865, saving model to weights.h5\n",
      "Epoch 9/10\n",
      "25000/25000 [==============================] - 60s 2ms/step - loss: 0.5700 - acc: 0.7054 - val_loss: 0.5581 - val_acc: 0.7244\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.54865\n",
      "Epoch 10/10\n",
      "25000/25000 [==============================] - 60s 2ms/step - loss: 0.5569 - acc: 0.7137 - val_loss: 0.5309 - val_acc: 0.7300\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.54865 to 0.53090, saving model to weights.h5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f211bfe0b00>"
      ]
     },
     "execution_count": 22,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epochs = 10\n",
    "batch_size = 1024\n",
    "\n",
    "file_path = 'weights.h5'\n",
    "checkpoint = ModelCheckpoint(file_path, monitor='val_loss', verbose=1,\n",
    "                             save_best_only=True, mode='min')\n",
    "early = EarlyStopping(monitor='val_loss', mode='min', patience=5)\n",
    "\n",
    "model.fit(X_train, y_train,\n",
    "          shuffle=True,\n",
    "          batch_size=batch_size, \n",
    "          epochs=epochs,\n",
    "          validation_data=(X_test, y_test),\n",
    "          callbacks=[checkpoint, early])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 527
    },
    "colab_type": "code",
    "id": "HYw4EFQD5REW",
    "outputId": "cec31ca2-47f9-4597-8ee2-cdcba9baa34b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "embedding_1 (Embedding)      (None, 100, 300)          6000000   \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 100, 300)          0         \n",
      "_________________________________________________________________\n",
      "qrnn_1 (QRNN)                (None, 100, 256)          691968    \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 100, 256)          0         \n",
      "_________________________________________________________________\n",
      "qrnn_2 (QRNN)                (None, 100, 256)          590592    \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 100, 256)          0         \n",
      "_________________________________________________________________\n",
      "qrnn_3 (QRNN)                (None, 100, 256)          590592    \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 100, 256)          0         \n",
      "_________________________________________________________________\n",
      "qrnn_4 (QRNN)                (None, 256)               590592    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 257       \n",
      "=================================================================\n",
      "Total params: 8,464,001\n",
      "Trainable params: 2,464,001\n",
      "Non-trainable params: 6,000,000\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "def build_model(input_length=100, max_features=20000, embed_size=300):\n",
    "    inputs = Input(shape=(input_length, ))\n",
    "    x = Embedding(max_features, embed_size, trainable=False)(inputs)\n",
    "    x = Dropout(0.3)(x)\n",
    "    for _ in range(3):\n",
    "        x = QRNN(256, window_size=3, dropout=0, return_sequences=True)(x)\n",
    "        x = Dropout(0.3)(x)\n",
    "        \n",
    "    x = QRNN(256, window_size=3, dropout=0, return_sequences=False)(x)\n",
    "    outputs = Dense(1, activation='sigmoid')(x)\n",
    "    model = Model(inputs, outputs)\n",
    "    \n",
    "    model.compile(loss='binary_crossentropy',\n",
    "                  optimizer='adam',\n",
    "                  metrics=['accuracy'])\n",
    "    print(model.summary())\n",
    "    return model\n",
    "\n",
    "model = build_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1411
    },
    "colab_type": "code",
    "id": "0xdCwe-b5Q9x",
    "outputId": "184ca60f-271e-44ab-b9c3-9bf59166c174"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 25000 samples, validate on 25000 samples\n",
      "Epoch 1/20\n",
      "25000/25000 [==============================] - 50s 2ms/step - loss: 0.6929 - acc: 0.5114 - val_loss: 0.6897 - val_acc: 0.5620\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.68971, saving model to weights.h5\n",
      "Epoch 2/20\n",
      "25000/25000 [==============================] - 46s 2ms/step - loss: 0.6725 - acc: 0.5800 - val_loss: 0.6577 - val_acc: 0.6027\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.68971 to 0.65767, saving model to weights.h5\n",
      "Epoch 3/20\n",
      "25000/25000 [==============================] - 46s 2ms/step - loss: 0.6539 - acc: 0.6097 - val_loss: 0.6389 - val_acc: 0.6334\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.65767 to 0.63891, saving model to weights.h5\n",
      "Epoch 4/20\n",
      "25000/25000 [==============================] - 46s 2ms/step - loss: 0.6398 - acc: 0.6274 - val_loss: 0.6361 - val_acc: 0.6313\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.63891 to 0.63614, saving model to weights.h5\n",
      "Epoch 5/20\n",
      "25000/25000 [==============================] - 46s 2ms/step - loss: 0.6298 - acc: 0.6353 - val_loss: 0.6261 - val_acc: 0.6397\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.63614 to 0.62608, saving model to weights.h5\n",
      "Epoch 6/20\n",
      "25000/25000 [==============================] - 46s 2ms/step - loss: 0.6214 - acc: 0.6446 - val_loss: 0.6234 - val_acc: 0.6456\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.62608 to 0.62337, saving model to weights.h5\n",
      "Epoch 7/20\n",
      "25000/25000 [==============================] - 46s 2ms/step - loss: 0.6183 - acc: 0.6476 - val_loss: 0.6219 - val_acc: 0.6421\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.62337 to 0.62185, saving model to weights.h5\n",
      "Epoch 8/20\n",
      "25000/25000 [==============================] - 46s 2ms/step - loss: 0.6162 - acc: 0.6495 - val_loss: 0.6185 - val_acc: 0.6456\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.62185 to 0.61852, saving model to weights.h5\n",
      "Epoch 9/20\n",
      "25000/25000 [==============================] - 46s 2ms/step - loss: 0.6087 - acc: 0.6559 - val_loss: 0.6166 - val_acc: 0.6448\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.61852 to 0.61658, saving model to weights.h5\n",
      "Epoch 10/20\n",
      "25000/25000 [==============================] - 46s 2ms/step - loss: 0.6032 - acc: 0.6579 - val_loss: 0.6126 - val_acc: 0.6458\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.61658 to 0.61259, saving model to weights.h5\n",
      "Epoch 11/20\n",
      "25000/25000 [==============================] - 46s 2ms/step - loss: 0.5941 - acc: 0.6644 - val_loss: 0.6057 - val_acc: 0.6498\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.61259 to 0.60568, saving model to weights.h5\n",
      "Epoch 12/20\n",
      "25000/25000 [==============================] - 46s 2ms/step - loss: 0.5902 - acc: 0.6683 - val_loss: 0.6062 - val_acc: 0.6488\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.60568\n",
      "Epoch 13/20\n",
      "25000/25000 [==============================] - 47s 2ms/step - loss: 0.5838 - acc: 0.6753 - val_loss: 0.6006 - val_acc: 0.6535\n",
      "\n",
      "Epoch 00013: val_loss improved from 0.60568 to 0.60059, saving model to weights.h5\n",
      "Epoch 14/20\n",
      "25000/25000 [==============================] - 47s 2ms/step - loss: 0.5799 - acc: 0.6788 - val_loss: 0.5992 - val_acc: 0.6518\n",
      "\n",
      "Epoch 00014: val_loss improved from 0.60059 to 0.59924, saving model to weights.h5\n",
      "Epoch 15/20\n",
      "25000/25000 [==============================] - 47s 2ms/step - loss: 0.5747 - acc: 0.6801 - val_loss: 0.5995 - val_acc: 0.6489\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.59924\n",
      "Epoch 16/20\n",
      "25000/25000 [==============================] - 47s 2ms/step - loss: 0.5705 - acc: 0.6820 - val_loss: 0.5947 - val_acc: 0.6534\n",
      "\n",
      "Epoch 00016: val_loss improved from 0.59924 to 0.59472, saving model to weights.h5\n",
      "Epoch 17/20\n",
      "25000/25000 [==============================] - 47s 2ms/step - loss: 0.5662 - acc: 0.6860 - val_loss: 0.5942 - val_acc: 0.6530\n",
      "\n",
      "Epoch 00017: val_loss improved from 0.59472 to 0.59418, saving model to weights.h5\n",
      "Epoch 18/20\n",
      "25000/25000 [==============================] - 47s 2ms/step - loss: 0.5589 - acc: 0.6935 - val_loss: 0.5893 - val_acc: 0.6593\n",
      "\n",
      "Epoch 00018: val_loss improved from 0.59418 to 0.58930, saving model to weights.h5\n",
      "Epoch 19/20\n",
      "25000/25000 [==============================] - 47s 2ms/step - loss: 0.5572 - acc: 0.6944 - val_loss: 0.5891 - val_acc: 0.6566\n",
      "\n",
      "Epoch 00019: val_loss improved from 0.58930 to 0.58906, saving model to weights.h5\n",
      "Epoch 20/20\n",
      "25000/25000 [==============================] - 47s 2ms/step - loss: 0.5574 - acc: 0.6963 - val_loss: 0.5884 - val_acc: 0.6551\n",
      "\n",
      "Epoch 00020: val_loss improved from 0.58906 to 0.58844, saving model to weights.h5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f212fa62ef0>"
      ]
     },
     "execution_count": 8,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epochs = 20\n",
    "batch_size = 1024\n",
    "\n",
    "file_path = 'weights.h5'\n",
    "checkpoint = ModelCheckpoint(file_path, monitor='val_loss', verbose=1,\n",
    "                             save_best_only=True, mode='min')\n",
    "early = EarlyStopping(monitor='val_loss', mode='min', patience=5)\n",
    "\n",
    "model.fit(X_train, y_train,\n",
    "          shuffle=True,\n",
    "          batch_size=batch_size, \n",
    "          epochs=epochs,\n",
    "          validation_data=(X_test, y_test),\n",
    "          callbacks=[checkpoint, early])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nE4J43atJnzg"
   },
   "source": [
    "<a id='qrnn-vae'></a>\n",
    "\n",
    "## QRNN VAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 476
    },
    "colab_type": "code",
    "id": "A-uFNihNGzo7",
    "outputId": "be02f3fa-07dc-457a-ad16-7c1441936cc3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 28, 28)       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "qrnn_1 (QRNN)                   (None, 28, 256)      43776       input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "qrnn_2 (QRNN)                   (None, 512)          787968      qrnn_1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "qrnn_3 (QRNN)                   (None, 512)          787968      qrnn_1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 1024)         0           qrnn_2[0][0]                     \n",
      "                                                                 qrnn_3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 1024)         0           concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 64)           65600       dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 64)           0           dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 10)           650         dropout_2[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 1,685,962\n",
      "Trainable params: 1,685,962\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "def build_model(timesteps=80, input_dim=28, num_classes=2):\n",
    "    embed_size = 128\n",
    "    timesteps = 28  # timesteps\n",
    "    input_dim = 28\n",
    "    num_classes = 10\n",
    "    \n",
    "    inputs = Input(shape=(timesteps, input_dim))\n",
    "#     x = Embedding(max_features, embed_size)(inputs)\n",
    "#     x = Dropout(0.25)(x)\n",
    "#     x = Conv1D(2*embed_size, kernel_size=3)(inputs)\n",
    "#     x = Conv1D(2*embed_size, kernel_size=3)(x)\n",
    "    x = inputs\n",
    "    \n",
    "    # strides rate we use here for skip\n",
    "    for strides in [1]:#[1, 1, 2]:\n",
    "        x = QRNN(128*2**(strides), return_sequences=True, stride=strides,\n",
    "                 dropout=0.2)(x)\n",
    "    x_f = QRNN(512)(x)  \n",
    "    x_b = QRNN(512, go_backwards=True)(x)\n",
    "    x = concatenate([x_f, x_b])\n",
    "    x = Dropout(0.5)(x)\n",
    "    x = Dense(64, activation='relu')(x)\n",
    "    x = Dropout(0.1)(x)\n",
    "#     outputs = Dense(6, activation='sigmoid')(x)\n",
    "    outputs = Dense(num_classes, activation='softmax')(x)\n",
    "    model = Model(inputs, outputs)\n",
    "#     model.compile(loss='binary_crossentropy',\n",
    "#                   optimizer='adam',\n",
    "#                   metrics=['binary_accuracy'])\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "                  optimizer='rmsprop',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    return model\n",
    "\n",
    "model = build_model()\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 391
    },
    "colab_type": "code",
    "id": "B0OszOvI5U8p",
    "outputId": "ab032535-aea0-41e9-cf8d-f68d7eed2fff"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 45000 samples, validate on 15000 samples\n",
      "Epoch 1/5\n",
      "45000/45000 [==============================] - 809s 18ms/step - loss: 1.8990 - acc: 0.2944 - val_loss: 1.6506 - val_acc: 0.3665\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.65065, saving model to weights.h5\n",
      "Epoch 2/5\n",
      "45000/45000 [==============================] - 789s 18ms/step - loss: 1.5591 - acc: 0.4214 - val_loss: 1.4525 - val_acc: 0.4081\n",
      "\n",
      "Epoch 00002: val_loss improved from 1.65065 to 1.45250, saving model to weights.h5\n",
      "Epoch 3/5\n",
      "45000/45000 [==============================] - 788s 18ms/step - loss: 1.3850 - acc: 0.4746 - val_loss: 1.3008 - val_acc: 0.5083\n",
      "\n",
      "Epoch 00003: val_loss improved from 1.45250 to 1.30083, saving model to weights.h5\n",
      "Epoch 4/5\n",
      "45000/45000 [==============================] - 791s 18ms/step - loss: 1.2083 - acc: 0.5632 - val_loss: 1.1050 - val_acc: 0.6289\n",
      "\n",
      "Epoch 00004: val_loss improved from 1.30083 to 1.10504, saving model to weights.h5\n",
      "Epoch 5/5\n",
      "45000/45000 [==============================] - 799s 18ms/step - loss: 0.9704 - acc: 0.6700 - val_loss: 0.8337 - val_acc: 0.7319\n",
      "\n",
      "Epoch 00005: val_loss improved from 1.10504 to 0.83368, saving model to weights.h5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f3d3c23ae50>"
      ]
     },
     "execution_count": 87,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epochs = 5\n",
    "batch_size = 1024\n",
    "\n",
    "file_path = 'weights.h5'\n",
    "checkpoint = ModelCheckpoint(file_path, monitor='val_loss', verbose=1, save_best_only=True, mode='min')\n",
    "early = EarlyStopping(monitor='val_loss', mode='min', patience=5)\n",
    "\n",
    "model.fit(X_train, y_train,\n",
    "          shuffle=True,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          validation_data=(X_test, y_test),\n",
    "          callbacks=[checkpoint, early])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XBoiwEzzZYik"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IcUh6oIs8MWv"
   },
   "outputs": [],
   "source": [
    "class qrnn_vae():\n",
    "    def __init__(self, input_dim, timesteps):\n",
    "        self.input_dim = input_dim\n",
    "        self.timesteps = timesteps\n",
    "        self.input_shape = (timesteps, input_dim)\n",
    "#         self.original_dim = timesteps * input_dim\n",
    "        self.latent_dim = 2\n",
    "        \n",
    "        # Build the encoder / decoder\n",
    "        self.encoder = self.build_encoder()\n",
    "        self.decoder = self.build_decoder()\n",
    "\n",
    "        img = Input(shape=self.input_shape)\n",
    "        # The generator takes the image, encodes it and reconstructs it\n",
    "        # from the encoding\n",
    "        z_mean, z_log_var, encoded_repr = self.encoder(img)\n",
    "        img_reconst = self.decoder(encoded_repr)\n",
    "\n",
    "        self.vae = Model(img, img_reconst)\n",
    "        \n",
    "        def vae_loss(inputs, outputs):\n",
    "            # VAE loss = mse_loss or xent_loss + kl_loss\n",
    "            if True:\n",
    "                reconst_loss = self.input_dim * objectives.mse(K.flatten(inputs), K.flatten(outputs))\n",
    "            else:\n",
    "                reconst_loss = self.input_dim * objectives.binary_crossentropy(K.flatten(inputs), K.flatten(outputs))\n",
    "            kl_loss = -0.5 * K.sum(1 + z_log_var - K.square(z_mean) - K.exp(z_log_var))\n",
    "            return K.mean(reconst_loss + kl_loss)\n",
    "        \n",
    "        self.vae.compile(optimizer='adam', loss=vae_loss)\n",
    "\n",
    "\n",
    "    def build_encoder(self):\n",
    "        def sampling(args):\n",
    "            \"\"\"Reparameterization trick by sampling from an isotropic unit Gaussian.\n",
    "            # Arguments:\n",
    "                args (tensor): mean and log of variance of Q(z|X)\n",
    "            # Returns:\n",
    "                z (tensor): sampled latent vector\n",
    "            \"\"\"\n",
    "            z_mean, z_log_var = args\n",
    "            batch_size = K.shape(z_mean)[0]\n",
    "            latent_dim = K.int_shape(z_mean)[1]\n",
    "            epsilon = K.random_normal(shape=(batch_size, latent_dim))\n",
    "            return z_mean + K.exp(0.5 * z_log_var) * epsilon\n",
    "    \n",
    "        # Encoder\n",
    "        inputs = Input(shape=self.input_shape)\n",
    "        x = QRNN(128, return_sequences=True, stride=1, dropout=0.)(inputs)\n",
    "        x = Dropout(0.5)(x)\n",
    "        x = QRNN(256, stride=1, dropout=0.)(x)\n",
    "#         x_f = QRNN(256)(x)  \n",
    "#         x_b = QRNN(256, go_backwards=True)(x)\n",
    "#         x = concatenate([x_f, x_b])\n",
    "        x = Dropout(0.5)(x)\n",
    "        z_mean = Dense(self.latent_dim)(x)\n",
    "        z_log_var = Dense(self.latent_dim)(x)\n",
    "\n",
    "        # use reparameterization trick to push the sampling out as input\n",
    "        # note that \"output_shape\" isn't necessary with the TensorFlow backend\n",
    "        z = Lambda(sampling, output_shape=(self.latent_dim, ))([z_mean, z_log_var])\n",
    "\n",
    "        # instantiate encoder model\n",
    "        encoder = Model(inputs, [z_mean, z_log_var, z])\n",
    "        print(encoder.summary())\n",
    "        return encoder\n",
    "\n",
    "    \n",
    "    def build_decoder(self):\n",
    "        # Decoder\n",
    "        latent_inputs = Input(shape=(self.latent_dim, ))\n",
    "        x = RepeatVector(timesteps)(latent_inputs)\n",
    "        x = QRNN(256, return_sequences=True, stride=1, dropout=0.2)(x)\n",
    "        outputs = QRNN(input_dim, return_sequences=True)(x)\n",
    "        \n",
    "        # instantiate decoder model\n",
    "        decoder = Model(latent_inputs, outputs)\n",
    "        print(decoder.summary())\n",
    "        return decoder\n",
    "\n",
    "\n",
    "    def train(self, X_train, X_test, epochs, batch_size):\n",
    "        file_path = 'weights.h5'\n",
    "        checkpoint = ModelCheckpoint(file_path, monitor='val_loss', verbose=1,\n",
    "                                     save_best_only=True, mode='min')\n",
    "        early = EarlyStopping(monitor='val_loss', mode='min', patience=5)\n",
    "\n",
    "        self.vae.fit(X_train, X_train,\n",
    "                     epochs=epochs,\n",
    "                     batch_size=batch_size,\n",
    "                     validation_data=(X_test, X_test),\n",
    "                     callbacks=[checkpoint, early])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 734
    },
    "colab_type": "code",
    "id": "186kaa_a2zUQ",
    "outputId": "929498e2-7dc5-4f2a-f570-c024eb6d0c47"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_10 (InputLayer)           (None, 28, 28)       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "qrnn_14 (QRNN)                  (None, 28, 128)      21888       input_10[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)             (None, 28, 128)      0           qrnn_14[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "qrnn_15 (QRNN)                  (None, 256)          197376      dropout_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_5 (Dropout)             (None, 256)          0           qrnn_15[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_5 (Dense)                 (None, 2)            514         dropout_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_6 (Dense)                 (None, 2)            514         dropout_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_3 (Lambda)               (None, 2)            0           dense_5[0][0]                    \n",
      "                                                                 dense_6[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 220,292\n",
      "Trainable params: 220,292\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_11 (InputLayer)        (None, 2)                 0         \n",
      "_________________________________________________________________\n",
      "repeat_vector_3 (RepeatVecto (None, 28, 2)             0         \n",
      "_________________________________________________________________\n",
      "qrnn_16 (QRNN)               (None, 28, 256)           3840      \n",
      "_________________________________________________________________\n",
      "qrnn_17 (QRNN)               (None, 28, 28)            43092     \n",
      "=================================================================\n",
      "Total params: 46,932\n",
      "Trainable params: 46,932\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "input_dim = 28\n",
    "timesteps = 28\n",
    "epochs = 5\n",
    "batch_size = 128\n",
    "\n",
    "model = qrnn_vae(input_dim, timesteps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 394
    },
    "colab_type": "code",
    "id": "f166Eluu3Ial",
    "outputId": "edc53cad-60f0-4d76-ab6d-2de350323dfe"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/5\n",
      "60000/60000 [==============================] - 52s 864us/step - loss: 2.2369 - val_loss: 2.1717\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 2.17171, saving model to weights.h5\n",
      "Epoch 2/5\n",
      "60000/60000 [==============================] - 50s 841us/step - loss: 2.1337 - val_loss: 2.1563\n",
      "\n",
      "Epoch 00002: val_loss improved from 2.17171 to 2.15629, saving model to weights.h5\n",
      "Epoch 3/5\n",
      "60000/60000 [==============================] - 50s 828us/step - loss: 2.1298 - val_loss: 2.1521\n",
      "\n",
      "Epoch 00003: val_loss improved from 2.15629 to 2.15212, saving model to weights.h5\n",
      "Epoch 4/5\n",
      "60000/60000 [==============================] - 50s 835us/step - loss: 2.1270 - val_loss: 2.1619\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 2.15212\n",
      "Epoch 5/5\n",
      "60000/60000 [==============================] - 50s 826us/step - loss: 2.1242 - val_loss: 2.1602\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 2.15212\n"
     ]
    }
   ],
   "source": [
    "model.train(X_train, X_test, epochs, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 201
    },
    "colab_type": "code",
    "id": "qesjNuB238A3",
    "outputId": "612abbed-0073-4bc9-959c-9cee6c8838d8"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAW8AAAC4CAYAAAAscG03AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fa496decb70>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# test image\n",
    "img = X_test[19].reshape(1, 28, 28)\n",
    "_, _, z_sample = model.encoder.predict(img)\n",
    "x_decoded = model.decoder.predict(z_sample)\n",
    "\n",
    "plt.figure()\n",
    "plt.subplot(121)\n",
    "plt.imshow(img.reshape(28, 28), cmap='gray')\n",
    "plt.axis('off')\n",
    "plt.subplot(122)\n",
    "plt.imshow(x_decoded.reshape(28, 28), cmap='gray')\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 265
    },
    "colab_type": "code",
    "id": "ucDa3ypODwSc",
    "outputId": "e17985b4-ded8-48c4-84c8-4feea85920ab"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPoAAAD4CAYAAADFJPs2AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fa48febeac8>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# random sample\n",
    "z_sample = np.array([[0., 0.5]])\n",
    "x_decoded = model.decoder.predict(z_sample)\n",
    "\n",
    "plt.figure()\n",
    "plt.imshow(x_decoded.reshape(28, 28), cmap='gray')\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pXFvMfi_fkgn"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "keras_qrnn.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
