{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"pytorch_distilbert_sentiment.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.4"},"widgets":{"application/vnd.jupyter.widget-state+json":{"b642648b49a8456ea033ed1d9338a133":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_183f12add9bf47bcb72d1f48773dd054","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_da9777c8ad1a4017ac693fc93a985483","IPY_MODEL_55c2a342c3214804be2b78ac44af97b6"]}},"183f12add9bf47bcb72d1f48773dd054":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"da9777c8ad1a4017ac693fc93a985483":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_38d30f17d5b0496f950538f0b6f661ce","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":213450,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":213450,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_c8f03434e8f140dc92f8a63383a80ead"}},"55c2a342c3214804be2b78ac44af97b6":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_a6d9c907124b4e37b2f3282560303f56","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 213k/213k [00:02&lt;00:00, 88.4kB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_ec86d04ef54e4922987c08f13b4e06aa"}},"38d30f17d5b0496f950538f0b6f661ce":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"c8f03434e8f140dc92f8a63383a80ead":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"a6d9c907124b4e37b2f3282560303f56":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"ec86d04ef54e4922987c08f13b4e06aa":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"098d4c764c984e8eb96d2b70a44cc120":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_64645a5c8b19460c91e518f56733c057","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_853af8525a36491ab780c37865e98eeb","IPY_MODEL_10b3c8bd22614961b98b1a4e891606e4"]}},"64645a5c8b19460c91e518f56733c057":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"853af8525a36491ab780c37865e98eeb":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_4049a0c5acb4433a8b130c0fc83940c5","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":29,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":29,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_7a2befcd957a4282913d82f35b65c364"}},"10b3c8bd22614961b98b1a4e891606e4":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_7b899e8a975a467687d582484d51eea8","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 29.0/29.0 [00:00&lt;00:00, 46.7B/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_6f68de530454419fa687c3564fbe0593"}},"4049a0c5acb4433a8b130c0fc83940c5":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"7a2befcd957a4282913d82f35b65c364":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"7b899e8a975a467687d582484d51eea8":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"6f68de530454419fa687c3564fbe0593":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"4465541f68a64384be7a6a585ebfd23c":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_16c188fa09c740518648114657627001","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_03d7c925a0574921bafde088be0f6d8b","IPY_MODEL_e023dc5f48b24bab8e3d0cd9fe3e236d"]}},"16c188fa09c740518648114657627001":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"03d7c925a0574921bafde088be0f6d8b":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_476c0152cf5b44b0899737332e2ef722","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":435797,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":435797,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_560689064c624b59875ad5bdb9cece48"}},"e023dc5f48b24bab8e3d0cd9fe3e236d":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_682e88183df34cb3989937cdb6c3b4ee","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 436k/436k [00:00&lt;00:00, 996kB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_755ca6fa7d884b8d8fdcafbc73dcb2ef"}},"476c0152cf5b44b0899737332e2ef722":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"560689064c624b59875ad5bdb9cece48":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"682e88183df34cb3989937cdb6c3b4ee":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"755ca6fa7d884b8d8fdcafbc73dcb2ef":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"834e3ba2a8344ccd912a1344e8c465e3":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_bcd21bcf025a44b8b5726c1c7f8a309c","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_9ce5e083d184465aa1e0671b10854d83","IPY_MODEL_565b086da94643d0b989c250715428bf"]}},"bcd21bcf025a44b8b5726c1c7f8a309c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"9ce5e083d184465aa1e0671b10854d83":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_0e9c0ea175fc40eabc9dbd201ce1d779","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":411,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":411,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_3460b997ad454c58a780e782120b4b18"}},"565b086da94643d0b989c250715428bf":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_f7e36eff29bb48c7b5f14f7d72982880","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 411/411 [00:10&lt;00:00, 39.0B/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_a02d75a178804f7ca244a74c2d825fe0"}},"0e9c0ea175fc40eabc9dbd201ce1d779":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"3460b997ad454c58a780e782120b4b18":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"f7e36eff29bb48c7b5f14f7d72982880":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"a02d75a178804f7ca244a74c2d825fe0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"f146e1de9bcd42cfb2344c3ef7794def":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_4ee5f5661e524edcbc8f8239f411c717","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_deaffc71a0ee426c89b3033696b7196e","IPY_MODEL_22d9019e27ff48b3895b8edc7d792c39"]}},"4ee5f5661e524edcbc8f8239f411c717":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"deaffc71a0ee426c89b3033696b7196e":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_495da80868744b2ab58a5032201073a9","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":263273408,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":263273408,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_6b53d52aa4cf4e3ca5055f5f263669b0"}},"22d9019e27ff48b3895b8edc7d792c39":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_91956175e9e3430696bfa964aea14088","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 263M/263M [00:09&lt;00:00, 27.0MB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_4591691af16d49c19f31ebbc010bea47"}},"495da80868744b2ab58a5032201073a9":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"6b53d52aa4cf4e3ca5055f5f263669b0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"91956175e9e3430696bfa964aea14088":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"4591691af16d49c19f31ebbc010bea47":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}}}},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"vQUlhd9D9fgu"},"source":["# Text Classification"]},{"cell_type":"code","metadata":{"id":"9yEPdr7V-hFp","scrolled":true,"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1621499450710,"user_tz":-480,"elapsed":10137,"user":{"displayName":"Kok Meng Tan","photoUrl":"","userId":"03184747090436452828"}},"outputId":"48c51fc9-4d8b-488d-ace3-764dbd9f37a1"},"source":["!pip install transformers"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Collecting transformers\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/b0/9e/5b80becd952d5f7250eaf8fc64b957077b12ccfe73e9c03d37146ab29712/transformers-4.6.0-py3-none-any.whl (2.3MB)\n","\u001b[K     |████████████████████████████████| 2.3MB 5.9MB/s \n","\u001b[?25hCollecting sacremoses\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/75/ee/67241dc87f266093c533a2d4d3d69438e57d7a90abb216fa076e7d475d4a/sacremoses-0.0.45-py3-none-any.whl (895kB)\n","\u001b[K     |████████████████████████████████| 901kB 33.4MB/s \n","\u001b[?25hCollecting tokenizers<0.11,>=0.10.1\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ae/04/5b870f26a858552025a62f1649c20d29d2672c02ff3c3fb4c688ca46467a/tokenizers-0.10.2-cp37-cp37m-manylinux2010_x86_64.whl (3.3MB)\n","\u001b[K     |████████████████████████████████| 3.3MB 35.8MB/s \n","\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.0.12)\n","Collecting huggingface-hub==0.0.8\n","  Downloading https://files.pythonhosted.org/packages/a1/88/7b1e45720ecf59c6c6737ff332f41c955963090a18e72acbcbeac6b25e86/huggingface_hub-0.0.8-py3-none-any.whl\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.41.1)\n","Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from transformers) (4.0.1)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers) (20.9)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.0.1)\n","Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (8.0.0)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2020.12.5)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n","Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.7.4.3)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.4.1)\n","Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers) (2.4.7)\n","Installing collected packages: sacremoses, tokenizers, huggingface-hub, transformers\n","Successfully installed huggingface-hub-0.0.8 sacremoses-0.0.45 tokenizers-0.10.2 transformers-4.6.0\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"vMn7kxCI-j8_","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1621499575173,"user_tz":-480,"elapsed":32336,"user":{"displayName":"Kok Meng Tan","photoUrl":"","userId":"03184747090436452828"}},"outputId":"f8e2fdd0-bcb3-40ea-b8a8-70453ffef35d"},"source":["from google.colab import drive\n","drive.mount(\"/content/drive\")"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"Ecq_gi8Z-sPj"},"source":["## Main"]},{"cell_type":"code","metadata":{"id":"wuMlXT80GAMK"},"source":["import time\n","\n","import numpy as np\n","import pandas as pd\n","import torch\n","from torch.utils.data import Dataset, DataLoader\n","from transformers import (\n","    DistilBertModel,\n","    DistilBertTokenizer,\n","    DistilBertForSequenceClassification,\n","    AlbertTokenizer,\n","    AlbertForSequenceClassification,\n",")\n","from sklearn import metrics\n","from sklearn.model_selection import train_test_split"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"4bNCYD92-egB","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1621499641546,"user_tz":-480,"elapsed":1429,"user":{"displayName":"Kok Meng Tan","photoUrl":"","userId":"03184747090436452828"}},"outputId":"cc2b0e9c-baf7-40ba-b945-b4359cae5ab8"},"source":["print(f\"Pytorch Version: {torch.__version__}\")\n","\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","print(f\"Device: {device}\")\n","if torch.cuda.device_count() > 0:\n","    print(f\"Found GPU at: {torch.cuda.get_device_name(0)}\")\n","\n","DIRNAME = \"drive/My Drive/Colab Notebooks/\""],"execution_count":null,"outputs":[{"output_type":"stream","text":["Pytorch Version: 1.8.1+cu101\n","Device: cuda\n","Found GPU at: Tesla K80\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"05Z5M_dX9fg7"},"source":["## Load data"]},{"cell_type":"code","metadata":{"id":"r1XBjyGn9fg8","colab":{"base_uri":"https://localhost:8080/","height":221},"executionInfo":{"status":"ok","timestamp":1621499647002,"user_tz":-480,"elapsed":3144,"user":{"displayName":"Kok Meng Tan","photoUrl":"","userId":"03184747090436452828"}},"outputId":"130bd408-f3b9-4456-d6ac-ddc2b8284c72"},"source":["data = pd.read_csv(DIRNAME + \"data/financial_sentiment/adhoc_sentences.tsv\", sep=\"\\t\")\n","data[\"sentence\"] = data[\"sentence\"].str.strip()  # strip trailing space\n","print(data.shape)\n","data.head()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["(1000, 2)\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>sentence</th>\n","      <th>sentiment</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>In several projects the technical complexity h...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>To return to profitability in this environment...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>Investment advisory fees are expected to drop ...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>The designated sponsor agreement with the BHF ...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>In addition, due to the persistence of the poo...</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                                            sentence  sentiment\n","0  In several projects the technical complexity h...          0\n","1  To return to profitability in this environment...          0\n","2  Investment advisory fees are expected to drop ...          1\n","3  The designated sponsor agreement with the BHF ...          0\n","4  In addition, due to the persistence of the poo...          0"]},"metadata":{"tags":[]},"execution_count":5}]},{"cell_type":"code","metadata":{"id":"JrBr2YesGdO_"},"source":["class CFG:\n","    \"\"\"Configuration.\"\"\"\n","    max_len = 256\n","    batch_size = 8\n","    epochs = 10\n","    lr = 5e-6  # 1e-5\n","    patience = 5\n","    n_classes = 2\n","    finetuned_model_path = DIRNAME + \"models/finetuned_distilbert_fin.bin\"\n","    # finetuned_model_path = DIRNAME + \"models/finetuned_albert_fin.bin\"\n","    # finetuned_model_path = DIRNAME + \"models/finetuned_albert_large_fin.bin\"\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ggaiyve39fhA"},"source":["### Preparing the Dataset and Dataloader"]},{"cell_type":"code","metadata":{"id":"QGn9lJZfqksR","colab":{"base_uri":"https://localhost:8080/","height":164,"referenced_widgets":["b642648b49a8456ea033ed1d9338a133","183f12add9bf47bcb72d1f48773dd054","da9777c8ad1a4017ac693fc93a985483","55c2a342c3214804be2b78ac44af97b6","38d30f17d5b0496f950538f0b6f661ce","c8f03434e8f140dc92f8a63383a80ead","a6d9c907124b4e37b2f3282560303f56","ec86d04ef54e4922987c08f13b4e06aa","098d4c764c984e8eb96d2b70a44cc120","64645a5c8b19460c91e518f56733c057","853af8525a36491ab780c37865e98eeb","10b3c8bd22614961b98b1a4e891606e4","4049a0c5acb4433a8b130c0fc83940c5","7a2befcd957a4282913d82f35b65c364","7b899e8a975a467687d582484d51eea8","6f68de530454419fa687c3564fbe0593","4465541f68a64384be7a6a585ebfd23c","16c188fa09c740518648114657627001","03d7c925a0574921bafde088be0f6d8b","e023dc5f48b24bab8e3d0cd9fe3e236d","476c0152cf5b44b0899737332e2ef722","560689064c624b59875ad5bdb9cece48","682e88183df34cb3989937cdb6c3b4ee","755ca6fa7d884b8d8fdcafbc73dcb2ef"]},"executionInfo":{"status":"ok","timestamp":1621499652119,"user_tz":-480,"elapsed":4344,"user":{"displayName":"Kok Meng Tan","photoUrl":"","userId":"03184747090436452828"}},"outputId":"aabaf077-d74a-4bc6-dd6c-095e7f47f0ca"},"source":["tokenizer = DistilBertTokenizer.from_pretrained(\"distilbert-base-cased\")\n","\n","# tokenizer = AlbertTokenizer.from_pretrained(\"albert-base-v2\")\n","\n","# tokenizer = AlbertTokenizer.from_pretrained(\"albert-large-v2\")"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"b642648b49a8456ea033ed1d9338a133","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=213450.0, style=ProgressStyle(descripti…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"098d4c764c984e8eb96d2b70a44cc120","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=29.0, style=ProgressStyle(description_w…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"4465541f68a64384be7a6a585ebfd23c","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=435797.0, style=ProgressStyle(descripti…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"2vX7kzaAHu39"},"source":["class TextDataset(Dataset):\n","    def __init__(self, data, tokenizer, max_len, labels=None):\n","        self.len = len(data)\n","        self.data = data\n","        self.labels = labels\n","        self.tokenizer = tokenizer\n","        self.max_len = max_len\n","        \n","    def __getitem__(self, index):\n","        sentence = self.data[index]\n","        inputs = self.tokenizer.encode_plus(\n","            sentence,\n","            None,\n","            add_special_tokens=True,\n","            truncation=True,\n","            max_length=self.max_len,\n","            padding=\"max_length\",            \n","            return_token_type_ids=True,\n","        )\n","\n","        output = {\n","            \"ids\": torch.tensor(inputs[\"input_ids\"], dtype=torch.long),\n","            \"mask\": torch.tensor(inputs[\"attention_mask\"], dtype=torch.long),\n","        }\n","        if self.labels is not None:\n","            output[\"targets\"] = torch.tensor(self.labels[index], dtype=torch.long)\n","        return output\n","    \n","    def __len__(self):\n","        return self.len\n","    "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"KUqk4uUOC-SB","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1621499652121,"user_tz":-480,"elapsed":2521,"user":{"displayName":"Kok Meng Tan","photoUrl":"","userId":"03184747090436452828"}},"outputId":"12ce587c-ec2d-468d-b960-6001913acb26"},"source":["train_df, valid_df = train_test_split(data, test_size=0.2, random_state=0)\n","\n","print(f\"Train Dataset: {train_df.shape}\")\n","print(f\"Valid Dataset: {valid_df.shape}\")"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Train Dataset: (800, 2)\n","Valid Dataset: (200, 2)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"l1BgA1CkQSYa"},"source":["train_data = TextDataset(\n","    train_df[\"sentence\"].tolist(), tokenizer, CFG.max_len, labels=train_df[\"sentiment\"].tolist())\n","train_loader = DataLoader(\n","    train_data, batch_size=CFG.batch_size, shuffle=True, num_workers=0)\n","\n","valid_data = TextDataset(\n","    valid_df[\"sentence\"].tolist(), tokenizer, CFG.max_len, labels=valid_df[\"sentiment\"].tolist())\n","valid_loader = DataLoader(\n","    valid_data, batch_size=CFG.batch_size, shuffle=False, num_workers=0)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"7XEVIV9u9fhU"},"source":["### Model\n","\n"," - We will be creating a neural network with the `DistillBERTClass`. \n"," - This network will have the DistilBERT Language model followed by a `dropout` and finally a `Linear` layer to obtain the final outputs. \n"," - The data will be fed to the DistilBERT Language model as defined in the dataset. \n"," - Final layer outputs is what will be compared to the `encoded category` to determine the accuracy of models prediction. \n"," - We will initiate an instance of the network called `model`. This instance will be used for training and then to save the final trained model for future inference."]},{"cell_type":"code","metadata":{"id":"rC_h5xS69fhV"},"source":["# # Creating the customized model, by adding a drop out and a dense layer on top of distil bert to get the final output for the model. \n","\n","# class DistillBERTClass(torch.nn.Module):\n","#     def __init__(self):\n","#         super(DistillBERTClass, self).__init__()\n","#         self.l1 = DistilBertModel.from_pretrained(\"distilbert-base-cased\")\n","#         self.l2 = torch.nn.Dropout(0.3)\n","#         self.l3 = torch.nn.Linear(768, 1)\n","    \n","#     def forward(self, ids, mask):\n","#         output_1 = self.l1(ids, mask)\n","#         output_2 = self.l2(output_1[0])\n","#         output = self.l3(output_2)\n","#         return output"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"xlNnKY6T9fhZ","colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["834e3ba2a8344ccd912a1344e8c465e3","bcd21bcf025a44b8b5726c1c7f8a309c","9ce5e083d184465aa1e0671b10854d83","565b086da94643d0b989c250715428bf","0e9c0ea175fc40eabc9dbd201ce1d779","3460b997ad454c58a780e782120b4b18","f7e36eff29bb48c7b5f14f7d72982880","a02d75a178804f7ca244a74c2d825fe0","f146e1de9bcd42cfb2344c3ef7794def","4ee5f5661e524edcbc8f8239f411c717","deaffc71a0ee426c89b3033696b7196e","22d9019e27ff48b3895b8edc7d792c39","495da80868744b2ab58a5032201073a9","6b53d52aa4cf4e3ca5055f5f263669b0","91956175e9e3430696bfa964aea14088","4591691af16d49c19f31ebbc010bea47"]},"executionInfo":{"status":"ok","timestamp":1621499677615,"user_tz":-480,"elapsed":21718,"user":{"displayName":"Kok Meng Tan","photoUrl":"","userId":"03184747090436452828"}},"outputId":"4b0953c6-4100-4dd7-f8a5-121941d0ed7a"},"source":["model = DistilBertForSequenceClassification.from_pretrained(\n","    \"distilbert-base-cased\", num_labels=CFG.n_classes)\n","\n","# model = AlbertForSequenceClassification.from_pretrained(\n","#     \"albert-base-v2\", num_labels=CFG.n_classes)\n","\n","# model = AlbertForSequenceClassification.from_pretrained(\n","#     \"albert-large-v2\", num_labels=CFG.n_classes)\n","\n","model.to(device)"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"834e3ba2a8344ccd912a1344e8c465e3","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=411.0, style=ProgressStyle(description_…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"f146e1de9bcd42cfb2344c3ef7794def","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=263273408.0, style=ProgressStyle(descri…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"},{"output_type":"stream","text":["Some weights of the model checkpoint at distilbert-base-cased were not used when initializing DistilBertForSequenceClassification: ['vocab_layer_norm.bias', 'vocab_transform.weight', 'vocab_projector.weight', 'vocab_layer_norm.weight', 'vocab_projector.bias', 'vocab_transform.bias']\n","- This IS expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-cased and are newly initialized: ['classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight', 'classifier.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"],"name":"stderr"},{"output_type":"execute_result","data":{"text/plain":["DistilBertForSequenceClassification(\n","  (distilbert): DistilBertModel(\n","    (embeddings): Embeddings(\n","      (word_embeddings): Embedding(28996, 768, padding_idx=0)\n","      (position_embeddings): Embedding(512, 768)\n","      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","      (dropout): Dropout(p=0.1, inplace=False)\n","    )\n","    (transformer): Transformer(\n","      (layer): ModuleList(\n","        (0): TransformerBlock(\n","          (attention): MultiHeadSelfAttention(\n","            (dropout): Dropout(p=0.1, inplace=False)\n","            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n","            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n","            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n","            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n","          )\n","          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","          (ffn): FFN(\n","            (dropout): Dropout(p=0.1, inplace=False)\n","            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n","            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n","          )\n","          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","        )\n","        (1): TransformerBlock(\n","          (attention): MultiHeadSelfAttention(\n","            (dropout): Dropout(p=0.1, inplace=False)\n","            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n","            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n","            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n","            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n","          )\n","          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","          (ffn): FFN(\n","            (dropout): Dropout(p=0.1, inplace=False)\n","            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n","            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n","          )\n","          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","        )\n","        (2): TransformerBlock(\n","          (attention): MultiHeadSelfAttention(\n","            (dropout): Dropout(p=0.1, inplace=False)\n","            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n","            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n","            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n","            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n","          )\n","          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","          (ffn): FFN(\n","            (dropout): Dropout(p=0.1, inplace=False)\n","            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n","            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n","          )\n","          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","        )\n","        (3): TransformerBlock(\n","          (attention): MultiHeadSelfAttention(\n","            (dropout): Dropout(p=0.1, inplace=False)\n","            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n","            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n","            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n","            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n","          )\n","          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","          (ffn): FFN(\n","            (dropout): Dropout(p=0.1, inplace=False)\n","            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n","            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n","          )\n","          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","        )\n","        (4): TransformerBlock(\n","          (attention): MultiHeadSelfAttention(\n","            (dropout): Dropout(p=0.1, inplace=False)\n","            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n","            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n","            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n","            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n","          )\n","          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","          (ffn): FFN(\n","            (dropout): Dropout(p=0.1, inplace=False)\n","            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n","            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n","          )\n","          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","        )\n","        (5): TransformerBlock(\n","          (attention): MultiHeadSelfAttention(\n","            (dropout): Dropout(p=0.1, inplace=False)\n","            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n","            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n","            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n","            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n","          )\n","          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","          (ffn): FFN(\n","            (dropout): Dropout(p=0.1, inplace=False)\n","            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n","            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n","          )\n","          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","        )\n","      )\n","    )\n","  )\n","  (pre_classifier): Linear(in_features=768, out_features=768, bias=True)\n","  (classifier): Linear(in_features=768, out_features=2, bias=True)\n","  (dropout): Dropout(p=0.2, inplace=False)\n",")"]},"metadata":{"tags":[]},"execution_count":11}]},{"cell_type":"code","metadata":{"id":"pl5qdxD69fhc"},"source":["# param_optimizer = list(model.named_parameters())\n","# no_decay = [\"bias\", \"LayerNorm.bias\", \"LayerNorm.weight\"]\n","# optimizer_grouped_parameters = [\n","#     {\"params\": [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)],\n","#      \"weight_decay\": 0.01},\n","#     {\"params\": [p for n, p in param_optimizer if any(nd in n for nd in no_decay)],\n","#      \"weight_decay\":0.0}\n","# ]\n","# optimizer = AdamW(optimizer_grouped_parameters, lr=3e-5)\n","\n","# total_steps = len(train_data_loader) * EPOCHS\n","\n","# scheduler = get_linear_schedule_with_warmup(\n","#   optimizer,\n","#   num_warmup_steps=0,\n","#   num_training_steps=total_steps\n","# )"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"SsyhcM9Y9fhg"},"source":["## Fine Tuning the Model"]},{"cell_type":"code","metadata":{"id":"SvXA_orKB_19"},"source":["def train_fn(cfg, model, train_loader, valid_loader, device):\n","    \"\"\"Train function.\"\"\"\n","    optimizer = torch.optim.Adam(model.parameters(), lr=cfg.lr)\n","    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n","        optimizer, \"min\", factor=0.5, patience=2, verbose=True, eps=1e-6)\n","    \n","    best_loss = np.inf\n","    counter = 0\n","\n","    for epoch in range(cfg.epochs):\n","\n","        start_time = time.time()\n","\n","        model.train()\n","        train_loss = 0.\n","        y_train = list()\n","        pred_train = list()\n","\n","        optimizer.zero_grad()\n","\n","        for data in train_loader:\n","            ids = data[\"ids\"].to(device)\n","            mask = data[\"mask\"].to(device)\n","            targets = data[\"targets\"].to(device)\n","\n","            outputs = model(ids, attention_mask=mask, labels=targets)\n","            loss, logits = outputs[:2]\n","\n","            loss.backward()\n","            optimizer.step()\n","            optimizer.zero_grad()\n","\n","            train_loss += loss.item() / len(train_loader)\n","\n","            y_train.append(targets.cpu().numpy())\n","            pred_train.append(logits.detach().cpu().numpy().argmax(axis=1))\n","\n","        y_train = np.concatenate(y_train)\n","        pred_train = np.concatenate(pred_train)\n","        train_acc = metrics.accuracy_score(y_train, pred_train)\n","\n","        model.eval()\n","        valid_loss = 0.\n","        y_valid = list()\n","        pred_valid = list()\n","\n","        for data in valid_loader:\n","            ids = data[\"ids\"].to(device)\n","            mask = data[\"mask\"].to(device)\n","            targets = data[\"targets\"].to(device)\n","\n","            with torch.no_grad():\n","                outputs = model(ids, attention_mask=mask, labels=targets)\n","                loss, logits = outputs[:2]\n","\n","            valid_loss += loss.item() / len(valid_loader)\n","\n","            y_valid.append(targets.cpu().numpy())\n","            pred_valid.append(logits.cpu().numpy().argmax(axis=1))\n","\n","        scheduler.step(valid_loss)\n","\n","        y_valid = np.concatenate(y_valid)\n","        pred_valid = np.concatenate(pred_valid)\n","        valid_acc = metrics.accuracy_score(y_valid, pred_valid)\n","\n","        print(f\"Epoch {epoch + 1}/{cfg.epochs}: elapsed time: {time.time() - start_time:.0f}s\\n\"\n","              f\"  loss: {train_loss:.4f}  train_acc: {train_acc:.4f}\"\n","              f\" - valid_loss: {valid_loss:.4f}  valid_acc: {valid_acc:.4f}\")\n","\n","        if valid_loss < best_loss:\n","            print(f\"Epoch {epoch + 1}: valid_loss improved from {best_loss:.5f} to {valid_loss:.5f}, \"\n","                  f\"saving model to {cfg.finetuned_model_path}\")\n","            best_loss = valid_loss\n","            counter = 0\n","            torch.save(model.state_dict(), cfg.finetuned_model_path)\n","        else:\n","            print(f\"Epoch {epoch + 1}: valid_loss did not improve from {best_loss:.5f}\")\n","            counter += 1\n","            if counter == cfg.patience:\n","                break"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"87WcwsrECHHD","executionInfo":{"status":"ok","timestamp":1621502160104,"user_tz":-480,"elapsed":246741,"user":{"displayName":"Kok Meng Tan","photoUrl":"","userId":"03184747090436452828"}},"outputId":"19c3689d-cfaf-4bcf-9f68-fedcf9d1e1f0"},"source":["# Distilbert\n","train_fn(CFG, model, train_loader, valid_loader, device)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Epoch 1/10: elapsed time: 41s\n","  loss: 0.0750  train_acc: 0.9812 - valid_loss: 0.5957  valid_acc: 0.8200\n","Epoch 1: valid_loss improved from inf to 0.59572, saving model to drive/My Drive/Colab Notebooks/models/finetuned_distilbert_fin.bin\n","Epoch 2/10: elapsed time: 41s\n","  loss: 0.0494  train_acc: 0.9838 - valid_loss: 0.6405  valid_acc: 0.7850\n","Epoch 2: valid_loss did not improve from 0.59572\n","Epoch 3/10: elapsed time: 41s\n","  loss: 0.0336  train_acc: 0.9938 - valid_loss: 0.6573  valid_acc: 0.8250\n","Epoch 3: valid_loss did not improve from 0.59572\n","Epoch     4: reducing learning rate of group 0 to 2.5000e-06.\n","Epoch 4/10: elapsed time: 41s\n","  loss: 0.0327  train_acc: 0.9925 - valid_loss: 0.6632  valid_acc: 0.8400\n","Epoch 4: valid_loss did not improve from 0.59572\n","Epoch 5/10: elapsed time: 41s\n","  loss: 0.0231  train_acc: 0.9950 - valid_loss: 0.6703  valid_acc: 0.8300\n","Epoch 5: valid_loss did not improve from 0.59572\n","Epoch 6/10: elapsed time: 41s\n","  loss: 0.0237  train_acc: 0.9938 - valid_loss: 0.6835  valid_acc: 0.8400\n","Epoch 6: valid_loss did not improve from 0.59572\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"ugJl4gRJipbV","colab":{"base_uri":"https://localhost:8080/","height":561},"executionInfo":{"status":"ok","timestamp":1594885886629,"user_tz":-480,"elapsed":795666,"user":{"displayName":"Kok Meng Tan","photoUrl":"","userId":"03184747090436452828"}},"outputId":"c5e3f4fc-5e8c-4a31-f20a-63c52973b230"},"source":["# Albert large v2\n","best_loss = np.inf\n","for epoch in range(CFG.epochs):\n","    best_loss = train_step(epoch, best_loss)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Epoch 1/10: elapsed time: 79s\n","  loss: 0.6159  train_acc: 0.6750 - val_loss: 0.5092  val_acc: 0.7850\n","Epoch 1: val_loss improved from inf to 0.50921, saving model to drive/My Drive/Colab Notebooks/models/finetuned_albert_large_fin.bin\n","Epoch 2/10: elapsed time: 79s\n","  loss: 0.4908  train_acc: 0.7775 - val_loss: 0.4660  val_acc: 0.8000\n","Epoch 2: val_loss improved from 0.50921 to 0.46603, saving model to drive/My Drive/Colab Notebooks/models/finetuned_albert_large_fin.bin\n","Epoch 3/10: elapsed time: 79s\n","  loss: 0.3132  train_acc: 0.8812 - val_loss: 0.4550  val_acc: 0.8050\n","Epoch 3: val_loss improved from 0.46603 to 0.45497, saving model to drive/My Drive/Colab Notebooks/models/finetuned_albert_large_fin.bin\n","Epoch 4/10: elapsed time: 79s\n","  loss: 0.2130  train_acc: 0.9300 - val_loss: 0.4603  val_acc: 0.8200\n","Epoch 4: val_loss did not improve from 0.45497\n","Epoch 5/10: elapsed time: 79s\n","  loss: 0.1810  train_acc: 0.9375 - val_loss: 0.4797  val_acc: 0.8100\n","Epoch 5: val_loss did not improve from 0.45497\n","Epoch     6: reducing learning rate of group 0 to 2.5000e-06.\n","Epoch 6/10: elapsed time: 79s\n","  loss: 0.1662  train_acc: 0.9375 - val_loss: 0.6469  val_acc: 0.5600\n","Epoch 6: val_loss did not improve from 0.45497\n","Epoch 7/10: elapsed time: 79s\n","  loss: 0.7035  train_acc: 0.5375 - val_loss: 0.7097  val_acc: 0.4650\n","Epoch 7: val_loss did not improve from 0.45497\n","Epoch 8/10: elapsed time: 79s\n","  loss: 0.7038  train_acc: 0.4963 - val_loss: 0.7091  val_acc: 0.4200\n","Epoch 8: val_loss did not improve from 0.45497\n","Epoch     9: reducing learning rate of group 0 to 1.2500e-06.\n","Epoch 9/10: elapsed time: 79s\n","  loss: 0.7047  train_acc: 0.5062 - val_loss: 0.7013  val_acc: 0.4300\n","Epoch 9: val_loss did not improve from 0.45497\n","Epoch 10/10: elapsed time: 79s\n","  loss: 0.7100  train_acc: 0.4888 - val_loss: 0.6992  val_acc: 0.5050\n","Epoch 10: val_loss did not improve from 0.45497\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"226zBRWZ9fhn"},"source":["## Validating the Model"]},{"cell_type":"code","metadata":{"id":"nVLN8MYWmDbN","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1621411211244,"user_tz":-480,"elapsed":2248,"user":{"displayName":"Kok Meng Tan","photoUrl":"","userId":"03184747090436452828"}},"outputId":"62651eb5-4f3d-451b-f715-6c9773f84ee2"},"source":["model = DistilBertForSequenceClassification.from_pretrained(\n","    \"distilbert-base-cased\", num_labels=CFG.n_classes)\n","model.load_state_dict(torch.load(CFG.finetuned_model_path, map_location=device))\n","model.to(device)\n","model.eval()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Some weights of the model checkpoint at distilbert-base-cased were not used when initializing DistilBertForSequenceClassification: ['vocab_layer_norm.bias', 'vocab_transform.bias', 'vocab_layer_norm.weight', 'vocab_transform.weight', 'vocab_projector.weight', 'vocab_projector.bias']\n","- This IS expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-cased and are newly initialized: ['pre_classifier.bias', 'classifier.bias', 'pre_classifier.weight', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"],"name":"stderr"},{"output_type":"execute_result","data":{"text/plain":["DistilBertForSequenceClassification(\n","  (distilbert): DistilBertModel(\n","    (embeddings): Embeddings(\n","      (word_embeddings): Embedding(28996, 768, padding_idx=0)\n","      (position_embeddings): Embedding(512, 768)\n","      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","      (dropout): Dropout(p=0.1, inplace=False)\n","    )\n","    (transformer): Transformer(\n","      (layer): ModuleList(\n","        (0): TransformerBlock(\n","          (attention): MultiHeadSelfAttention(\n","            (dropout): Dropout(p=0.1, inplace=False)\n","            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n","            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n","            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n","            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n","          )\n","          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","          (ffn): FFN(\n","            (dropout): Dropout(p=0.1, inplace=False)\n","            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n","            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n","          )\n","          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","        )\n","        (1): TransformerBlock(\n","          (attention): MultiHeadSelfAttention(\n","            (dropout): Dropout(p=0.1, inplace=False)\n","            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n","            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n","            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n","            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n","          )\n","          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","          (ffn): FFN(\n","            (dropout): Dropout(p=0.1, inplace=False)\n","            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n","            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n","          )\n","          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","        )\n","        (2): TransformerBlock(\n","          (attention): MultiHeadSelfAttention(\n","            (dropout): Dropout(p=0.1, inplace=False)\n","            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n","            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n","            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n","            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n","          )\n","          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","          (ffn): FFN(\n","            (dropout): Dropout(p=0.1, inplace=False)\n","            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n","            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n","          )\n","          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","        )\n","        (3): TransformerBlock(\n","          (attention): MultiHeadSelfAttention(\n","            (dropout): Dropout(p=0.1, inplace=False)\n","            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n","            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n","            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n","            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n","          )\n","          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","          (ffn): FFN(\n","            (dropout): Dropout(p=0.1, inplace=False)\n","            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n","            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n","          )\n","          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","        )\n","        (4): TransformerBlock(\n","          (attention): MultiHeadSelfAttention(\n","            (dropout): Dropout(p=0.1, inplace=False)\n","            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n","            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n","            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n","            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n","          )\n","          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","          (ffn): FFN(\n","            (dropout): Dropout(p=0.1, inplace=False)\n","            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n","            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n","          )\n","          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","        )\n","        (5): TransformerBlock(\n","          (attention): MultiHeadSelfAttention(\n","            (dropout): Dropout(p=0.1, inplace=False)\n","            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n","            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n","            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n","            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n","          )\n","          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","          (ffn): FFN(\n","            (dropout): Dropout(p=0.1, inplace=False)\n","            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n","            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n","          )\n","          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","        )\n","      )\n","    )\n","  )\n","  (pre_classifier): Linear(in_features=768, out_features=768, bias=True)\n","  (classifier): Linear(in_features=768, out_features=2, bias=True)\n","  (dropout): Dropout(p=0.2, inplace=False)\n",")"]},"metadata":{"tags":[]},"execution_count":20}]},{"cell_type":"code","metadata":{"id":"d5QFCM6-9fho"},"source":["def evaluate(model, valid_loader):\n","    y_true = list()\n","    y_prob = list()\n","    with torch.no_grad():\n","        for  data in valid_loader:\n","            ids = data[\"ids\"].to(device)\n","            mask = data[\"mask\"].to(device)\n","            targets = data[\"targets\"].to(device)\n","            \n","            logits = model(ids, attention_mask=mask)[0]\n","            probs = torch.softmax(logits, axis=1)\n","            \n","            y_true.append(targets.cpu().numpy())\n","            y_prob.append(probs[:, 1].cpu().numpy())\n","\n","    y_true = np.concatenate(y_true)\n","    y_prob = np.concatenate(y_prob)\n","    return y_true, y_prob\n","\n","\n","def compute_metrics(y_true, y_prob):\n","    \"\"\"Compute metrics.\"\"\"\n","    y_pred = (y_prob > 0.5).astype(int)\n","\n","    acc = metrics.accuracy_score(y_true, y_pred)\n","    roc_auc = metrics.roc_auc_score(y_true, y_prob)\n","    avg_prc = metrics.average_precision_score(y_true, y_prob)\n","    print(f\"  Accuracy          = {acc:.4f}\")\n","    print(f\"  ROC AUC           = {roc_auc:.4f}\")\n","    print(f\"  Average precision = {avg_prc:.4f}\\n\")\n","    print(metrics.classification_report(y_true, y_pred, digits=4))\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"NkbQZa0enU0P","colab":{"base_uri":"https://localhost:8080/","height":238},"executionInfo":{"status":"ok","timestamp":1594886038655,"user_tz":-480,"elapsed":1105,"user":{"displayName":"Kok Meng Tan","photoUrl":"","userId":"03184747090436452828"}},"outputId":"53d88848-8f37-46fb-8658-82fbc337367f"},"source":["# Albert large v2\n","\n","y_true, y_prob = evaluate(model, valid_loader)\n","compute_metrics(y_true, y_prob)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["  Accuracy          = 0.8050\n","  ROC AUC           = 0.8785\n","  Average precision = 0.8751\n","\n","              precision    recall  f1-score   support\n","\n","           0     0.8119    0.8039    0.8079       102\n","           1     0.7980    0.8061    0.8020        98\n","\n","    accuracy                         0.8050       200\n","   macro avg     0.8049    0.8050    0.8050       200\n","weighted avg     0.8051    0.8050    0.8050       200\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"RKYxjThAqks6","colab":{"base_uri":"https://localhost:8080/","height":238},"executionInfo":{"status":"ok","timestamp":1594884618404,"user_tz":-480,"elapsed":4651,"user":{"displayName":"Kok Meng Tan","photoUrl":"","userId":"03184747090436452828"}},"outputId":"b98c7329-320f-46ed-af4a-c8e911364db1"},"source":["# Albert v2\n","\n","y_true, y_prob = evaluate(model, valid_loader)\n","compute_metrics(y_true, y_prob)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["  Accuracy          = 0.7950\n","  ROC AUC           = 0.8919\n","  Average precision = 0.8692\n","\n","              precision    recall  f1-score   support\n","\n","           0     0.8211    0.7647    0.7919       102\n","           1     0.7714    0.8265    0.7980        98\n","\n","    accuracy                         0.7950       200\n","   macro avg     0.7962    0.7956    0.7950       200\n","weighted avg     0.7967    0.7950    0.7949       200\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HV3ANCZKlAqb","executionInfo":{"status":"ok","timestamp":1621411237019,"user_tz":-480,"elapsed":2420,"user":{"displayName":"Kok Meng Tan","photoUrl":"","userId":"03184747090436452828"}},"outputId":"ca0b153c-599e-454f-9391-e0c771b1b644"},"source":["# Distilbert\n","\n","y_true, y_prob = evaluate(model, valid_loader)\n","compute_metrics(y_true, y_prob)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["  Accuracy          = 0.8600\n","  ROC AUC           = 0.9120\n","  Average precision = 0.9103\n","\n","              precision    recall  f1-score   support\n","\n","           0     0.8854    0.8333    0.8586       102\n","           1     0.8365    0.8878    0.8614        98\n","\n","    accuracy                         0.8600       200\n","   macro avg     0.8610    0.8605    0.8600       200\n","weighted avg     0.8615    0.8600    0.8600       200\n","\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"017pklSy9fhv"},"source":["### Saving the Trained Model Artifacts for inference"]},{"cell_type":"code","metadata":{"id":"s8Oe7IOj9fhv","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1594789935086,"user_tz":-480,"elapsed":6992,"user":{"displayName":"Kok Meng Tan","photoUrl":"","userId":"03184747090436452828"}},"outputId":"33a6a620-7760-4588-db2e-d65ee4e71183"},"source":["output_model_file = DIRNAME + \"models/pytorch_distilbert_news.bin\"\n","output_vocab_file = DIRNAME + \"models/vocab_distilbert_news.bin\"\n","\n","torch.save(model, output_model_file)\n","tokenizer.save_vocabulary(output_vocab_file)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["('drive/My Drive/Colab Notebooks/models/vocab_distilbert_news.bin',)"]},"metadata":{"tags":[]},"execution_count":57}]},{"cell_type":"code","metadata":{"id":"ZYY1_K67tSkX"},"source":["torch.save(model.state_dict(), DIRNAME + \"models/pytorch_distilbert_news2.bin\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"sexTxTM1qktG"},"source":[""],"execution_count":null,"outputs":[]}]}