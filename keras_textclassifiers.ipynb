{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "keras_textclassifiers.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.8"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "LvYaPYrn0S5n"
      },
      "source": [
        "# Doc classification\n",
        "\n",
        "* CNN\n",
        "* Bidirectional LSTM\n",
        "* Attention Bidirectional GRU\n",
        "* Hierarchical LSTM\n",
        "* Hierarchical Attention Networks"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "-9Xzhx9rvN13",
        "outputId": "49b94bb0-ba74-452e-d97b-054999045aa7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "import tensorflow as tf\n",
        "device_name = tf.test.gpu_device_name()\n",
        "if device_name != '/device:GPU:0':\n",
        "    raise SystemError('GPU device not found')\n",
        "print('Found GPU at: {}'.format(device_name))\n",
        "print('TensorFlow Version: {}'.format(tf.__version__))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found GPU at: /device:GPU:0\n",
            "TensorFlow Version: 2.2.0-rc3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "KGmO4EWb0S5p",
        "outputId": "b4e2a1e3-eebb-4a93-dda8-67004c572234",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "import re\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "from keras.datasets import imdb\n",
        "from keras.preprocessing.text import Tokenizer, text_to_word_sequence\n",
        "from keras.preprocessing.sequence import pad_sequences, sequence\n",
        "from keras.utils.np_utils import to_categorical\n",
        "from keras.models import Model\n",
        "from keras.layers import (\n",
        "    Embedding, Dense, Input, Flatten,\n",
        "    Conv1D, MaxPooling1D, Embedding, Concatenate, Dropout,\n",
        "    Bidirectional, LSTM, GRU, TimeDistributed)\n",
        "from keras.callbacks import EarlyStopping, ModelCheckpoint"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
            "  import pandas.util.testing as tm\n",
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CfFAeQAbgig0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "zk6fbj9vi3UV",
        "colab": {}
      },
      "source": [
        "DIRNAME = 'gdrive/My Drive/Colab Notebooks/'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "oLFBPH1z0S5t"
      },
      "source": [
        "## Helpers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OVZvIE2ER94D",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def clean_str(string):\n",
        "    \"\"\"\n",
        "    Tokenization/string cleaning for dataset\n",
        "    Every dataset is lower cased except\n",
        "    \"\"\"\n",
        "    string = re.sub(r\"\\\\\", \"\", string)\n",
        "    string = re.sub(r\"\\'\", \"\", string)\n",
        "    string = re.sub(r\"\\\"\", \"\", string)\n",
        "    return string.strip().lower()\n",
        "\n",
        "\n",
        "def glove_embedding_matrix(EMBEDDING_DIM, word_index):\n",
        "    embeddings_index = {}\n",
        "    with open(DIRNAME + 'data/glove.6B.100d.txt') as f:\n",
        "        for line in f:\n",
        "            values = line.split()\n",
        "            word = values[0]\n",
        "            coefs = np.asarray(values[1:], dtype='float32')\n",
        "            embeddings_index[word] = coefs\n",
        "    print('Total %s word vectors in Glove 6B 100d.' % len(embeddings_index))\n",
        "    \n",
        "    embedding_matrix = np.random.random((len(word_index) + 1, EMBEDDING_DIM))\n",
        "    for word, i in word_index.items():\n",
        "        embedding_vector = embeddings_index.get(word)\n",
        "        if embedding_vector is not None:\n",
        "            # words not found in embedding index will be all-zeros.\n",
        "            embedding_matrix[i] = embedding_vector\n",
        "            \n",
        "    return embedding_matrix\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "JEvJiktXFXox"
      },
      "source": [
        "## Download word2vec-nlp data from Kaggle\n",
        "wget https://www.kaggle.com/c/word2vec-nlp-tutorial/download/labeledTrainData.tsv"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TbR5PtlnSCis",
        "colab_type": "text"
      },
      "source": [
        "## Load data and Preprocess 2D"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "EAHHKwd-0S5u",
        "outputId": "7deb7113-4125-415f-ad04-7a56c09a305e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "data_train = pd.read_csv(DIRNAME + 'data/word2vec-nlp/labeledTrainData.tsv', sep='\\t')\n",
        "texts = []\n",
        "labels = []\n",
        "for i in range(data_train.review.shape[0]):\n",
        "    text = BeautifulSoup(data_train.review[i], 'html5lib')\n",
        "    texts.append(clean_str(text.get_text()))\n",
        "    labels.append(data_train.sentiment[i])\n",
        "    \n",
        "labels = to_categorical(np.asarray(labels))\n",
        "print('Shape of label tensor:', labels.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Shape of label tensor: (25000, 2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "yU8I1zkf0S5x",
        "outputId": "81cbeb49-cb3c-46a0-a28b-ebc824f05a9e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "MAX_SEQUENCE_LENGTH = 1000\n",
        "MAX_NUM_WORDS = 20000\n",
        "EMBEDDING_DIM = 100\n",
        "VALIDATION_SPLIT = 0.2\n",
        "\n",
        "tokenizer = Tokenizer(num_words=MAX_NUM_WORDS)\n",
        "tokenizer.fit_on_texts(texts)\n",
        "sequences = tokenizer.texts_to_sequences(texts)\n",
        "\n",
        "word_index = tokenizer.word_index\n",
        "print('Found %s unique tokens.' % len(word_index))\n",
        "\n",
        "data = pad_sequences(sequences, maxlen=MAX_SEQUENCE_LENGTH)\n",
        "print('Shape of data tensor:', data.shape)\n",
        "\n",
        "\n",
        "# Shuffling and splitting into train and validation sets\n",
        "indices = np.arange(data.shape[0])\n",
        "np.random.shuffle(indices)\n",
        "data = data[indices]\n",
        "labels = labels[indices]\n",
        "num_validation_samples = int(VALIDATION_SPLIT * data.shape[0])\n",
        "\n",
        "x_train = data[:-num_validation_samples]\n",
        "y_train = labels[:-num_validation_samples]\n",
        "x_val = data[-num_validation_samples:]\n",
        "y_val = labels[-num_validation_samples:]\n",
        "\n",
        "print('Number of positive and negative reviews in training and validation set ')\n",
        "print(y_train.sum(axis=0))\n",
        "print(y_val.sum(axis=0))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 81503 unique tokens.\n",
            "Shape of data tensor: (25000, 1000)\n",
            "Number of positive and negative reviews in training and validation set \n",
            "[10014.  9986.]\n",
            "[2486. 2514.]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "-xQyLIQfzxTI"
      },
      "source": [
        "## Glove embedding matrix"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "I6JFqvLN0S5z",
        "outputId": "196284d2-1755-4832-92a1-f52ecb026984",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "embedding_matrix = glove_embedding_matrix(EMBEDDING_DIM, word_index)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total 400000 word vectors in Glove 6B 100d.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "9HfARsQQ0S52",
        "colab": {}
      },
      "source": [
        "embedding_layer = Embedding(\n",
        "    len(word_index) + 1,\n",
        "    EMBEDDING_DIM,\n",
        "    weights=[embedding_matrix],\n",
        "    input_length=MAX_SEQUENCE_LENGTH,\n",
        "    trainable=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "rrTZX71d0S54"
      },
      "source": [
        "## CNN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "mMaxdbiJvrGB",
        "outputId": "ef4906b6-ff84-409b-d746-9166e3263a99",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 748
        }
      },
      "source": [
        "sequence_input = Input(shape=[MAX_SEQUENCE_LENGTH], dtype='int32')\n",
        "embedded_sequences = embedding_layer(sequence_input)\n",
        "\n",
        "kernel_sizes = [3,4,5]\n",
        "convs = []\n",
        "for fsz in kernel_sizes:\n",
        "    l_conv = Conv1D(filters=128, kernel_size=fsz, activation='relu')(embedded_sequences)\n",
        "    l_pool = MaxPooling1D(pool_size=5)(l_conv)\n",
        "    convs.append(l_pool)\n",
        "    \n",
        "l_merge = Concatenate(axis=1)(convs)\n",
        "l_cov1= Conv1D(filters=128, kernel_size=5, activation='relu')(l_merge)\n",
        "l_pool1 = MaxPooling1D(pool_size=5)(l_cov1)\n",
        "l_cov2 = Conv1D(filters=128, kernel_size=5, activation='relu')(l_pool1)\n",
        "l_pool2 = MaxPooling1D(pool_size=30)(l_cov2)\n",
        "l_flat = Flatten()(l_pool2)\n",
        "l_dense = Dense(units=128, activation='relu')(l_flat)\n",
        "preds = Dense(units=2, activation='softmax')(l_dense)\n",
        "\n",
        "model = Model(sequence_input, preds)\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer='rmsprop',\n",
        "              metrics=['acc'])\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_1\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            (None, 1000)         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding_1 (Embedding)         (None, 1000, 100)    8150400     input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_1 (Conv1D)               (None, 998, 128)     38528       embedding_1[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_2 (Conv1D)               (None, 997, 128)     51328       embedding_1[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_3 (Conv1D)               (None, 996, 128)     64128       embedding_1[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling1d_1 (MaxPooling1D)  (None, 199, 128)     0           conv1d_1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling1d_2 (MaxPooling1D)  (None, 199, 128)     0           conv1d_2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling1d_3 (MaxPooling1D)  (None, 199, 128)     0           conv1d_3[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_1 (Concatenate)     (None, 597, 128)     0           max_pooling1d_1[0][0]            \n",
            "                                                                 max_pooling1d_2[0][0]            \n",
            "                                                                 max_pooling1d_3[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_4 (Conv1D)               (None, 593, 128)     82048       concatenate_1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling1d_4 (MaxPooling1D)  (None, 118, 128)     0           conv1d_4[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv1d_5 (Conv1D)               (None, 114, 128)     82048       max_pooling1d_4[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling1d_5 (MaxPooling1D)  (None, 3, 128)       0           conv1d_5[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "flatten_1 (Flatten)             (None, 384)          0           max_pooling1d_5[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, 128)          49280       flatten_1[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dense_2 (Dense)                 (None, 2)            258         dense_1[0][0]                    \n",
            "==================================================================================================\n",
            "Total params: 8,518,018\n",
            "Trainable params: 8,518,018\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "hg2PuxUAxsUz",
        "outputId": "cf03d08c-4c20-48f6-d284-93e6d3466563",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 785
        }
      },
      "source": [
        "epochs = 10\n",
        "batch_size = 1024\n",
        "\n",
        "file_path = 'cnn.h5'\n",
        "checkpoint = ModelCheckpoint(file_path, monitor='val_loss', verbose=1,\n",
        "                             save_best_only=True, mode='min')\n",
        "early = EarlyStopping(monitor='val_loss', mode='min', patience=5)\n",
        "\n",
        "model.fit(x_train,\n",
        "          y_train,\n",
        "          batch_size=batch_size,\n",
        "          epochs=epochs,\n",
        "          shuffle=True,\n",
        "          validation_data=(x_val, y_val),\n",
        "          callbacks=[checkpoint, early])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/indexed_slices.py:434: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 20000 samples, validate on 5000 samples\n",
            "Epoch 1/10\n",
            "20000/20000 [==============================] - 26s 1ms/step - loss: 1.0055 - acc: 0.5102 - val_loss: 0.7000 - val_acc: 0.4972\n",
            "\n",
            "Epoch 00001: val_loss improved from inf to 0.70003, saving model to weights.h5\n",
            "Epoch 2/10\n",
            "20000/20000 [==============================] - 17s 827us/step - loss: 0.6933 - acc: 0.5232 - val_loss: 0.6896 - val_acc: 0.5028\n",
            "\n",
            "Epoch 00002: val_loss improved from 0.70003 to 0.68960, saving model to weights.h5\n",
            "Epoch 3/10\n",
            "20000/20000 [==============================] - 17s 828us/step - loss: 0.6955 - acc: 0.5742 - val_loss: 0.6805 - val_acc: 0.5074\n",
            "\n",
            "Epoch 00003: val_loss improved from 0.68960 to 0.68048, saving model to weights.h5\n",
            "Epoch 4/10\n",
            "20000/20000 [==============================] - 17s 829us/step - loss: 0.6709 - acc: 0.6270 - val_loss: 0.7177 - val_acc: 0.5238\n",
            "\n",
            "Epoch 00004: val_loss did not improve from 0.68048\n",
            "Epoch 5/10\n",
            "20000/20000 [==============================] - 17s 830us/step - loss: 0.6115 - acc: 0.7030 - val_loss: 1.0074 - val_acc: 0.5042\n",
            "\n",
            "Epoch 00005: val_loss did not improve from 0.68048\n",
            "Epoch 6/10\n",
            "20000/20000 [==============================] - 17s 830us/step - loss: 0.5664 - acc: 0.7431 - val_loss: 0.4330 - val_acc: 0.8114\n",
            "\n",
            "Epoch 00006: val_loss improved from 0.68048 to 0.43296, saving model to weights.h5\n",
            "Epoch 7/10\n",
            "20000/20000 [==============================] - 17s 830us/step - loss: 0.4728 - acc: 0.7817 - val_loss: 0.4138 - val_acc: 0.8266\n",
            "\n",
            "Epoch 00007: val_loss improved from 0.43296 to 0.41376, saving model to weights.h5\n",
            "Epoch 8/10\n",
            "20000/20000 [==============================] - 17s 833us/step - loss: 0.4066 - acc: 0.8240 - val_loss: 0.3602 - val_acc: 0.8480\n",
            "\n",
            "Epoch 00008: val_loss improved from 0.41376 to 0.36016, saving model to weights.h5\n",
            "Epoch 9/10\n",
            "20000/20000 [==============================] - 17s 835us/step - loss: 0.3669 - acc: 0.8405 - val_loss: 0.3783 - val_acc: 0.8332\n",
            "\n",
            "Epoch 00009: val_loss did not improve from 0.36016\n",
            "Epoch 10/10\n",
            "20000/20000 [==============================] - 17s 836us/step - loss: 0.3319 - acc: 0.8590 - val_loss: 0.3211 - val_acc: 0.8668\n",
            "\n",
            "Epoch 00010: val_loss improved from 0.36016 to 0.32111, saving model to weights.h5\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.callbacks.History at 0x7f38eb40c0f0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "apCPWvZz0S57"
      },
      "source": [
        "## Bidirectional LSTM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nsU7dyJaIz4o",
        "colab_type": "code",
        "outputId": "b46b073b-effa-4602-a16b-7643522c0449",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        }
      },
      "source": [
        "sequence_input = Input(shape=[MAX_SEQUENCE_LENGTH], dtype='int32')\n",
        "embedded_sequences = embedding_layer(sequence_input)\n",
        "\n",
        "l_lstm = Bidirectional(LSTM(units=100))(embedded_sequences)\n",
        "preds = Dense(units=2, activation='softmax')(l_lstm)\n",
        "\n",
        "model = Model(sequence_input, preds)\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer='rmsprop',\n",
        "              metrics=['acc'])\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_2 (InputLayer)         (None, 1000)              0         \n",
            "_________________________________________________________________\n",
            "embedding_1 (Embedding)      (None, 1000, 100)         8150400   \n",
            "_________________________________________________________________\n",
            "bidirectional_1 (Bidirection (None, 200)               160800    \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 2)                 402       \n",
            "=================================================================\n",
            "Total params: 8,311,602\n",
            "Trainable params: 8,311,602\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "6UPQXYw80S58",
        "outputId": "d42d4551-b372-4950-f26d-093d79b375ce",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 731
        }
      },
      "source": [
        "epochs = 10\n",
        "batch_size = 512\n",
        "\n",
        "file_path = 'bilstm.h5'\n",
        "checkpoint = ModelCheckpoint(file_path, monitor='val_loss', verbose=1,\n",
        "                             save_best_only=True, mode='min')\n",
        "early = EarlyStopping(monitor='val_loss', mode='min', patience=5)\n",
        "\n",
        "model.fit(x_train,\n",
        "          y_train,\n",
        "          batch_size=batch_size,\n",
        "          epochs=epochs,\n",
        "          shuffle=True,\n",
        "          validation_data=(x_val, y_val),\n",
        "          callbacks=[checkpoint, early])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 20000 samples, validate on 5000 samples\n",
            "Epoch 1/10\n",
            "20000/20000 [==============================] - 137s 7ms/step - loss: 0.6699 - acc: 0.6220 - val_loss: 0.8781 - val_acc: 0.5512\n",
            "\n",
            "Epoch 00001: val_loss improved from inf to 0.87808, saving model to bilstm.h5\n",
            "Epoch 2/10\n",
            "20000/20000 [==============================] - 136s 7ms/step - loss: 0.5284 - acc: 0.7532 - val_loss: 0.5109 - val_acc: 0.7552\n",
            "\n",
            "Epoch 00002: val_loss improved from 0.87808 to 0.51089, saving model to bilstm.h5\n",
            "Epoch 3/10\n",
            "20000/20000 [==============================] - 139s 7ms/step - loss: 0.4447 - acc: 0.8030 - val_loss: 0.4185 - val_acc: 0.8212\n",
            "\n",
            "Epoch 00003: val_loss improved from 0.51089 to 0.41853, saving model to bilstm.h5\n",
            "Epoch 4/10\n",
            "20000/20000 [==============================] - 136s 7ms/step - loss: 0.3872 - acc: 0.8408 - val_loss: 1.2485 - val_acc: 0.6108\n",
            "\n",
            "Epoch 00004: val_loss did not improve from 0.41853\n",
            "Epoch 5/10\n",
            "20000/20000 [==============================] - 136s 7ms/step - loss: 0.3547 - acc: 0.8582 - val_loss: 0.3551 - val_acc: 0.8480\n",
            "\n",
            "Epoch 00005: val_loss improved from 0.41853 to 0.35513, saving model to bilstm.h5\n",
            "Epoch 6/10\n",
            "20000/20000 [==============================] - 134s 7ms/step - loss: 0.3273 - acc: 0.8677 - val_loss: 0.5487 - val_acc: 0.7604\n",
            "\n",
            "Epoch 00006: val_loss did not improve from 0.35513\n",
            "Epoch 7/10\n",
            "20000/20000 [==============================] - 135s 7ms/step - loss: 0.2717 - acc: 0.8942 - val_loss: 0.3930 - val_acc: 0.8260\n",
            "\n",
            "Epoch 00007: val_loss did not improve from 0.35513\n",
            "Epoch 8/10\n",
            "20000/20000 [==============================] - 137s 7ms/step - loss: 0.2523 - acc: 0.9028 - val_loss: 0.4454 - val_acc: 0.8340\n",
            "\n",
            "Epoch 00008: val_loss did not improve from 0.35513\n",
            "Epoch 9/10\n",
            "20000/20000 [==============================] - 135s 7ms/step - loss: 0.2241 - acc: 0.9115 - val_loss: 0.3057 - val_acc: 0.8894\n",
            "\n",
            "Epoch 00009: val_loss improved from 0.35513 to 0.30566, saving model to bilstm.h5\n",
            "Epoch 10/10\n",
            "20000/20000 [==============================] - 135s 7ms/step - loss: 0.1969 - acc: 0.9255 - val_loss: 0.3750 - val_acc: 0.8616\n",
            "\n",
            "Epoch 00010: val_loss did not improve from 0.30566\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.callbacks.History at 0x7f38ea43ed68>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "vs8A-FyO0S5_"
      },
      "source": [
        "## Attention Bidirectional GRU"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "326P2x3X0S6A",
        "colab": {}
      },
      "source": [
        "# Adapted from https://github.com/cbaziotis/keras-utilities/blob/master/kutilities/layers.py\n",
        "\n",
        "from keras import backend as K\n",
        "from keras import activations, initializers, regularizers, constraints\n",
        "from keras.layers import Layer\n",
        "\n",
        "\n",
        "def dot_product(x, kernel):\n",
        "    \"\"\"\n",
        "    Wrapper for dot product operation, in order to be compatible with both\n",
        "    Theano and Tensorflow\n",
        "    Args:\n",
        "        x (): input\n",
        "        kernel (): weights\n",
        "    Returns:\n",
        "    \"\"\"\n",
        "    if K.backend() == 'tensorflow':\n",
        "        return K.squeeze(K.dot(x, K.expand_dims(kernel)), axis=-1)\n",
        "    else:\n",
        "        return K.dot(x, kernel)\n",
        "\n",
        "\n",
        "class MeanOverTime(Layer):\n",
        "    \"\"\"\n",
        "    Layer that computes the mean of timesteps returned from an RNN and supports masking\n",
        "    Example:\n",
        "        activations = LSTM(64, return_sequences=True)(words)\n",
        "        mean = MeanOverTime()(activations)\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, **kwargs):\n",
        "        self.supports_masking = True\n",
        "        super(MeanOverTime, self).__init__(**kwargs)\n",
        "\n",
        "    def call(self, x, mask=None):\n",
        "        if mask is not None:\n",
        "            mask = K.cast(mask, 'float32')\n",
        "            return K.cast(K.sum(x, axis=1) / K.sum(mask, axis=1, keepdims=True),\n",
        "                          K.floatx())\n",
        "        else:\n",
        "            return K.mean(x, axis=1)\n",
        "\n",
        "    def compute_output_shape(self, input_shape):\n",
        "        return input_shape[0], input_shape[-1]\n",
        "\n",
        "    def compute_mask(self, input, input_mask=None):\n",
        "        return None\n",
        "\n",
        "\n",
        "class Attention(Layer):\n",
        "    def __init__(self,\n",
        "                 W_regularizer=None, b_regularizer=None,\n",
        "                 W_constraint=None, b_constraint=None,\n",
        "                 bias=True,\n",
        "                 return_attention=False,\n",
        "                 **kwargs):\n",
        "        \"\"\"\n",
        "        Keras Layer that implements an Attention mechanism for temporal data.\n",
        "        Supports Masking.\n",
        "        Follows the work of Raffel et al. [https://arxiv.org/abs/1512.08756]\n",
        "        # Input shape\n",
        "            3D tensor with shape: `(samples, steps, features)`.\n",
        "        # Output shape\n",
        "            2D tensor with shape: `(samples, features)`.\n",
        "        :param kwargs:\n",
        "        Just put it on top of an RNN Layer (GRU/LSTM/SimpleRNN) with return_sequences=True.\n",
        "        The dimensions are inferred based on the output shape of the RNN.\n",
        "        Note: The layer has been tested with Keras 1.x\n",
        "        Example:\n",
        "\n",
        "            # 1\n",
        "            model.add(LSTM(64, return_sequences=True))\n",
        "            model.add(Attention())\n",
        "            # next add a Dense layer (for classification/regression) or whatever...\n",
        "            # 2 - Get the attention scores\n",
        "            hidden = LSTM(64, return_sequences=True)(words)\n",
        "            sentence, word_scores = Attention(return_attention=True)(hidden)\n",
        "        \"\"\"\n",
        "        self.supports_masking = True\n",
        "        self.return_attention = return_attention\n",
        "        self.init = initializers.get('glorot_uniform')\n",
        "\n",
        "        self.W_regularizer = regularizers.get(W_regularizer)\n",
        "        self.b_regularizer = regularizers.get(b_regularizer)\n",
        "\n",
        "        self.W_constraint = constraints.get(W_constraint)\n",
        "        self.b_constraint = constraints.get(b_constraint)\n",
        "\n",
        "        self.bias = bias\n",
        "        super(Attention, self).__init__(**kwargs)\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        assert len(input_shape) == 3\n",
        "\n",
        "        self.W = self.add_weight(shape=(input_shape[-1],),\n",
        "                                 initializer=self.init,\n",
        "                                 name='{}_W'.format(self.name),\n",
        "                                 regularizer=self.W_regularizer,\n",
        "                                 constraint=self.W_constraint)\n",
        "        if self.bias:\n",
        "            self.b = self.add_weight(shape=(input_shape[1],),\n",
        "                                     initializer='zero',\n",
        "                                     name='{}_b'.format(self.name),\n",
        "                                     regularizer=self.b_regularizer,\n",
        "                                     constraint=self.b_constraint)\n",
        "        else:\n",
        "            self.b = None\n",
        "\n",
        "        self.built = True\n",
        "\n",
        "    def compute_mask(self, input, input_mask=None):\n",
        "        # do not pass the mask to the next layers\n",
        "        return None\n",
        "\n",
        "    def call(self, x, mask=None):\n",
        "        eij = dot_product(x, self.W)\n",
        "\n",
        "        if self.bias:\n",
        "            eij += self.b\n",
        "\n",
        "        eij = K.tanh(eij)\n",
        "\n",
        "        a = K.exp(eij)\n",
        "\n",
        "        # apply mask after the exp. will be re-normalized next\n",
        "        if mask is not None:\n",
        "            # Cast the mask to floatX to avoid float64 upcasting in theano\n",
        "            a *= K.cast(mask, K.floatx())\n",
        "\n",
        "        # in some cases especially in the early stages of training the sum may be almost zero\n",
        "        # and this results in NaN's. A workaround is to add a very small positive number ε to the sum.\n",
        "        # a /= K.cast(K.sum(a, axis=1, keepdims=True), K.floatx())\n",
        "        a /= K.cast(K.sum(a, axis=1, keepdims=True) + K.epsilon(), K.floatx())\n",
        "\n",
        "        weighted_input = x * K.expand_dims(a)\n",
        "\n",
        "        result = K.sum(weighted_input, axis=1)\n",
        "\n",
        "        if self.return_attention:\n",
        "            return [result, a]\n",
        "        return result\n",
        "\n",
        "    def compute_output_shape(self, input_shape):\n",
        "        if self.return_attention:\n",
        "            return [(input_shape[0], input_shape[-1]),\n",
        "                    (input_shape[0], input_shape[1])]\n",
        "        else:\n",
        "            return input_shape[0], input_shape[-1]\n",
        "\n",
        "\n",
        "class AttentionWithContext(Layer):\n",
        "    \"\"\"\n",
        "        Attention operation, with a context/query vector, for temporal data.\n",
        "        Supports Masking.\n",
        "        Follows the work of Yang et al. [https://www.cs.cmu.edu/~diyiy/docs/naacl16.pdf]\n",
        "        \"Hierarchical Attention Networks for Document Classification\"\n",
        "        by using a context vector to assist the attention\n",
        "        # Input shape\n",
        "            3D tensor with shape: `(samples, steps, features)`.\n",
        "        # Output shape\n",
        "            2D tensor with shape: `(samples, features)`.\n",
        "        :param kwargs:\n",
        "        Just put it on top of an RNN Layer (GRU/LSTM/SimpleRNN) with return_sequences=True.\n",
        "        The dimensions are inferred based on the output shape of the RNN.\n",
        "        Example:\n",
        "            model.add(LSTM(64, return_sequences=True))\n",
        "            model.add(AttentionWithContext())\n",
        "        \"\"\"\n",
        "\n",
        "    def __init__(self,\n",
        "                 W_regularizer=None, u_regularizer=None, b_regularizer=None,\n",
        "                 W_constraint=None, u_constraint=None, b_constraint=None,\n",
        "                 bias=True,\n",
        "                 return_attention=False, **kwargs):\n",
        "\n",
        "        self.supports_masking = True\n",
        "        self.return_attention = return_attention\n",
        "        self.init = initializers.get('glorot_uniform')\n",
        "\n",
        "        self.W_regularizer = regularizers.get(W_regularizer)\n",
        "        self.u_regularizer = regularizers.get(u_regularizer)\n",
        "        self.b_regularizer = regularizers.get(b_regularizer)\n",
        "\n",
        "        self.W_constraint = constraints.get(W_constraint)\n",
        "        self.u_constraint = constraints.get(u_constraint)\n",
        "        self.b_constraint = constraints.get(b_constraint)\n",
        "\n",
        "        self.bias = bias\n",
        "        super(AttentionWithContext, self).__init__(**kwargs)\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        assert len(input_shape) == 3\n",
        "\n",
        "        self.W = self.add_weight(shape=(input_shape[-1], input_shape[-1],),\n",
        "                                 initializer=self.init,\n",
        "                                 name='{}_W'.format(self.name),\n",
        "                                 regularizer=self.W_regularizer,\n",
        "                                 constraint=self.W_constraint)\n",
        "        if self.bias:\n",
        "            self.b = self.add_weight(shape=(input_shape[-1],),\n",
        "                                     initializer='zero',\n",
        "                                     name='{}_b'.format(self.name),\n",
        "                                     regularizer=self.b_regularizer,\n",
        "                                     constraint=self.b_constraint)\n",
        "\n",
        "        self.u = self.add_weight(shape=(input_shape[-1],),\n",
        "                                 initializer=self.init,\n",
        "                                 name='{}_u'.format(self.name),\n",
        "                                 regularizer=self.u_regularizer,\n",
        "                                 constraint=self.u_constraint)\n",
        "\n",
        "        super(AttentionWithContext, self).build(input_shape)\n",
        "\n",
        "    def compute_mask(self, input, input_mask=None):\n",
        "        # do not pass the mask to the next layers\n",
        "        return None\n",
        "\n",
        "    def call(self, x, mask=None):\n",
        "        uit = dot_product(x, self.W)\n",
        "\n",
        "        if self.bias:\n",
        "            uit += self.b\n",
        "\n",
        "        uit = K.tanh(uit)\n",
        "        ait = dot_product(uit, self.u)\n",
        "\n",
        "        a = K.exp(ait)\n",
        "\n",
        "        # apply mask after the exp. will be re-normalized next\n",
        "        if mask is not None:\n",
        "            # Cast the mask to floatX to avoid float64 upcasting in theano\n",
        "            a *= K.cast(mask, K.floatx())\n",
        "\n",
        "        # in some cases especially in the early stages of training the sum may be almost zero\n",
        "        # and this results in NaN's. A workaround is to add a very small positive number ε to the sum.\n",
        "        # a /= K.cast(K.sum(a, axis=1, keepdims=True), K.floatx())\n",
        "        a /= K.cast(K.sum(a, axis=1, keepdims=True) + K.epsilon(), K.floatx())\n",
        "\n",
        "        a = K.expand_dims(a)\n",
        "        weighted_input = x * a\n",
        "        result = K.sum(weighted_input, axis=1)\n",
        "\n",
        "        if self.return_attention:\n",
        "            return [result, a]\n",
        "        return result\n",
        "\n",
        "    def compute_output_shape(self, input_shape):\n",
        "        if self.return_attention:\n",
        "            return [(input_shape[0], input_shape[-1]),\n",
        "                    (input_shape[0], input_shape[1])]\n",
        "        else:\n",
        "            return input_shape[0], input_shape[-1]\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ceMAGK8xKmLS",
        "colab_type": "code",
        "outputId": "39d34131-4a3b-4ac9-8beb-cfe5ccf287f2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 323
        }
      },
      "source": [
        "sequence_input = Input(shape=[MAX_SEQUENCE_LENGTH], dtype='int32')\n",
        "embedded_sequences = embedding_layer(sequence_input)\n",
        "\n",
        "l_gru = Bidirectional(GRU(units=100, return_sequences=True))(embedded_sequences)\n",
        "l_attn = Attention()(l_gru)\n",
        "preds = Dense(units=2, activation='softmax')(l_attn)\n",
        "\n",
        "model = Model(sequence_input, preds)\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer='rmsprop',\n",
        "              metrics=['acc'])\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_3\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_5 (InputLayer)         (None, 1000)              0         \n",
            "_________________________________________________________________\n",
            "embedding_1 (Embedding)      (None, 1000, 100)         8150400   \n",
            "_________________________________________________________________\n",
            "bidirectional_4 (Bidirection (None, 1000, 200)         120600    \n",
            "_________________________________________________________________\n",
            "attention_2 (Attention)      (None, 200)               1200      \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 2)                 402       \n",
            "=================================================================\n",
            "Total params: 8,272,602\n",
            "Trainable params: 8,272,602\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qQTKdCvrKu4X",
        "colab_type": "code",
        "outputId": "96faffdf-e329-4d0c-f800-02d517446e2f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 731
        }
      },
      "source": [
        "epochs = 10\n",
        "batch_size = 512\n",
        "\n",
        "file_path = 'attn_bigru.h5'\n",
        "checkpoint = ModelCheckpoint(file_path, monitor='val_loss', verbose=1,\n",
        "                             save_best_only=True, mode='min')\n",
        "early = EarlyStopping(monitor='val_loss', mode='min', patience=5)\n",
        "\n",
        "model.fit(x_train,\n",
        "          y_train,\n",
        "          batch_size=batch_size,\n",
        "          epochs=epochs,\n",
        "          shuffle=True,\n",
        "          validation_data=(x_val, y_val),\n",
        "          callbacks=[checkpoint, early])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 20000 samples, validate on 5000 samples\n",
            "Epoch 1/10\n",
            "20000/20000 [==============================] - 172s 9ms/step - loss: 0.6633 - acc: 0.6093 - val_loss: 0.6983 - val_acc: 0.5438\n",
            "\n",
            "Epoch 00001: val_loss improved from inf to 0.69834, saving model to attn_bigru.h5\n",
            "Epoch 2/10\n",
            "20000/20000 [==============================] - 174s 9ms/step - loss: 0.3951 - acc: 0.8273 - val_loss: 0.3182 - val_acc: 0.8710\n",
            "\n",
            "Epoch 00002: val_loss improved from 0.69834 to 0.31818, saving model to attn_bigru.h5\n",
            "Epoch 3/10\n",
            "20000/20000 [==============================] - 173s 9ms/step - loss: 0.2612 - acc: 0.8987 - val_loss: 0.4146 - val_acc: 0.8514\n",
            "\n",
            "Epoch 00003: val_loss did not improve from 0.31818\n",
            "Epoch 4/10\n",
            "20000/20000 [==============================] - 170s 9ms/step - loss: 0.2333 - acc: 0.9122 - val_loss: 0.2999 - val_acc: 0.8882\n",
            "\n",
            "Epoch 00004: val_loss improved from 0.31818 to 0.29985, saving model to attn_bigru.h5\n",
            "Epoch 5/10\n",
            "20000/20000 [==============================] - 170s 8ms/step - loss: 0.1889 - acc: 0.9312 - val_loss: 0.4757 - val_acc: 0.8390\n",
            "\n",
            "Epoch 00005: val_loss did not improve from 0.29985\n",
            "Epoch 6/10\n",
            "20000/20000 [==============================] - 171s 9ms/step - loss: 0.1636 - acc: 0.9428 - val_loss: 0.5606 - val_acc: 0.8414\n",
            "\n",
            "Epoch 00006: val_loss did not improve from 0.29985\n",
            "Epoch 7/10\n",
            "20000/20000 [==============================] - 170s 9ms/step - loss: 0.1471 - acc: 0.9509 - val_loss: 0.2893 - val_acc: 0.8912\n",
            "\n",
            "Epoch 00007: val_loss improved from 0.29985 to 0.28929, saving model to attn_bigru.h5\n",
            "Epoch 8/10\n",
            "20000/20000 [==============================] - 169s 8ms/step - loss: 0.1303 - acc: 0.9539 - val_loss: 0.2961 - val_acc: 0.8890\n",
            "\n",
            "Epoch 00008: val_loss did not improve from 0.28929\n",
            "Epoch 9/10\n",
            "20000/20000 [==============================] - 166s 8ms/step - loss: 0.1091 - acc: 0.9629 - val_loss: 0.3971 - val_acc: 0.8656\n",
            "\n",
            "Epoch 00009: val_loss did not improve from 0.28929\n",
            "Epoch 10/10\n",
            "20000/20000 [==============================] - 166s 8ms/step - loss: 0.0923 - acc: 0.9700 - val_loss: 0.3384 - val_acc: 0.8932\n",
            "\n",
            "Epoch 00010: val_loss did not improve from 0.28929\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.callbacks.History at 0x7f38e7a8d908>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "RlTYML7P0S6L"
      },
      "source": [
        "## Load data and Preprocess 3D\n",
        "\n",
        "Need to construct the data input as 3D other than 2D in previous two posts. So the input tensor would be (# of reviews each batch, # of sentences, # of words in each sentence)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "H1lRCIOS0S6L",
        "outputId": "fe238c9e-a5e4-42fd-815f-3d6bf05acc04",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "import nltk\n",
        "\n",
        "\n",
        "nltk.download('punkt')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "SMnLCqIc0S6O",
        "outputId": "9b588f5c-20de-478e-eb50-0b153f5b720c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from nltk import tokenize\n",
        "\n",
        "\n",
        "data_train = pd.read_csv(DIRNAME + 'data/word2vec-nlp/labeledTrainData.tsv', sep='\\t')\n",
        "texts = []\n",
        "reviews = []\n",
        "labels = []\n",
        "for i in range(data_train.review.shape[0]):\n",
        "    text = clean_str(BeautifulSoup(data_train.review[i], 'html5lib').get_text())\n",
        "    texts.append(text)\n",
        "    reviews.append(tokenize.sent_tokenize(text))\n",
        "    labels.append(data_train.sentiment[i])\n",
        "    \n",
        "labels = to_categorical(np.asarray(labels))\n",
        "print('Shape of label tensor:', labels.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Shape of label tensor: (25000, 2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "uqTjJUeb0S6T",
        "outputId": "b84dfcfd-24d0-4179-9d30-13e346e7acf6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "MAX_SENT_LENGTH = 100\n",
        "MAX_SENTS = 15\n",
        "MAX_NUM_WORDS = 20000\n",
        "EMBEDDING_DIM = 100\n",
        "VALIDATION_SPLIT = 0.2\n",
        "\n",
        "tokenizer = Tokenizer(num_words=MAX_NUM_WORDS)\n",
        "tokenizer.fit_on_texts(texts)\n",
        "\n",
        "data = np.zeros((len(texts), MAX_SENTS, MAX_SENT_LENGTH), dtype='int32')\n",
        "for i, sentences in enumerate(reviews):\n",
        "    for j, sent in enumerate(sentences):\n",
        "        if j < MAX_SENTS:\n",
        "            wordTokens = text_to_word_sequence(sent)\n",
        "            #set max number of words\n",
        "            k = 0\n",
        "            for _, word in enumerate(wordTokens):\n",
        "                if k < MAX_SENT_LENGTH and tokenizer.word_index[word] < MAX_NUM_WORDS:\n",
        "                    data[i,j,k] = tokenizer.word_index[word]\n",
        "                    k = k + 1\n",
        "print('Shape of data tensor:', data.shape)\n",
        "\n",
        "word_index = tokenizer.word_index\n",
        "print('Found %s unique tokens.' % len(word_index))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Shape of data tensor: (25000, 15, 100)\n",
            "Found 81503 unique tokens.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "cECx-Lhu0S6W",
        "outputId": "ae4ca1e0-8901-42ff-e604-af1a65002847",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "# Shuffling and splitting into train and validation sets\n",
        "indices = np.arange(data.shape[0])\n",
        "np.random.shuffle(indices)\n",
        "data = data[indices]\n",
        "labels = labels[indices]\n",
        "num_validation_samples = int(VALIDATION_SPLIT * data.shape[0])\n",
        "\n",
        "x_train = data[:-num_validation_samples]\n",
        "y_train = labels[:-num_validation_samples]\n",
        "x_val = data[-num_validation_samples:]\n",
        "y_val = labels[-num_validation_samples:]\n",
        "\n",
        "print('Number of positive and negative reviews in training and validation set')\n",
        "print(y_train.sum(axis=0))\n",
        "print(y_val.sum(axis=0))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of positive and negative reviews in training and validation set\n",
            "[ 9995. 10005.]\n",
            "[2505. 2495.]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "njGBT5usUnZV",
        "colab_type": "text"
      },
      "source": [
        "## Glove embedding matrix"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AqtavvyvNnVI",
        "colab_type": "code",
        "outputId": "a63f1536-af1e-4620-afec-304def31c54b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "embedding_matrix = glove_embedding_matrix(EMBEDDING_DIM, word_index)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total 400000 word vectors in Glove 6B 100d.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "76T4XBXK0S6c",
        "colab": {}
      },
      "source": [
        "embedding_layer = Embedding(\n",
        "    len(word_index) + 1,\n",
        "    EMBEDDING_DIM,\n",
        "    weights=[embedding_matrix],\n",
        "    input_length=MAX_SENT_LENGTH,\n",
        "    trainable=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "2EExzRt_0S6K"
      },
      "source": [
        "## Hierarchical LSTM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EWrhwWL1XRLh",
        "colab_type": "code",
        "outputId": "24f3c3b6-14d1-4720-d595-4ee00d3836aa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        }
      },
      "source": [
        "sentence_input = Input(shape=(MAX_SENT_LENGTH,), dtype='int32')\n",
        "embedded_sequences = embedding_layer(sentence_input)\n",
        "\n",
        "l_lstm = Bidirectional(LSTM(units=100))(embedded_sequences)\n",
        "sentEncoder = Model(sentence_input, l_lstm)\n",
        "\n",
        "review_input = Input(shape=(MAX_SENTS, MAX_SENT_LENGTH), dtype='int32')\n",
        "review_encoder = TimeDistributed(sentEncoder)(review_input)\n",
        "\n",
        "l_lstm_sent = Bidirectional(LSTM(units=100))(review_encoder)\n",
        "preds = Dense(units=2, activation='softmax')(l_lstm_sent)\n",
        "\n",
        "model = Model(review_input, preds)\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer='rmsprop',\n",
        "              metrics=['acc'])\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_5\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_7 (InputLayer)         (None, 15, 100)           0         \n",
            "_________________________________________________________________\n",
            "time_distributed_1 (TimeDist (None, 15, 200)           8311200   \n",
            "_________________________________________________________________\n",
            "bidirectional_6 (Bidirection (None, 200)               240800    \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 2)                 402       \n",
            "=================================================================\n",
            "Total params: 8,552,402\n",
            "Trainable params: 8,552,402\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LaAE8OwYXXiz",
        "colab_type": "code",
        "outputId": "3e657c8f-a40e-49b5-d037-bedc922d852c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 445
        }
      },
      "source": [
        "epochs = 5\n",
        "batch_size = 512\n",
        "\n",
        "file_path = 'hlstm.h5'\n",
        "checkpoint = ModelCheckpoint(file_path, monitor='val_loss', verbose=1,\n",
        "                             save_best_only=True, mode='min')\n",
        "early = EarlyStopping(monitor='val_loss', mode='min', patience=5)\n",
        "\n",
        "model.fit(x_train,\n",
        "          y_train,\n",
        "          batch_size=batch_size,\n",
        "          epochs=epochs,\n",
        "          shuffle=True,\n",
        "          validation_data=(x_val, y_val),\n",
        "          callbacks=[checkpoint, early])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/indexed_slices.py:434: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 20000 samples, validate on 5000 samples\n",
            "Epoch 1/5\n",
            "20000/20000 [==============================] - 49s 2ms/step - loss: 0.7440 - acc: 0.5546 - val_loss: 0.6265 - val_acc: 0.6728\n",
            "\n",
            "Epoch 00001: val_loss improved from inf to 0.62654, saving model to hlstm.h5\n",
            "Epoch 2/5\n",
            "20000/20000 [==============================] - 48s 2ms/step - loss: 0.6158 - acc: 0.6662 - val_loss: 0.6797 - val_acc: 0.6250\n",
            "\n",
            "Epoch 00002: val_loss did not improve from 0.62654\n",
            "Epoch 3/5\n",
            "20000/20000 [==============================] - 48s 2ms/step - loss: 0.5292 - acc: 0.7394 - val_loss: 0.4772 - val_acc: 0.7736\n",
            "\n",
            "Epoch 00003: val_loss improved from 0.62654 to 0.47725, saving model to hlstm.h5\n",
            "Epoch 4/5\n",
            "20000/20000 [==============================] - 48s 2ms/step - loss: 0.4475 - acc: 0.7974 - val_loss: 0.3791 - val_acc: 0.8356\n",
            "\n",
            "Epoch 00004: val_loss improved from 0.47725 to 0.37911, saving model to hlstm.h5\n",
            "Epoch 5/5\n",
            "20000/20000 [==============================] - 48s 2ms/step - loss: 0.3848 - acc: 0.8342 - val_loss: 0.4834 - val_acc: 0.7848\n",
            "\n",
            "Epoch 00005: val_loss did not improve from 0.37911\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.callbacks.History at 0x7f38eb1f65c0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "_egM5LQu0S6k"
      },
      "source": [
        "## Hierarchical Attention Networks"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DmnTyeu0Xn2r",
        "colab_type": "code",
        "outputId": "62bed5ad-6caa-4db2-d587-e4215bed5c69",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        }
      },
      "source": [
        "sentence_input = Input(shape=(MAX_SENT_LENGTH,), dtype='int32')\n",
        "embedded_sequences = embedding_layer(sentence_input)\n",
        "\n",
        "l_gru = Bidirectional(GRU(units=100, return_sequences=True))(embedded_sequences)\n",
        "l_dense = TimeDistributed(Dense(units=200))(l_gru)\n",
        "l_attn = Attention()(l_dense)\n",
        "sentEncoder = Model(sentence_input, l_attn)\n",
        "\n",
        "review_input = Input(shape=(MAX_SENTS, MAX_SENT_LENGTH), dtype='int32')\n",
        "review_encoder = TimeDistributed(sentEncoder)(review_input)\n",
        "\n",
        "l_gru_sent = Bidirectional(GRU(units=100, return_sequences=True))(review_encoder)\n",
        "l_dense_sent = TimeDistributed(Dense(units=200))(l_gru_sent)\n",
        "l_attn_sent = Attention()(l_dense_sent)\n",
        "preds = Dense(units=2, activation='softmax')(l_attn_sent)\n",
        "\n",
        "model = Model(review_input, preds)\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer='rmsprop',\n",
        "              metrics=['acc'])\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_8\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_12 (InputLayer)        (None, 15, 100)           0         \n",
            "_________________________________________________________________\n",
            "time_distributed_7 (TimeDist (None, 15, 200)           8311500   \n",
            "_________________________________________________________________\n",
            "bidirectional_11 (Bidirectio (None, 15, 200)           180600    \n",
            "_________________________________________________________________\n",
            "time_distributed_8 (TimeDist (None, 15, 200)           40200     \n",
            "_________________________________________________________________\n",
            "attention_5 (Attention)      (None, 200)               215       \n",
            "_________________________________________________________________\n",
            "dense_11 (Dense)             (None, 2)                 402       \n",
            "=================================================================\n",
            "Total params: 8,532,917\n",
            "Trainable params: 8,532,917\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bssPo1dwXsL-",
        "colab_type": "code",
        "outputId": "f3dc6608-adcc-48ee-d40a-6f353a12ccd0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        }
      },
      "source": [
        "epochs = 5\n",
        "batch_size = 256\n",
        "\n",
        "file_path = 'hattn.h5'\n",
        "checkpoint = ModelCheckpoint(file_path, monitor='val_loss', verbose=1,\n",
        "                             save_best_only=True, mode='min')\n",
        "early = EarlyStopping(monitor='val_loss', mode='min', patience=5)\n",
        "\n",
        "model.fit(x_train,\n",
        "          y_train,\n",
        "          batch_size=batch_size,\n",
        "          epochs=epochs,\n",
        "          shuffle=True,\n",
        "          validation_data=(x_val, y_val),\n",
        "          callbacks=[checkpoint, early])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 20000 samples, validate on 5000 samples\n",
            "Epoch 1/5\n",
            "20000/20000 [==============================] - 68s 3ms/step - loss: 0.7469 - acc: 0.5968 - val_loss: 0.6075 - val_acc: 0.6650\n",
            "\n",
            "Epoch 00001: val_loss improved from inf to 0.60748, saving model to hattn.h5\n",
            "Epoch 2/5\n",
            "20000/20000 [==============================] - 68s 3ms/step - loss: 0.4603 - acc: 0.7829 - val_loss: 0.4279 - val_acc: 0.8040\n",
            "\n",
            "Epoch 00002: val_loss improved from 0.60748 to 0.42788, saving model to hattn.h5\n",
            "Epoch 3/5\n",
            "20000/20000 [==============================] - 68s 3ms/step - loss: 0.3290 - acc: 0.8584 - val_loss: 0.3147 - val_acc: 0.8646\n",
            "\n",
            "Epoch 00003: val_loss improved from 0.42788 to 0.31475, saving model to hattn.h5\n",
            "Epoch 4/5\n",
            "20000/20000 [==============================] - 68s 3ms/step - loss: 0.2718 - acc: 0.8876 - val_loss: 0.2952 - val_acc: 0.8818\n",
            "\n",
            "Epoch 00004: val_loss improved from 0.31475 to 0.29518, saving model to hattn.h5\n",
            "Epoch 5/5\n",
            "20000/20000 [==============================] - 68s 3ms/step - loss: 0.2274 - acc: 0.9091 - val_loss: 0.3983 - val_acc: 0.8216\n",
            "\n",
            "Epoch 00005: val_loss did not improve from 0.29518\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.callbacks.History at 0x7f3718df34e0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "evB_X3yX0S6r",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}