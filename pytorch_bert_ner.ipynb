{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"pytorch_bert_ner.ipynb","provenance":[],"collapsed_sections":[],"toc_visible":true},"kernelspec":{"name":"python3","display_name":"Python 3"},"widgets":{"application/vnd.jupyter.widget-state+json":{"c79417cf92764416adcc675fb52e4190":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_4c3b20f0e82d4eba86c0b088742e2141","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_cd586a112d6e480e97cdf825ee0ece0c","IPY_MODEL_b129fd46c0644212a593428886ae8efc"]}},"4c3b20f0e82d4eba86c0b088742e2141":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"cd586a112d6e480e97cdf825ee0ece0c":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_1444d3567a354374a47d6a036850877e","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":995526,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":995526,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_d9f5e3cc6db143d5ac8e9f0a17fb5dfb"}},"b129fd46c0644212a593428886ae8efc":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_bd8c602e551a4520a60d78bd985483d7","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 996k/996k [00:00&lt;00:00, 6.75MB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_9d2cc54c26084912b8b74593f3778d1a"}},"1444d3567a354374a47d6a036850877e":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"d9f5e3cc6db143d5ac8e9f0a17fb5dfb":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"bd8c602e551a4520a60d78bd985483d7":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"9d2cc54c26084912b8b74593f3778d1a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"75a1971391584a2c82537563e8d58e15":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_6091ed9b84354b97b4a8adfad5b618a8","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_a74376068b564304b965fab3755ad030","IPY_MODEL_6327f277ad6841d3adf1ac1970fa41c7"]}},"6091ed9b84354b97b4a8adfad5b618a8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"a74376068b564304b965fab3755ad030":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_e8b87f9ca00b4b6fbf9a9ac616da9881","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":29,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":29,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_7483ed33eda74796992fb3ba15553791"}},"6327f277ad6841d3adf1ac1970fa41c7":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_0d67a2cbade44b3594ea3d524c07382e","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 29.0/29.0 [00:00&lt;00:00, 97.4B/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_0b84e91136b84a819293af7f08c59b40"}},"e8b87f9ca00b4b6fbf9a9ac616da9881":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"7483ed33eda74796992fb3ba15553791":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"0d67a2cbade44b3594ea3d524c07382e":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"0b84e91136b84a819293af7f08c59b40":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"bcf59b1743e14f6aa550882ec140aa6f":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_82b367f2291f427b8de2c34c3112ab91","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_820399bdf0b2498a8a997f500b8493ff","IPY_MODEL_72c2d520b47a4b61a5472a4210e3bbbe"]}},"82b367f2291f427b8de2c34c3112ab91":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"820399bdf0b2498a8a997f500b8493ff":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_128c3dacf69e4be99de94377e1dacc57","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":1961828,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":1961828,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_748e772cd01642eb9f045c4adb3e31a6"}},"72c2d520b47a4b61a5472a4210e3bbbe":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_09c1429ee90142d684c990b06bb1a4a3","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 1.96M/1.96M [00:00&lt;00:00, 10.5MB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_4a8a4e48280f4de39c8c38956ad63e4b"}},"128c3dacf69e4be99de94377e1dacc57":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"748e772cd01642eb9f045c4adb3e31a6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"09c1429ee90142d684c990b06bb1a4a3":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"4a8a4e48280f4de39c8c38956ad63e4b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"26ea3145b32e46fd99d97b1371f7e98a":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_07850615519b4311976d2e3e09c8e8a9","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_334e7928320240b39b1505c8d678d761","IPY_MODEL_9825c6859b1b44339da5eec917f812ea"]}},"07850615519b4311976d2e3e09c8e8a9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"334e7928320240b39b1505c8d678d761":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_2136d8c1171f45b9958b1878e57916ef","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":625,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":625,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_4528b1e2f35d4b6c9b4be25e19db57ec"}},"9825c6859b1b44339da5eec917f812ea":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_f0bf4623399b41e488683f3b5628028a","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 625/625 [00:00&lt;00:00, 10.2kB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_3b93e0891dc34ea99aa3496429d87e6c"}},"2136d8c1171f45b9958b1878e57916ef":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"4528b1e2f35d4b6c9b4be25e19db57ec":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"f0bf4623399b41e488683f3b5628028a":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"3b93e0891dc34ea99aa3496429d87e6c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"98fe754cee984cd88775d5a7c0927eec":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_72b08ff86017494b9179ca850dec4687","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_a5c6e8b7403d4afeb74c84b2d6d501bc","IPY_MODEL_b4fc5907165e49f7a5b87ea527bdbe4a"]}},"72b08ff86017494b9179ca850dec4687":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"a5c6e8b7403d4afeb74c84b2d6d501bc":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_b813d9d777574e4e9ce9ef3b3412075e","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":714314041,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":714314041,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_e37c9aa3d5cc4eb19599e736dd8d42fe"}},"b4fc5907165e49f7a5b87ea527bdbe4a":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_8f131eb1844040f9b64dcd9ee49ed1df","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 714M/714M [00:13&lt;00:00, 51.9MB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_6cb49d493f3a4e0fa07aa2786f0a77de"}},"b813d9d777574e4e9ce9ef3b3412075e":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"e37c9aa3d5cc4eb19599e736dd8d42fe":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"8f131eb1844040f9b64dcd9ee49ed1df":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"6cb49d493f3a4e0fa07aa2786f0a77de":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}}}},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"mJD5uYaeQ4-3"},"source":["\n","# NER with BERT"]},{"cell_type":"code","metadata":{"id":"iixnQ1G0Qdfv","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1619600005636,"user_tz":-480,"elapsed":8293,"user":{"displayName":"Kok Meng Tan","photoUrl":"","userId":"03184747090436452828"}},"outputId":"37a0a4ed-4f99-48d5-de61-376e91afa718"},"source":["!pip install transformers seqeval\n","# !pip install -U tensorflow"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Collecting transformers\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d8/b2/57495b5309f09fa501866e225c84532d1fd89536ea62406b2181933fb418/transformers-4.5.1-py3-none-any.whl (2.1MB)\n","\u001b[K     |████████████████████████████████| 2.1MB 14.7MB/s \n","\u001b[?25hCollecting seqeval\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9d/2d/233c79d5b4e5ab1dbf111242299153f3caddddbb691219f363ad55ce783d/seqeval-1.2.2.tar.gz (43kB)\n","\u001b[K     |████████████████████████████████| 51kB 8.0MB/s \n","\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n","Collecting tokenizers<0.11,>=0.10.1\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ae/04/5b870f26a858552025a62f1649c20d29d2672c02ff3c3fb4c688ca46467a/tokenizers-0.10.2-cp37-cp37m-manylinux2010_x86_64.whl (3.3MB)\n","\u001b[K     |████████████████████████████████| 3.3MB 46.9MB/s \n","\u001b[?25hRequirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from transformers) (3.10.1)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers) (20.9)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.0.12)\n","Collecting sacremoses\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/75/ee/67241dc87f266093c533a2d4d3d69438e57d7a90abb216fa076e7d475d4a/sacremoses-0.0.45-py3-none-any.whl (895kB)\n","\u001b[K     |████████████████████████████████| 901kB 48.9MB/s \n","\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.41.1)\n","Requirement already satisfied: scikit-learn>=0.21.3 in /usr/local/lib/python3.7/dist-packages (from seqeval) (0.22.2.post1)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2020.12.5)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.4.1)\n","Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.7.4.3)\n","Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers) (2.4.7)\n","Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.0.1)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n","Requirement already satisfied: scipy>=0.17.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.21.3->seqeval) (1.4.1)\n","Building wheels for collected packages: seqeval\n","  Building wheel for seqeval (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for seqeval: filename=seqeval-1.2.2-cp37-none-any.whl size=16172 sha256=6c7b4d28230fe266746b125e7c23a3e55f53d7dc99286adf54c760a29694bf60\n","  Stored in directory: /root/.cache/pip/wheels/52/df/1b/45d75646c37428f7e626214704a0e35bd3cfc32eda37e59e5f\n","Successfully built seqeval\n","Installing collected packages: tokenizers, sacremoses, transformers, seqeval\n","Successfully installed sacremoses-0.0.45 seqeval-1.2.2 tokenizers-0.10.2 transformers-4.5.1\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"8xsPuzmBZXZK","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1619600053855,"user_tz":-480,"elapsed":53941,"user":{"displayName":"Kok Meng Tan","photoUrl":"","userId":"03184747090436452828"}},"outputId":"a9a920cf-d41e-4ff0-9a44-ac178bdc0f09"},"source":["from google.colab import drive\n","drive.mount(\"/content/drive\")"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"U5fsfxofZL4F"},"source":["# !git clone https://github.com/NVIDIA/apex\n","# !cd apex\n","# !pip install -v --no-cache-dir --global-option=\"--cpp_ext\" --global-option=\"--cuda_ext\" ./"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"gpihnGdvkcL5"},"source":["## Import"]},{"cell_type":"code","metadata":{"id":"pJJNjlkDO9yB","executionInfo":{"status":"ok","timestamp":1619600218902,"user_tz":-480,"elapsed":6634,"user":{"displayName":"Kok Meng Tan","photoUrl":"","userId":"03184747090436452828"}}},"source":["import os\n","import re\n","import time\n","\n","import numpy as np\n","import pandas as pd\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","from torch.utils.data import DataLoader\n","from transformers import (\n","    BertTokenizer, BertForTokenClassification, AdamW,\n","    get_linear_schedule_with_warmup)\n","from seqeval.metrics import accuracy_score, classification_report\n","from tqdm import tqdm, tqdm_notebook\n","from jieba import cut\n","\n","import seaborn as sns\n","import matplotlib.pyplot as plt\n","%matplotlib inline\n","\n","# from apex import amp  # for distributed training in Pytorch\n","# import psutil\n","# from multiprocessing import Pool\n","\n","# NUM_CORES = psutil.cpu_count()  # number of cores on your machine\n","# print(\"number of cores:\", NUM_CORES)\n","\n","# def df_parallelize_run(df, func, num_partitions=20):\n","#     df_split = np.array_split(df, num_partitions)\n","#     pool = Pool(NUM_CORES)\n","#     df = pd.concat(pool.map(func, df_split))\n","#     #df = sp.vstack(pool.map(func, df_split), format=\"csr\") faster and mem efficient for\n","#     pool.close()\n","#     pool.join()\n","#     return df"],"execution_count":3,"outputs":[]},{"cell_type":"code","metadata":{"id":"qeHIthXpJ2ha","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1619600218906,"user_tz":-480,"elapsed":5856,"user":{"displayName":"Kok Meng Tan","photoUrl":"","userId":"03184747090436452828"}},"outputId":"be0ac038-698e-47e1-c75f-17dbd42e1ca0"},"source":["print(\"Pytorch Version: {}\".format(torch.__version__))\n","\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","print(f\"Device: {device}\")\n","if torch.cuda.device_count() > 0:\n","    print(\"Found GPU at: {}\".format(torch.cuda.get_device_name(0)))\n","\n","DATA_DIR = \"drive/MyDrive/Colab Notebooks/data/ner\""],"execution_count":4,"outputs":[{"output_type":"stream","text":["Pytorch Version: 1.8.1+cu101\n","Device: cuda\n","Found GPU at: Tesla T4\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"J4LVCp1fZcpD"},"source":["## Data preprocessing"]},{"cell_type":"code","metadata":{"id":"jq37Cup1A7iZ","executionInfo":{"status":"ok","timestamp":1619600218907,"user_tz":-480,"elapsed":3113,"user":{"displayName":"Kok Meng Tan","photoUrl":"","userId":"03184747090436452828"}}},"source":["def whitespace_punctuation(s):\n","    \"\"\"Add whitespace before punctuation.\"\"\"\n","    s = re.sub(r\"([.,!?()])\", r\" \\1 \", s)\n","    s = re.sub(r\"\\s{2,}\", \" \", s)\n","    return s\n","\n","\n","def word_tagging(raw_line):\n","    \"\"\"\"Tag each word for given line.\"\"\"\n","    raw_line = re.sub(r\"\\t\\d+\\n\", \"\", raw_line)\n","    line_split0 = re.split(r'<ENAMEX TYPE=\"(.*?)\">(.*?)</ENAMEX>', raw_line)\n","\n","    raw_tags = []\n","    line_split1 = []\n","    flag = 0\n","    for x in line_split0:\n","        if x not in [\"PERSON\", \"ORGANIZATION\", \"LOCATION\"]:\n","            if flag == 0:\n","                raw_tags.append(\"O\")\n","            line_split1.append(x)\n","            flag = 0\n","        else:\n","            flag = 1\n","            raw_tags.append(x)\n","\n","    line_split = []\n","    tags = []\n","    for x, t in zip(line_split1, raw_tags):\n","        y = whitespace_punctuation(x).split()\n","        line_split.extend(y)\n","        tags.extend([t] * len(y))\n","    return line_split, tags\n","\n","\n","class InputExample(object):\n","    \"\"\"A single training/test example for simple sequence classification.\"\"\"\n","    def __init__(self, guid, text_a, text_b=None, label=None):\n","        \"\"\"Constructs a InputExample.\n","        Args:\n","            guid: Unique id for the example.\n","            text_a: string. The untokenized text of the first sequence. For single\n","            sequence tasks, only this sequence must be specified.\n","            text_b: (Optional) string. The untokenized text of the second sequence.\n","            Only must be specified for sequence pair tasks.\n","            label: (Optional) string. The label of the example. This should be\n","            specified for train and dev examples, but not for test examples.\n","        \"\"\"\n","        self.guid = guid\n","        self.text_a = text_a\n","        self.text_b = text_b\n","        self.label = label\n","\n","\n","def load_data(file_path):\n","    \"\"\"Load data.\"\"\"\n","    data_examples = []\n","    with open(file_path, \"r\") as f:\n","        for i, raw_line in enumerate(f):\n","            line_split, tags = word_tagging(raw_line)\n","            data_examples.append(InputExample(i, \" \".join(line_split), label=tags))\n","    return data_examples"],"execution_count":5,"outputs":[]},{"cell_type":"code","metadata":{"id":"M0A1xA4PbCUd","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1619600219382,"user_tz":-480,"elapsed":3158,"user":{"displayName":"Kok Meng Tan","photoUrl":"","userId":"03184747090436452828"}},"outputId":"e8a6167c-071c-43e5-df92-9bd00e3c03e8"},"source":["train_examples = load_data(DATA_DIR + \"/ner_train_data.txt\")\n","print(\"Training data size =\", len(train_examples))"],"execution_count":6,"outputs":[{"output_type":"stream","text":["Training data size = 1700\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"fU3g7_feRsIk","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1619600220155,"user_tz":-480,"elapsed":3097,"user":{"displayName":"Kok Meng Tan","photoUrl":"","userId":"03184747090436452828"}},"outputId":"94140ae7-2b1a-420c-af62-436e2896117c"},"source":["val_examples = load_data(DATA_DIR + \"/ner_val_data.txt\")\n","print(\"Validation data size =\", len(val_examples))"],"execution_count":7,"outputs":[{"output_type":"stream","text":["Validation data size = 426\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"BzYWHZAJmHG2","executionInfo":{"status":"ok","timestamp":1619600220156,"user_tz":-480,"elapsed":2229,"user":{"displayName":"Kok Meng Tan","photoUrl":"","userId":"03184747090436452828"}}},"source":["class InputFeatures(object):\n","    \"\"\"A single set of features of data.\"\"\"\n","    def __init__(self, input_ids, input_mask, segment_ids, label_id):\n","        self.input_ids = input_ids\n","        self.input_mask = input_mask\n","        self.segment_ids = segment_ids\n","        self.label_id = label_id\n","\n","\n","def convert_examples_to_features(examples, label_list, max_seq_length, tokenizer,\n","                                 print_examples=False):\n","    \"\"\"Loads a data file into a list of `InputBatch`s.\"\"\"\n","    label_map = {label: i for i, label in enumerate(label_list, 1)}\n","\n","    features = []\n","    for ex_index, example in enumerate(examples):\n","        textlist = example.text_a.split(\" \")\n","        labellist = example.label\n","        if labellist is None:\n","            labellist = [\"O\"] * len(textlist)\n","        tokens = []\n","        labels = []\n","        for i, word in enumerate(textlist):\n","            token = tokenizer.tokenize(word)\n","            tokens.extend(token)\n","            label_1 = labellist[i]\n","            for m in range(len(token)):\n","                if m == 0:\n","                    labels.append(label_1)\n","                else:\n","                    labels.append(\"X\")\n","        if len(tokens) >= max_seq_length - 1:\n","            tokens = tokens[0:(max_seq_length - 2)]\n","            labels = labels[0:(max_seq_length - 2)]\n","        ntokens = []\n","        segment_ids = []\n","        label_id = []\n","        ntokens.append(\"[CLS]\")\n","        segment_ids.append(0)\n","        label_id.append(label_map[\"[CLS]\"])\n","        for i, token in enumerate(tokens):\n","            ntokens.append(token)\n","            segment_ids.append(0)\n","            label_id.append(label_map[labels[i]])\n","        ntokens.append(\"[SEP]\")\n","        segment_ids.append(0)\n","        label_id.append(label_map[\"[SEP]\"])\n","        input_ids = tokenizer.convert_tokens_to_ids(ntokens)\n","        input_mask = [1] * len(input_ids)\n","        while len(input_ids) < max_seq_length:\n","            input_ids.append(0)\n","            input_mask.append(0)\n","            segment_ids.append(0)\n","            label_id.append(0)\n","        assert len(input_ids) == max_seq_length\n","        assert len(input_mask) == max_seq_length\n","        assert len(segment_ids) == max_seq_length\n","        assert len(label_id) == max_seq_length\n","\n","        if print_examples and ex_index < 3:\n","            print(\"*** Example ***\")\n","            print(\"tokens: %s\" % \" \".join([str(x) for x in tokens]))\n","            print(\"input_ids: %s\" % \" \".join([str(x) for x in input_ids]))\n","            print(\"input_mask: %s\" % \" \".join([str(x) for x in input_mask]))\n","            print(\"segment_ids: %s\" % \" \".join([str(x) for x in segment_ids]))\n","\n","        features.append(\n","            InputFeatures(input_ids=input_ids,\n","                          input_mask=input_mask,\n","                          segment_ids=segment_ids,\n","                          label_id=label_id))\n","    return features\n"],"execution_count":8,"outputs":[]},{"cell_type":"code","metadata":{"id":"m3O4FDej7Wxz","executionInfo":{"status":"ok","timestamp":1619600220157,"user_tz":-480,"elapsed":1500,"user":{"displayName":"Kok Meng Tan","photoUrl":"","userId":"03184747090436452828"}}},"source":["PRETRAINED_MODEL_NAME = \"bert-base-multilingual-cased\"\n","MAX_SEQUENCE_LENGTH = 100\n","LABEL_LIST = [\"O\", \"PERSON\", \"ORGANIZATION\", \"LOCATION\", \"[CLS]\", \"[SEP]\", \"X\"]\n","REV_LABEL_MAP = {i: label for i, label in enumerate(LABEL_LIST, 1)}\n","NUM_LABELS = len(LABEL_LIST) + 1\n","EPOCHS = 4\n","BATCH_SIZE = 16\n","LR = 2e-5\n","WARMUP = 0.1\n","LOGGING_STEPS = 20\n","ACCUMULATION_STEPS = 1\n","FINETUNED_MODEL_PATH = \"finetuned_bert.bin\""],"execution_count":9,"outputs":[]},{"cell_type":"code","metadata":{"id":"82GPG0KYe0M_","colab":{"base_uri":"https://localhost:8080/","height":164,"referenced_widgets":["c79417cf92764416adcc675fb52e4190","4c3b20f0e82d4eba86c0b088742e2141","cd586a112d6e480e97cdf825ee0ece0c","b129fd46c0644212a593428886ae8efc","1444d3567a354374a47d6a036850877e","d9f5e3cc6db143d5ac8e9f0a17fb5dfb","bd8c602e551a4520a60d78bd985483d7","9d2cc54c26084912b8b74593f3778d1a","75a1971391584a2c82537563e8d58e15","6091ed9b84354b97b4a8adfad5b618a8","a74376068b564304b965fab3755ad030","6327f277ad6841d3adf1ac1970fa41c7","e8b87f9ca00b4b6fbf9a9ac616da9881","7483ed33eda74796992fb3ba15553791","0d67a2cbade44b3594ea3d524c07382e","0b84e91136b84a819293af7f08c59b40","bcf59b1743e14f6aa550882ec140aa6f","82b367f2291f427b8de2c34c3112ab91","820399bdf0b2498a8a997f500b8493ff","72c2d520b47a4b61a5472a4210e3bbbe","128c3dacf69e4be99de94377e1dacc57","748e772cd01642eb9f045c4adb3e31a6","09c1429ee90142d684c990b06bb1a4a3","4a8a4e48280f4de39c8c38956ad63e4b"]},"executionInfo":{"status":"ok","timestamp":1619600221608,"user_tz":-480,"elapsed":1626,"user":{"displayName":"Kok Meng Tan","photoUrl":"","userId":"03184747090436452828"}},"outputId":"bd47cbff-a249-47cc-8fb9-52005fad4daa"},"source":["bert_tokenizer = BertTokenizer.from_pretrained(PRETRAINED_MODEL_NAME, do_lower_case=False)"],"execution_count":10,"outputs":[{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"c79417cf92764416adcc675fb52e4190","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=995526.0, style=ProgressStyle(descripti…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"75a1971391584a2c82537563e8d58e15","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=29.0, style=ProgressStyle(description_w…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"bcf59b1743e14f6aa550882ec140aa6f","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=1961828.0, style=ProgressStyle(descript…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"M-uI4dFMdoxo","executionInfo":{"status":"ok","timestamp":1619600224972,"user_tz":-480,"elapsed":2768,"user":{"displayName":"Kok Meng Tan","photoUrl":"","userId":"03184747090436452828"}}},"source":["train_features = convert_examples_to_features(\n","    train_examples, LABEL_LIST, MAX_SEQUENCE_LENGTH, bert_tokenizer)"],"execution_count":11,"outputs":[]},{"cell_type":"code","metadata":{"id":"K89qkMf-T-sA","executionInfo":{"status":"ok","timestamp":1619600225436,"user_tz":-480,"elapsed":2514,"user":{"displayName":"Kok Meng Tan","photoUrl":"","userId":"03184747090436452828"}}},"source":["val_features = convert_examples_to_features(\n","    val_examples, LABEL_LIST, MAX_SEQUENCE_LENGTH, bert_tokenizer)"],"execution_count":12,"outputs":[]},{"cell_type":"code","metadata":{"id":"tQ36dbHuXFBI","executionInfo":{"status":"ok","timestamp":1619600225437,"user_tz":-480,"elapsed":1974,"user":{"displayName":"Kok Meng Tan","photoUrl":"","userId":"03184747090436452828"}}},"source":["def get_dataloader(data_features, batch_size, shuffle=False, drop_last=False):\n","    \"\"\"Output dataloader.\"\"\"\n","    data_input_ids = torch.tensor(\n","        [f.input_ids for f in data_features], dtype=torch.long)\n","    data_input_mask = torch.tensor(\n","        [f.input_mask for f in data_features], dtype=torch.long)\n","    data_segment_ids = torch.tensor(\n","        [f.segment_ids for f in data_features], dtype=torch.long)\n","    data_label_id = torch.tensor(\n","        [f.label_id for f in data_features], dtype=torch.long)\n","    data_dataset = torch.utils.data.TensorDataset(\n","        data_input_ids, data_input_mask, data_segment_ids, data_label_id)\n","    data_loader = DataLoader(\n","        data_dataset, batch_size=batch_size, shuffle=shuffle, drop_last=drop_last)\n","    return data_loader\n","    \n","\n","train_loader = get_dataloader(train_features, BATCH_SIZE, shuffle=True)\n","val_loader = get_dataloader(val_features, BATCH_SIZE)"],"execution_count":13,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"DLq2R8Q_RTIY"},"source":["## Train model"]},{"cell_type":"code","metadata":{"id":"hII8b4dCMvO0","colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["26ea3145b32e46fd99d97b1371f7e98a","07850615519b4311976d2e3e09c8e8a9","334e7928320240b39b1505c8d678d761","9825c6859b1b44339da5eec917f812ea","2136d8c1171f45b9958b1878e57916ef","4528b1e2f35d4b6c9b4be25e19db57ec","f0bf4623399b41e488683f3b5628028a","3b93e0891dc34ea99aa3496429d87e6c","98fe754cee984cd88775d5a7c0927eec","72b08ff86017494b9179ca850dec4687","a5c6e8b7403d4afeb74c84b2d6d501bc","b4fc5907165e49f7a5b87ea527bdbe4a","b813d9d777574e4e9ce9ef3b3412075e","e37c9aa3d5cc4eb19599e736dd8d42fe","8f131eb1844040f9b64dcd9ee49ed1df","6cb49d493f3a4e0fa07aa2786f0a77de"]},"executionInfo":{"status":"ok","timestamp":1619600256004,"user_tz":-480,"elapsed":30861,"user":{"displayName":"Kok Meng Tan","photoUrl":"","userId":"03184747090436452828"}},"outputId":"8f9968f5-3736-4db9-f77a-2d8d736f5d8f"},"source":["model = BertForTokenClassification.from_pretrained(\n","    PRETRAINED_MODEL_NAME, num_labels=NUM_LABELS)\n","\n","model.to(device)"],"execution_count":14,"outputs":[{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"26ea3145b32e46fd99d97b1371f7e98a","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=625.0, style=ProgressStyle(description_…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"98fe754cee984cd88775d5a7c0927eec","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=714314041.0, style=ProgressStyle(descri…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"},{"output_type":"stream","text":["Some weights of the model checkpoint at bert-base-multilingual-cased were not used when initializing BertForTokenClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-multilingual-cased and are newly initialized: ['classifier.weight', 'classifier.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"],"name":"stderr"},{"output_type":"execute_result","data":{"text/plain":["BertForTokenClassification(\n","  (bert): BertModel(\n","    (embeddings): BertEmbeddings(\n","      (word_embeddings): Embedding(119547, 768, padding_idx=0)\n","      (position_embeddings): Embedding(512, 768)\n","      (token_type_embeddings): Embedding(2, 768)\n","      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","      (dropout): Dropout(p=0.1, inplace=False)\n","    )\n","    (encoder): BertEncoder(\n","      (layer): ModuleList(\n","        (0): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (1): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (2): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (3): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (4): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (5): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (6): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (7): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (8): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (9): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (10): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (11): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","    )\n","  )\n","  (dropout): Dropout(p=0.1, inplace=False)\n","  (classifier): Linear(in_features=768, out_features=8, bias=True)\n",")"]},"metadata":{"tags":[]},"execution_count":14}]},{"cell_type":"code","metadata":{"id":"bnL1jIaYtaPg","executionInfo":{"status":"ok","timestamp":1619600256007,"user_tz":-480,"elapsed":29993,"user":{"displayName":"Kok Meng Tan","photoUrl":"","userId":"03184747090436452828"}}},"source":["def evaluate_model(model, val_loader, device):\n","    \"\"\"Evaluate model.\"\"\"\n","    val_loss = 0\n","    nb_val_steps = 0\n","    y_true = []\n","    y_pred = []\n","    for batch in val_loader:\n","        batch = tuple(t.to(device) for t in batch)\n","        input_ids, input_mask, segment_ids, label_id = batch\n","\n","        with torch.no_grad():\n","            outputs = model(\n","                input_ids,\n","                token_type_ids=segment_ids,\n","                attention_mask=input_mask,\n","                labels=label_id)\n","            loss, logits = outputs[:2]\n","\n","        val_loss += loss.item()\n","        nb_val_steps += 1\n","\n","        indices = torch.argmax(logits, dim=2).detach().cpu().numpy()\n","        input_mask = input_mask.to(\"cpu\").numpy()\n","        label_id = label_id.to(\"cpu\").numpy()\n","\n","        for i, mask in enumerate(input_mask):\n","            tmp_true = []\n","            tmp_pred = []\n","            for j, m in enumerate(mask):\n","                if j == 0:\n","                    continue\n","                if m:\n","                    if REV_LABEL_MAP[label_id[i][j]] != \"X\":\n","                        tmp_true.append(REV_LABEL_MAP[label_id[i][j]])\n","                        tmp_pred.append(REV_LABEL_MAP[indices[i][j]])\n","                else:\n","                    tmp_true.pop()\n","                    tmp_pred.pop()\n","                    break\n","            y_true.append(tmp_true)\n","            y_pred.append(tmp_pred)\n","\n","    val_loss /= nb_val_steps\n","    val_acc = accuracy_score(y_true, y_pred)\n","    return val_loss, val_acc, y_true, y_pred\n","\n","\n","def train_model(model, train_loader, val_loader, device):\n","    \"\"\"Train model.\"\"\"\n","    max_grad_norm = 1.0\n","    param_optimizer = list(model.named_parameters())\n","    no_decay = [\"bias\", \"LayerNorm.bias\", \"LayerNorm.weight\"]\n","    optimizer_grouped_parameters = [\n","        {\"params\": [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)],\n","         \"weight_decay\": 0.01},\n","        {\"params\": [p for n, p in param_optimizer if any(nd in n for nd in no_decay)],\n","         \"weight_decay\": 0.0}\n","    ]\n","\n","    num_total_steps = int(\n","        EPOCHS * len(train_loader) / ACCUMULATION_STEPS)\n","    num_warmup_steps = WARMUP * num_total_steps\n","    optimizer = AdamW(optimizer_grouped_parameters, lr=LR,\n","                      correct_bias=False)  # To reproduce BertAdam specific behavior set correct_bias=False\n","    scheduler = get_linear_schedule_with_warmup(\n","        optimizer, num_warmup_steps, num_total_steps)  # PyTorch scheduler\n","\n","    best_loss = np.inf\n","    global_step = 0\n","    tr_loss = 0.0\n","    logging_loss = 0.0\n","    model.zero_grad()\n","    for epoch in range(EPOCHS):\n","        # TRAIN loop\n","        t0 = time.time()\n","        model.train()\n","        \n","        for step, batch in enumerate(train_loader):\n","            batch = tuple(t.to(device) for t in batch)\n","            input_ids, input_mask, segment_ids, label_id = batch\n","            # forward pass\n","            outputs = model(\n","                input_ids,\n","                token_type_ids=segment_ids,\n","                attention_mask=input_mask,\n","                labels=label_id)\n","            \n","            loss = outputs[0]\n","            if ACCUMULATION_STEPS > 1:\n","                loss = loss / ACCUMULATION_STEPS\n","\n","            # backward pass\n","            loss.backward()\n","\n","            # Gradient clipping is not in AdamW anymore (so you can use amp without issue)\n","            torch.nn.utils.clip_grad_norm_(model.parameters(), max_grad_norm)\n","\n","            tr_loss += loss.item()\n","\n","            # update parameters\n","            if (step + 1) % ACCUMULATION_STEPS == 0:\n","                optimizer.step()\n","                scheduler.step()\n","                model.zero_grad()  # same as optimizer.zero_grad()\n","                global_step += 1\n","\n","            if global_step % LOGGING_STEPS == 0:\n","                loss_scalar = (tr_loss - logging_loss) / LOGGING_STEPS\n","                logging_loss = tr_loss\n","                print(f\"Epoch {epoch + 1}: global step = {global_step}  train loss = {loss_scalar:.4f}\")\n","\n","        model.eval()\n","        val_loss, val_acc, _, _ = evaluate_model(model, val_loader, device)\n","        print(f\"Epoch {epoch + 1}/{EPOCHS}: elapsed time = {time.time() - t0:.0f}s\"\n","              f\"  val loss = {val_loss:.4f}  val accuracy = {val_acc:.4f}\")\n","        \n","        if val_loss < best_loss:\n","            # Save model artefact\n","            print(f\"Epoch {epoch + 1}: val loss improved from {best_loss:.5f} to {val_loss:.5f}, \"\n","                  f\"saving model to {FINETUNED_MODEL_PATH}\\n\")\n","            best_loss = val_loss\n","            torch.save(model.state_dict(), FINETUNED_MODEL_PATH)\n","        else:\n","            print(f\"Epoch {epoch + 1}: val loss did not improve from {best_loss:.5f}\\n\")\n"],"execution_count":15,"outputs":[]},{"cell_type":"code","metadata":{"id":"TCavPcvt7CSQ","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1619600405015,"user_tz":-480,"elapsed":178006,"user":{"displayName":"Kok Meng Tan","photoUrl":"","userId":"03184747090436452828"}},"outputId":"02c24201-24c4-4177-f70e-cd3769a0e592"},"source":["train_model(model, train_loader, val_loader, device)"],"execution_count":16,"outputs":[{"output_type":"stream","text":["Epoch 1: global step = 20  train loss = 1.3307\n","Epoch 1: global step = 40  train loss = 0.3001\n","Epoch 1: global step = 60  train loss = 0.1180\n","Epoch 1: global step = 80  train loss = 0.0831\n","Epoch 1: global step = 100  train loss = 0.0588\n","Epoch 1/4: elapsed time = 35s  val loss = 0.0771  val accuracy = 0.9612\n","Epoch 1: val loss improved from inf to 0.07708, saving model to finetuned_bert.bin\n","\n","Epoch 2: global step = 120  train loss = 0.0589\n","Epoch 2: global step = 140  train loss = 0.0409\n","Epoch 2: global step = 160  train loss = 0.0416\n","Epoch 2: global step = 180  train loss = 0.0427\n","Epoch 2: global step = 200  train loss = 0.0372\n","Epoch 2/4: elapsed time = 35s  val loss = 0.0619  val accuracy = 0.9739\n","Epoch 2: val loss improved from 0.07708 to 0.06190, saving model to finetuned_bert.bin\n","\n","Epoch 3: global step = 220  train loss = 0.0347\n","Epoch 3: global step = 240  train loss = 0.0187\n","Epoch 3: global step = 260  train loss = 0.0224\n","Epoch 3: global step = 280  train loss = 0.0175\n","Epoch 3: global step = 300  train loss = 0.0157\n","Epoch 3: global step = 320  train loss = 0.0179\n","Epoch 3/4: elapsed time = 36s  val loss = 0.0601  val accuracy = 0.9743\n","Epoch 3: val loss improved from 0.06190 to 0.06007, saving model to finetuned_bert.bin\n","\n","Epoch 4: global step = 340  train loss = 0.0101\n","Epoch 4: global step = 360  train loss = 0.0113\n","Epoch 4: global step = 380  train loss = 0.0104\n","Epoch 4: global step = 400  train loss = 0.0091\n","Epoch 4: global step = 420  train loss = 0.0106\n","Epoch 4/4: elapsed time = 36s  val loss = 0.0634  val accuracy = 0.9742\n","Epoch 4: val loss did not improve from 0.06007\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"r_x5J0ywZOI2","executionInfo":{"status":"ok","timestamp":1619600527428,"user_tz":-480,"elapsed":4151,"user":{"displayName":"Kok Meng Tan","photoUrl":"","userId":"03184747090436452828"}}},"source":["# !cp finetuned_bert.bin drive/MyDrive/Colab\\ Notebooks/models/finetuned_bert.bin"],"execution_count":23,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"lVru-ZmlRWSN"},"source":["## Validation"]},{"cell_type":"code","metadata":{"id":"ng9Pul5kgMmT","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1619600472282,"user_tz":-480,"elapsed":6861,"user":{"displayName":"Kok Meng Tan","photoUrl":"","userId":"03184747090436452828"}},"outputId":"0edee3e3-a72b-4662-f302-401036fb5261"},"source":["model = BertForTokenClassification.from_pretrained(\n","    PRETRAINED_MODEL_NAME, num_labels=NUM_LABELS)\n","model.load_state_dict(torch.load(FINETUNED_MODEL_PATH))\n","model.to(device)\n","model.eval()"],"execution_count":17,"outputs":[{"output_type":"stream","text":["Some weights of the model checkpoint at bert-base-multilingual-cased were not used when initializing BertForTokenClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-multilingual-cased and are newly initialized: ['classifier.weight', 'classifier.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"],"name":"stderr"},{"output_type":"execute_result","data":{"text/plain":["BertForTokenClassification(\n","  (bert): BertModel(\n","    (embeddings): BertEmbeddings(\n","      (word_embeddings): Embedding(119547, 768, padding_idx=0)\n","      (position_embeddings): Embedding(512, 768)\n","      (token_type_embeddings): Embedding(2, 768)\n","      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","      (dropout): Dropout(p=0.1, inplace=False)\n","    )\n","    (encoder): BertEncoder(\n","      (layer): ModuleList(\n","        (0): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (1): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (2): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (3): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (4): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (5): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (6): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (7): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (8): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (9): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (10): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (11): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","    )\n","  )\n","  (dropout): Dropout(p=0.1, inplace=False)\n","  (classifier): Linear(in_features=768, out_features=8, bias=True)\n",")"]},"metadata":{"tags":[]},"execution_count":17}]},{"cell_type":"code","metadata":{"id":"HLZN9OUnKcOx","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1619595878663,"user_tz":-480,"elapsed":24228,"user":{"displayName":"Kok Meng Tan","photoUrl":"","userId":"03184747090436452828"}},"outputId":"ae3ab899-bf1b-4494-eff0-733409860b4f"},"source":["val_loader = get_dataloader(val_features, batch_size=BATCH_SIZE)\n","\n","val_loss, val_acc, y_true, y_pred = evaluate_model(model, val_loader, device)\n","print(f\"Val loss = {val_loss:.4f}  Val accuracy = {val_acc:.4f}\")  # Val loss = 0.0664  Val accuracy = 0.9736"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Val loss = 0.0588  Val accuracy = 0.9719\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"LKDQ9QSAYPgH"},"source":["# with open(\"eval_results.txt\", \"w\") as writer:\n","#     writer.write(classification_report(y_true, y_pred, digits=6))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"G_w5Cp7WlMfQ"},"source":["## Batch scoring"]},{"cell_type":"code","metadata":{"id":"3eVOImytlRtO","executionInfo":{"status":"ok","timestamp":1619600478387,"user_tz":-480,"elapsed":956,"user":{"displayName":"Kok Meng Tan","photoUrl":"","userId":"03184747090436452828"}}},"source":["def split_text(text, lang):\n","    \"\"\"Split text.\"\"\"\n","    if lang in [\"zh-tw\", \"zh-cn\"]:\n","        return [el for el in cut(text, cut_all=False) if el != \" \"]\n","    return whitespace_punctuation(text).split()\n","\n","\n","# def convert_text_to_example(text, lang=None):\n","#     \"\"\"Convert text to input example.\"\"\"\n","#     text_split = split_text(text, lang)\n","#     return InputExample(0, \" \".join(text_split), label=[\"O\"] * len(text_split))\n","\n","\n","def print_text_with_tags(text_split, tags):\n","    # 0 black\n","    # 1 red\n","    # 2 green\n","    # 3 yellow\n","    # 4 blue\n","    # 5 magenta\n","    # 6 cyan\n","    # 7 white\n","    # 9 default\n","\n","    dict_background = {\n","        \"PERSON\": \"\\033[46m\", # cyan\n","        \"ORGANIZATION\": \"\\033[43m\", # yellow\n","        \"LOCATION\": \"\\033[45m\" # magenta\n","    }\n","    for k, v in dict_background.items():\n","        print(v+k+\"\\033[49m\")\n","\n","    print_str = []\n","    for word, tag in zip(text_split, tags):\n","        c = dict_background.get(tag)\n","        if c is not None:\n","            print_str.append(c+word+\"\\033[49m\")\n","        else:\n","            print_str.append(word)\n","        \n","    print(\" \".join(print_str))\n","    return"],"execution_count":18,"outputs":[]},{"cell_type":"code","metadata":{"id":"DKjrAiT6lZsM"},"source":["def batch_score(model, test_loader, device):\n","    \"\"\"Perform batch scoring.\"\"\"\n","    y_pred = []\n","    for batch in test_loader:\n","        batch = tuple(t.to(device) for t in batch)\n","        input_ids, input_mask, segment_ids, label_id = batch\n","\n","        with torch.no_grad():\n","            outputs = model(input_ids, segment_ids, input_mask, labels=None)\n","            logits = outputs[0]\n","        \n","        indices = torch.argmax(logits, dim=2).detach().to(\"cpu\").numpy()\n","        input_mask = input_mask.to(\"cpu\").numpy()\n","        label_id = label_id.to(\"cpu\").numpy()\n","\n","        for i, mask in enumerate(input_mask):\n","            tmp_pred = []\n","            for j, m in enumerate(mask):\n","                if j == 0:\n","                    continue\n","                if m:\n","                    if REV_LABEL_MAP[label_id[i][j]] != \"X\":\n","                        tmp_pred.append(REV_LABEL_MAP[indices[i][j]])\n","                else:\n","                    tmp_pred.pop()\n","                    break\n","            y_pred.append(tmp_pred)\n","    return y_pred"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"pbzZIjdm0HBP"},"source":["test_df = pd.read_csv(DATA_DIR + \"/ner_eval_data.csv\")\n","\n","print(\"Testing data size =\", test_df.shape[0])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"d6jRMx7olRek"},"source":["test_text_splits = []\n","test_examples = []\n","for i in range(test_df.shape[0]):\n","    text_split = split_text(test_df[\"title\"].iloc[i], test_df[\"language_s\"].iloc[i])\n","    test_text_splits.append(text_split)\n","    test_examples.append(\n","        InputExample(0, \" \".join(text_split), label=[\"O\"] * len(text_split)))\n","\n","test_features = convert_examples_to_features(\n","    test_examples, LABEL_LIST, MAX_SEQUENCE_LENGTH, bert_tokenizer)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"beB3jT0flaDc"},"source":["model = BertForTokenClassification.from_pretrained(\n","    PRETRAINED_MODEL_NAME, num_labels=NUM_LABELS)\n","model.load_state_dict(torch.load(FINETUNED_MODEL_PATH))\n","model.to(device)\n","\n","for param in model.parameters():\n","    param.requires_grad = False\n","model.eval()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"KbMKj3U2lZRd"},"source":["test_loader = get_dataloader(test_features, BATCH_SIZE)\n","\n","y_pred = predict(model, test_loader, device)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"AC69cr0K0UcN"},"source":["## Serve"]},{"cell_type":"code","metadata":{"id":"3XZfEs9k0JF8","executionInfo":{"status":"ok","timestamp":1619600483526,"user_tz":-480,"elapsed":1164,"user":{"displayName":"Kok Meng Tan","photoUrl":"","userId":"03184747090436452828"}}},"source":["def predict(text, lang=\"en\"):\n","    \"\"\"Predict.\"\"\"\n","    text_split = split_text(text, lang)\n","    sam_features = convert_examples_to_features(\n","        [InputExample(0, \" \".join(text_split), label=[\"O\"] * len(text_split))],\n","        LABEL_LIST, MAX_SEQUENCE_LENGTH, bert_tokenizer)\n","    \n","    sam_input_ids = torch.tensor([f.input_ids for f in sam_features], dtype=torch.long)\n","    sam_input_mask = torch.tensor([f.input_mask for f in sam_features], dtype=torch.long)\n","    sam_segment_ids = torch.tensor([f.segment_ids for f in sam_features], dtype=torch.long)\n","\n","    with torch.no_grad():\n","        logits = model(sam_input_ids, sam_segment_ids, sam_input_mask, labels=None)[0]\n","        \n","    indices = torch.argmax(logits, dim=2).detach().numpy()[0]\n","    mask = sam_features[0].input_mask\n","    label_id = sam_features[0].label_id\n","\n","    tags = []\n","    for j, m in enumerate(mask):\n","        if j == 0:\n","            continue\n","        if m:\n","            if REV_LABEL_MAP[label_id[j]] != \"X\":\n","                tags.append(REV_LABEL_MAP[indices[j]])\n","        else:\n","            tags.pop()\n","            break\n","    return text_split, tags"],"execution_count":19,"outputs":[]},{"cell_type":"code","metadata":{"id":"g6_3sbJFOPRd","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1619600496849,"user_tz":-480,"elapsed":6441,"user":{"displayName":"Kok Meng Tan","photoUrl":"","userId":"03184747090436452828"}},"outputId":"591c46e6-0c6c-44d9-8daf-db8e1c3909c4"},"source":["model = BertForTokenClassification.from_pretrained(\n","    PRETRAINED_MODEL_NAME, num_labels=NUM_LABELS)\n","model.load_state_dict(torch.load(\"finetuned_bert.bin\", map_location=torch.device(\"cpu\")))\n","model.eval()"],"execution_count":20,"outputs":[{"output_type":"stream","text":["Some weights of the model checkpoint at bert-base-multilingual-cased were not used when initializing BertForTokenClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-multilingual-cased and are newly initialized: ['classifier.weight', 'classifier.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"],"name":"stderr"},{"output_type":"execute_result","data":{"text/plain":["BertForTokenClassification(\n","  (bert): BertModel(\n","    (embeddings): BertEmbeddings(\n","      (word_embeddings): Embedding(119547, 768, padding_idx=0)\n","      (position_embeddings): Embedding(512, 768)\n","      (token_type_embeddings): Embedding(2, 768)\n","      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","      (dropout): Dropout(p=0.1, inplace=False)\n","    )\n","    (encoder): BertEncoder(\n","      (layer): ModuleList(\n","        (0): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (1): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (2): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (3): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (4): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (5): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (6): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (7): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (8): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (9): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (10): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (11): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","    )\n","  )\n","  (dropout): Dropout(p=0.1, inplace=False)\n","  (classifier): Linear(in_features=768, out_features=8, bias=True)\n",")"]},"metadata":{"tags":[]},"execution_count":20}]},{"cell_type":"code","metadata":{"id":"Vgs_2amJ0y_0","executionInfo":{"status":"ok","timestamp":1619600497982,"user_tz":-480,"elapsed":1062,"user":{"displayName":"Kok Meng Tan","photoUrl":"","userId":"03184747090436452828"}}},"source":["# sample_text = \"Mantan Gubernur DKI Jakarta Basuki Tjahaja Purnama atau Ahok menyatakan, dia heran Gubernur Anies Baswedan menerbitkan surat izin mendirikan bangunan (IMB) untuk bangunan di Pulau D, pulau hasil reklamasi, berdasarkan Peraturan Gubernur Nomor 206 Tahun 2016 yang dulu diteken Ahok.\"\n","\n","# sample_text = \"Presiden Joko Widodo membagikan video vlognya bersama Wakil Presiden Jusuf Kalla, di instagram @jokowi. Dalam video, Presiden Jokowi memberikan beberapa pertanyaan kepada Jusuf Kalla mengenai aktivitas selama lebaran. Presiden Jokowi tampak memegang sebuah ponsel berwarna hitam. Jokowi bertanya mengenai aktivitas Jusuf Kalla ketika lebaran. Jusuf Kalla kemudian menjelaskan kalau dirinya hanya istirahat di rumah.\" \\\n","#     + \"Jokowi kemudian melontarkan pertanyaan mengenai makanan favorit Jusuf Kalla saat merayakan lebaran. Jusuf Kalla mengaku rindu pada ayam opor, ketupat, dan sate. Ketika ditanya soal bermain dengan cucu, Jusuf Kalla menjelaskan dirinya memiliki 15 cucu dari kelima putra dan putrinya. Sementara melalui caption-nya, Jokowi menjelaskan bahwa dirinya menerima kedatangan Jusuf Kalla di istana negara, Jakarta. Kedatangan Jusuf Kalla tersebut bermaksud untuk membahas soal pekerjaan juga bercerita kegiatan dalam merayakan lebaran bersama keluarga.\"\n","\n","# sample_text = \"Wakil Presiden Jusuf Kalla memuji langkah safari lebaran yang dilakukan keluarga Ketua Kogasma (Komandan Tugas Bersama) Partai Demokrat Agus Harimukti Yudhoyono dan Eddhie Baskoro Yudhoyono (Ibbas), saat perayaan Hari Raya Idulfitri lalu, ke sejumlah tokoh besar bangsa Indonesia.Diketahui, keluarga generasi kedua dari presiden RI ke-6 Susilo Bambang Yudhoyono (SBY) itu, bertemu dengan \\nPresiden Jokowi, Presiden RI ke-5 Megawati Soekarnoputri, serta Presiden RI ke-3 BJ.Habibie.Menurut JK, pertemuan tersebut, terjalin hangat dan memungkinkan mencairkan suasana politik nasional.\"Itu suatu hal yang baek sebenarnya apabila dalam kondisi lebaran untuk silaturahim dengan siapa saja, justru kita saling memaafkan, ya semua tau bahwa hubungan Bu Mega dengan SBY agak renggang kan. Jadi justru anaknya generasi keduanya bagus, berselfie ria, itu berarti mencairkan suasana politik nasional,\" kata JK di kantor Wapres RI, Jalan Medan Merdeka Utara, Jakarta Pusat, Selasa (11/6/2019).JK menilai, semua pertemuan tak melulu terkait politik.Dari pertemuan-pertemuan tersebut diharapkan, dapat merekatkan kembali silaturahmi antar tokoh bangsa.\"Jadi kita sambut baik pertemuan-pertemuan itu, jangan diliat hanya dari sisi politik tapi dari sisi hubungan-hubungan secara nasional,\" ungkap mantan ketum partai Golkar ini.Pertemuan AHY dan Megawati terlaksana pada 5 Juni 2019 di rumah Megawati, di Teuku Umar, Jakarta Pusat.Baik AHY, Ibbas dan Puan, terlihat hangat dengan berswa foto bersama.\"\n","\n","# sample_text = \"Ir. H. Joko Widodo atau Jokowi adalah Presiden ke-7 Indonesia yang mulai menjabat sejak 20 Oktober 2014. Ia terpilih bersama Wakil Presiden Muhammad Jusuf Kalla dalam Pemilu Presiden 2014 dan kembali terpilih bersama Wakil Presiden Ma'ruf Amin dalam Pemilu Presiden 2019. Jokowi pernah menjabat Gubernur DKI Jakarta sejak 15 Oktober 2012 hingga 16 Oktober 2014 didampingi Basuki Tjahaja Purnama sebagai wakil gubernur. Sebelumnya, ia adalah Wali Kota Surakarta (Solo), sejak 28 Juli 2005 hingga 1 Oktober 2012 didampingi F.X. Hadi Rudyatmo sebagai wakil wali kota. Dua tahun menjalani periode keduanya menjadi Wali Kota Solo, Jokowi ditunjuk oleh partainya, Partai Demokrasi Indonesia Perjuangan (PDI-P), untuk bertarung dalam pemilihan Gubernur DKI Jakarta berpasangan dengan Basuki Tjahaja Purnama (Ahok).\"\n","\n","sample_text = \"Google, headquartered in Mountain View (1600 Amphitheatre Pkwy, Mountain View, CA 940430), unveiled the new Android phone for $799 at the Consumer Electronic Show. Sundar Pichai said in his keynote that users love their new Android phones.\""],"execution_count":21,"outputs":[]},{"cell_type":"code","metadata":{"id":"UJzFt-vIXyDY","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1619600498445,"user_tz":-480,"elapsed":1219,"user":{"displayName":"Kok Meng Tan","photoUrl":"","userId":"03184747090436452828"}},"outputId":"d4c9f575-be06-4fb7-f314-aaf89b90e7c7"},"source":["text_split, tags = predict(sample_text)\n","print_text_with_tags(text_split, tags)"],"execution_count":22,"outputs":[{"output_type":"stream","text":["\u001b[46mPERSON\u001b[49m\n","\u001b[43mORGANIZATION\u001b[49m\n","\u001b[45mLOCATION\u001b[49m\n","\u001b[43mGoogle\u001b[49m , headquartered in \u001b[45mMountain\u001b[49m \u001b[45mView\u001b[49m ( \u001b[45m1600\u001b[49m \u001b[45mAmphitheatre\u001b[49m \u001b[45mPkwy\u001b[49m , \u001b[45mMountain\u001b[49m \u001b[45mView\u001b[49m , \u001b[45mCA\u001b[49m \u001b[45m940430\u001b[49m ) , unveiled the new Android phone for $799 at the Consumer Electronic Show . \u001b[46mSundar\u001b[49m \u001b[46mPichai\u001b[49m said in his keynote that users love their new Android phones .\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"QB3I7baMzHMY"},"source":["sample_text = \"腾讯科技股份有限公司是中國大陸规模最大的互联网公司，1998年11月由马化腾、张志东、陈一丹、许晨晔、曾李青5位创始人共同创立，總部位於深圳南山区騰訊濱海大廈。腾讯业务拓展至社交、娱乐、金融、资讯、工具和平台等不同领域。目前，腾讯拥有中国大陸使用人数最多的社交软件腾讯QQ和微信，以及最大的网络游戏社区腾讯游戏。在電子書領域 ，旗下有閱文集團，運營有QQ讀書和微信讀書。\"\n","\n","# sample_text = \"近日，韩国男团GOT7的成员Jackson王嘉尔（嘎嘎）参加朋友的婚礼，一组迎娶婚礼,伴郎,王嘉尔,彭于晏,Jackson,胡歌,\""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"2ELczKKkxBqP","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1619596381936,"user_tz":-480,"elapsed":1538,"user":{"displayName":"Kok Meng Tan","photoUrl":"","userId":"03184747090436452828"}},"outputId":"d516da17-2036-4deb-8eda-fa1a65a243eb"},"source":["text_split, tags = predict(sample_text, \"zh-cn\")\n","print_text_with_tags(text_split, tags)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["\u001b[46mPERSON\u001b[49m\n","\u001b[43mORGANIZATION\u001b[49m\n","\u001b[45mLOCATION\u001b[49m\n","\u001b[43m腾讯\u001b[49m \u001b[43m科技股份\u001b[49m \u001b[43m有限公司\u001b[49m 是 \u001b[45m中國大陸\u001b[49m 规模 最大 的 互联网 公司 ， 1998 年 11 月 由 \u001b[46m马化腾\u001b[49m 、 \u001b[46m张志东\u001b[49m 、 \u001b[46m陈一丹\u001b[49m 、 \u001b[46m许晨晔\u001b[49m 、 \u001b[46m曾\u001b[49m \u001b[46m李青\u001b[49m 5 位 创始人 共同 创立 ， 總 部位 於 \u001b[45m深圳\u001b[49m \u001b[45m南山区\u001b[49m \u001b[43m騰訊濱\u001b[49m 海大 \u001b[45m廈\u001b[49m 。 \u001b[43m腾讯\u001b[49m 业务 拓展 至 社交 、 娱乐 、 金融 、 资讯 、 工具 和 平台\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"LPCqPtxFxffY"},"source":[""],"execution_count":null,"outputs":[]}]}