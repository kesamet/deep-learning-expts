{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wCNn9vIAivIS"
   },
   "source": [
    "# Seq2seq Language Translation - Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 9998,
     "status": "ok",
     "timestamp": 1535674572335,
     "user": {
      "displayName": "Kok Meng Tan",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "113459036002015692798"
     },
     "user_tz": -480
    },
    "id": "DFM350tOowf1",
    "outputId": "5e114cb8-5d9c-4c7c-b39b-cf6bfc8e99c9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found GPU at: /device:GPU:0\n",
      "TensorFlow Version: 1.10.1\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "device_name = tf.test.gpu_device_name()\n",
    "if device_name != '/device:GPU:0':\n",
    "    raise SystemError('GPU device not found')\n",
    "print('Found GPU at: {}'.format(device_name))\n",
    "print('TensorFlow Version: {}'.format(tf.__version__))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HL7RcyCgPthb"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import copy\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "95KZHwPTvde3"
   },
   "source": [
    "## Downloading the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bt5-RI6pXwvc"
   },
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/content/gdrive')\n",
    "\n",
    "DIRNAME = 'gdrive/My Drive/Colab Notebooks/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ka94FdXWj3CB"
   },
   "source": [
    "## Loading the data and preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "r95t42wIb_ap"
   },
   "outputs": [],
   "source": [
    "# Utility functions\n",
    "CODES = {'<PAD>': 0, '<EOS>': 1, '<UNK>': 2, '<GO>': 3 }\n",
    "\n",
    "\n",
    "def load_data(path):\n",
    "    \"\"\"\n",
    "    Load Dataset from File\n",
    "    \"\"\"\n",
    "    input_file = os.path.join(path)\n",
    "    with open(input_file, 'r', encoding='utf-8') as f:\n",
    "        return f.read()\n",
    "\n",
    "\n",
    "def preprocess_and_save_data(source_path, target_path, text_to_ids):\n",
    "    \"\"\"\n",
    "    Preprocess Text Data.  Save to to file.\n",
    "    \"\"\"\n",
    "    # Preprocess\n",
    "    source_text = load_data(source_path)\n",
    "    target_text = load_data(target_path)\n",
    "\n",
    "    source_text = source_text.lower()\n",
    "    target_text = target_text.lower()\n",
    "\n",
    "    source_vocab_to_int, source_int_to_vocab = create_lookup_tables(source_text)\n",
    "    target_vocab_to_int, target_int_to_vocab = create_lookup_tables(target_text)\n",
    "\n",
    "    source_text, target_text = text_to_ids(source_text, target_text, source_vocab_to_int, target_vocab_to_int)\n",
    "\n",
    "    # Save Data\n",
    "    with open('preprocess.p', 'wb') as out_file:\n",
    "        pickle.dump((\n",
    "            (source_text, target_text),\n",
    "            (source_vocab_to_int, target_vocab_to_int),\n",
    "            (source_int_to_vocab, target_int_to_vocab)), out_file)\n",
    "\n",
    "\n",
    "def load_preprocess():\n",
    "    \"\"\"\n",
    "    Load the Preprocessed Training data and return them in batches of <batch_size> or less\n",
    "    \"\"\"\n",
    "    with open('preprocess.p', mode='rb') as in_file:\n",
    "        return pickle.load(in_file)\n",
    "\n",
    "\n",
    "def create_lookup_tables(text):\n",
    "    \"\"\"\n",
    "    Create lookup tables for vocabulary\n",
    "    \"\"\"\n",
    "    vocab = set(text.split())\n",
    "    vocab_to_int = copy.copy(CODES)\n",
    "\n",
    "    for v_i, v in enumerate(vocab, len(CODES)):\n",
    "        vocab_to_int[v] = v_i\n",
    "\n",
    "    int_to_vocab = {v_i: v for v, v_i in vocab_to_int.items()}\n",
    "\n",
    "    return vocab_to_int, int_to_vocab\n",
    "\n",
    "\n",
    "def save_params(params):\n",
    "    \"\"\"\n",
    "    Save parameters to file\n",
    "    \"\"\"\n",
    "    with open('params.p', 'wb') as out_file:\n",
    "        pickle.dump(params, out_file)\n",
    "\n",
    "\n",
    "def load_params():\n",
    "    \"\"\"\n",
    "    Load parameters from file\n",
    "    \"\"\"\n",
    "    with open('params.p', mode='rb') as in_file:\n",
    "        return pickle.load(in_file)\n",
    "\n",
    "\n",
    "def batch_data(source, target, batch_size):\n",
    "    \"\"\"\n",
    "    Batch source and target together\n",
    "    \"\"\"\n",
    "    for batch_i in range(0, len(source)//batch_size):\n",
    "        start_i = batch_i * batch_size\n",
    "        source_batch = source[start_i:start_i + batch_size]\n",
    "        target_batch = target[start_i:start_i + batch_size]\n",
    "        yield np.array(pad_sentence_batch(source_batch)), np.array(pad_sentence_batch(target_batch))\n",
    "\n",
    "\n",
    "def pad_sentence_batch(sentence_batch):\n",
    "    \"\"\"\n",
    "    Pad sentence with <PAD> id\n",
    "    \"\"\"\n",
    "    max_sentence = max([len(sentence) for sentence in sentence_batch])\n",
    "    return [sentence + [CODES['<PAD>']] * (max_sentence - len(sentence))\n",
    "            for sentence in sentence_batch]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nDsEd2cEjyYZ"
   },
   "outputs": [],
   "source": [
    "source_path = DIRNAME + 'data/small_vocab_en.txt'\n",
    "target_path = DIRNAME + 'data/small_vocab_fr.txt'\n",
    "source_text = load_data(source_path)\n",
    "target_text = load_data(target_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 476
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1176,
     "status": "ok",
     "timestamp": 1535602787629,
     "user": {
      "displayName": "Kok Meng Tan",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "113459036002015692798"
     },
     "user_tz": -480
    },
    "id": "Fuqi8kX0jmap",
    "outputId": "ecdcc4fc-2c72-432d-dcfb-a3eb33e13780"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Approximate number of unique words: 227\n",
      "Number of sentences: 137861\n",
      "Average number of words in a sentence: 13.225277634719028\n",
      "\n",
      "English sentences 0 to 10:\n",
      "new jersey is sometimes quiet during autumn , and it is snowy in april .\n",
      "the united states is usually chilly during july , and it is usually freezing in november .\n",
      "california is usually quiet during march , and it is usually hot in june .\n",
      "the united states is sometimes mild during june , and it is cold in september .\n",
      "your least liked fruit is the grape , but my least liked is the apple .\n",
      "his favorite fruit is the orange , but my favorite is the grape .\n",
      "paris is relaxing during december , but it is usually chilly in july .\n",
      "new jersey is busy during spring , and it is never hot in march .\n",
      "our least liked fruit is the lemon , but my least liked is the grape .\n",
      "the united states is sometimes busy during january , and it is sometimes warm in november .\n",
      "\n",
      "French sentences 0 to 10:\n",
      "new jersey est parfois calme pendant l' automne , et il est neigeux en avril .\n",
      "les états-unis est généralement froid en juillet , et il gèle habituellement en novembre .\n",
      "california est généralement calme en mars , et il est généralement chaud en juin .\n",
      "les états-unis est parfois légère en juin , et il fait froid en septembre .\n",
      "votre moins aimé fruit est le raisin , mais mon moins aimé est la pomme .\n",
      "son fruit préféré est l'orange , mais mon préféré est le raisin .\n",
      "paris est relaxant en décembre , mais il est généralement froid en juillet .\n",
      "new jersey est occupé au printemps , et il est jamais chaude en mars .\n",
      "notre fruit est moins aimé le citron , mais mon moins aimé est le raisin .\n",
      "les états-unis est parfois occupé en janvier , et il est parfois chaud en novembre .\n"
     ]
    }
   ],
   "source": [
    "view_sentence_range = (0, 10)\n",
    "\n",
    "print('Approximate number of unique words: {}'.format(len({word: None for word in source_text.split()})))\n",
    "\n",
    "sentences = source_text.split('\\n')\n",
    "word_counts = [len(sentence.split()) for sentence in sentences]\n",
    "print('Number of sentences: {}'.format(len(sentences)))\n",
    "print('Average number of words in a sentence: {}'.format(np.average(word_counts)))\n",
    "\n",
    "print()\n",
    "print('English sentences {} to {}:'.format(*view_sentence_range))\n",
    "print('\\n'.join(source_text.split('\\n')[view_sentence_range[0]:view_sentence_range[1]]))\n",
    "print()\n",
    "print('French sentences {} to {}:'.format(*view_sentence_range))\n",
    "print('\\n'.join(target_text.split('\\n')[view_sentence_range[0]:view_sentence_range[1]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rRylCfl5c2uQ"
   },
   "outputs": [],
   "source": [
    "def text_to_ids(source_text, target_text, source_vocab_to_int, target_vocab_to_int):\n",
    "    \"\"\"\n",
    "    Convert source and target text to proper word ids. The <EOS> word id added at the end of target_text to help\n",
    "    the neural network to predict when the sentence should end.\n",
    "    :param source_text: String that contains all the source text.\n",
    "    :param target_text: String that contains all the target text.\n",
    "    :param source_vocab_to_int: Dictionary to go from the source words to an id\n",
    "    :param target_vocab_to_int: Dictionary to go from the target words to an id\n",
    "    :return: A tuple of lists (source_id_text, target_id_text)\n",
    "    \"\"\"\n",
    "    source_sentences = source_text.lower().split('\\n')\n",
    "    source_text_split = [sentence.split() for sentence in source_sentences]\n",
    "    source_ids = [[source_vocab_to_int[word] for word in sentence] for sentence in source_text_split]\n",
    "    target_sentences = target_text.lower().split('\\n')\n",
    "    target_text_split = [sentence.split() + ['<EOS>'] for sentence in target_sentences]\n",
    "    target_ids = [[target_vocab_to_int[word] for word in sentence] for sentence in target_text_split]\n",
    "    return source_ids, target_ids\n",
    "\n",
    "preprocess_and_save_data(source_path, target_path, text_to_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ps1IGVaGdLPd"
   },
   "source": [
    "## Checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wVB71KqEc_Ze"
   },
   "outputs": [],
   "source": [
    "(source_int_text, target_int_text), (source_vocab_to_int, target_vocab_to_int), _ = load_preprocess()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 952,
     "status": "ok",
     "timestamp": 1535610989146,
     "user": {
      "displayName": "Kok Meng Tan",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "113459036002015692798"
     },
     "user_tz": -480
    },
    "id": "8kYQ9TIhi-am",
    "outputId": "62bdca35-0187-471d-8418-bed6b1c612ab"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(137861, 137861)"
      ]
     },
     "execution_count": 88,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(source_int_text), len(target_int_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_TqUbkvOnUUu"
   },
   "source": [
    "## Creating network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LsHIFwRqdaYy"
   },
   "outputs": [],
   "source": [
    "def model_inputs():\n",
    "    \"\"\"\n",
    "    Create TF Placeholders for input, targets, learning rate, and lengths of source and target sequences.\n",
    "    :return: Tuple (input, targets, learning rate, keep probability, target sequence length,\n",
    "    max target sequence length, source sequence length)\n",
    "    \"\"\"\n",
    "    inputs = tf.placeholder(tf.int32, [None, None], name='input')\n",
    "    targets = tf.placeholder(tf.int32, [None, None], name='targets')\n",
    "    learning_rate = tf.placeholder(tf.float32, [], name='learning_rate')\n",
    "    keep_prob = tf.placeholder(tf.float32, [], name='keep_prob')\n",
    "    target_sequence_length = tf.placeholder(tf.int32, [None], name='target_sequence_length')\n",
    "    max_target_len = tf.reduce_max(target_sequence_length)\n",
    "    source_sequence_length = tf.placeholder(tf.int32, [None], name='source_sequence_length')\n",
    "    return inputs, targets, learning_rate, keep_prob, target_sequence_length, max_target_len, source_sequence_length\n",
    "\n",
    "\n",
    "def process_decoder_input(target_data, target_vocab_to_int, batch_size):\n",
    "    \"\"\"\n",
    "    Preprocess target data for encoding by removing the last word id from each batch in target_data \n",
    "    and concat the GO ID to the beginning of each batch.\n",
    "    :param target_data: Target Placeholder\n",
    "    :param target_vocab_to_int: Dictionary to go from the target words to an id\n",
    "    :param batch_size: Batch Size\n",
    "    :return: Preprocessed target data\n",
    "    \"\"\"\n",
    "    go_id = tf.constant(target_vocab_to_int['<GO>'], shape=(batch_size,1), dtype=tf.int32)\n",
    "    processed_data = tf.concat([go_id, target_data[:,:-1]], axis=1)\n",
    "    return processed_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9V_MdphxduOM"
   },
   "outputs": [],
   "source": [
    "def encoding_layer(rnn_inputs, rnn_size, num_layers, keep_prob, \n",
    "                   source_sequence_length, source_vocab_size, \n",
    "                   encoding_embedding_size):\n",
    "    \"\"\"\n",
    "    Create encoding layer\n",
    "    :param rnn_inputs: Inputs for the RNN\n",
    "    :param rnn_size: RNN Size\n",
    "    :param num_layers: Number of layers\n",
    "    :param keep_prob: Dropout keep probability\n",
    "    :param source_sequence_length: a list of the lengths of each sequence in the batch\n",
    "    :param source_vocab_size: vocabulary size of source data\n",
    "    :param encoding_embedding_size: embedding size of source data\n",
    "    :return: tuple (RNN output, RNN state)\n",
    "    \"\"\"\n",
    "    # Embed the encoder input\n",
    "    embed = tf.contrib.layers.embed_sequence(rnn_inputs, vocab_size=source_vocab_size,\n",
    "                                             embed_dim=encoding_embedding_size)\n",
    "\n",
    "    # RNN cell\n",
    "    def make_cell(rnn_size, keep_prob):\n",
    "        # LSTM cell\n",
    "        lstm = tf.contrib.rnn.LSTMCell(rnn_size)\n",
    "        # Add dropout to the cell\n",
    "        drop = tf.contrib.rnn.DropoutWrapper(lstm, output_keep_prob=keep_prob)\n",
    "        return drop\n",
    "    \n",
    "    # Stack up multiple LSTM layers, for deep learning\n",
    "    cell = tf.contrib.rnn.MultiRNNCell([make_cell(rnn_size, keep_prob) for _ in range(num_layers)])\n",
    "\n",
    "    # Pass cell and embedded input to tf.nn.dynamic.rnn\n",
    "    output, final_state = tf.nn.dynamic_rnn(cell, embed, sequence_length=source_sequence_length, dtype=tf.float32)\n",
    "    return output, final_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Go7wvd4vd3Bg"
   },
   "outputs": [],
   "source": [
    "def decoding_layer_train(encoder_state, dec_cell, dec_embed_input, \n",
    "                         target_sequence_length, max_summary_length, \n",
    "                         output_layer, keep_prob):\n",
    "    \"\"\"\n",
    "    Create a decoding layer for training\n",
    "    :param encoder_state: Encoder State\n",
    "    :param dec_cell: Decoder RNN Cell\n",
    "    :param dec_embed_input: Decoder embedded input\n",
    "    :param target_sequence_length: The lengths of each sequence in the target batch\n",
    "    :param max_summary_length: The length of the longest sequence in the batch\n",
    "    :param output_layer: Function to apply the output layer\n",
    "    :param keep_prob: Dropout keep probability\n",
    "    :return: BasicDecoderOutput containing training logits and sample_id\n",
    "    \"\"\"\n",
    "    training_helper = tf.contrib.seq2seq.TrainingHelper(dec_embed_input, target_sequence_length)\n",
    "    basic_decoder = tf.contrib.seq2seq.BasicDecoder(dec_cell, training_helper, encoder_state, output_layer)\n",
    "    basic_decoder_output, _, _ = tf.contrib.seq2seq.dynamic_decode(basic_decoder, \n",
    "                                                                   maximum_iterations=max_summary_length)\n",
    "    return basic_decoder_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cKwkeSM5d5Sz"
   },
   "outputs": [],
   "source": [
    "def decoding_layer_infer(encoder_state, dec_cell, dec_embeddings, start_of_sequence_id,\n",
    "                         end_of_sequence_id, max_target_sequence_length,\n",
    "                         vocab_size, output_layer, batch_size, keep_prob):\n",
    "    \"\"\"\n",
    "    Create a decoding layer for inference\n",
    "    :param encoder_state: Encoder state\n",
    "    :param dec_cell: Decoder RNN Cell\n",
    "    :param dec_embeddings: Decoder embeddings\n",
    "    :param start_of_sequence_id: GO ID\n",
    "    :param end_of_sequence_id: EOS ID\n",
    "    :param max_target_sequence_length: Maximum length of target sequences\n",
    "    :param vocab_size: Size of decoder/target vocabulary\n",
    "    :param decoding_scope: TensorFlow Variable Scope for decoding\n",
    "    :param output_layer: Function to apply the output layer\n",
    "    :param batch_size: Batch size\n",
    "    :param keep_prob: Dropout keep probability\n",
    "    :return: BasicDecoderOutput containing inference logits and sample_id\n",
    "    \"\"\"\n",
    "    start_tokens = tf.tile(tf.constant([start_of_sequence_id], dtype=tf.int32), \n",
    "                           [batch_size], name='start_tokens')\n",
    "    training_helper = tf.contrib.seq2seq.GreedyEmbeddingHelper(dec_embeddings, start_tokens, end_of_sequence_id)\n",
    "    inference_decoder = tf.contrib.seq2seq.BasicDecoder(dec_cell, training_helper, encoder_state, output_layer)\n",
    "    inference_decoder_output, _, _ = tf.contrib.seq2seq.dynamic_decode(inference_decoder, \n",
    "                                                                       maximum_iterations=max_target_sequence_length)\n",
    "    return inference_decoder_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Tt2KxR6ud9Fz"
   },
   "outputs": [],
   "source": [
    "def decoding_layer(dec_input, encoder_state,\n",
    "                   target_sequence_length, max_target_sequence_length,\n",
    "                   rnn_size,\n",
    "                   num_layers, target_vocab_to_int, target_vocab_size,\n",
    "                   batch_size, keep_prob, decoding_embedding_size):\n",
    "    \"\"\"\n",
    "    Create decoding layer\n",
    "    :param dec_input: Decoder input\n",
    "    :param encoder_state: Encoder state\n",
    "    :param target_sequence_length: The lengths of each sequence in the target batch\n",
    "    :param max_target_sequence_length: Maximum length of target sequences\n",
    "    :param rnn_size: RNN Size\n",
    "    :param num_layers: Number of layers\n",
    "    :param target_vocab_to_int: Dictionary to go from the target words to an id\n",
    "    :param target_vocab_size: Size of target vocabulary\n",
    "    :param batch_size: The size of the batch\n",
    "    :param keep_prob: Dropout keep probability\n",
    "    :param decoding_embedding_size: Decoding embedding size\n",
    "    :return: Tuple of (Training BasicDecoderOutput, Inference BasicDecoderOutput)\n",
    "    \"\"\"\n",
    "    # 1. Decoder Embedding\n",
    "    dec_embeddings = tf.Variable(tf.random_uniform([target_vocab_size, decoding_embedding_size]))\n",
    "    dec_embed_input = tf.nn.embedding_lookup(dec_embeddings, dec_input)\n",
    "\n",
    "    # 2. Construct the decoder cell\n",
    "    def make_cell(rnn_size, keep_prob):\n",
    "        # LSTM cell\n",
    "        lstm = tf.contrib.rnn.LSTMCell(rnn_size)\n",
    "        # Add dropout to the cell\n",
    "        drop = tf.contrib.rnn.DropoutWrapper(lstm, output_keep_prob=keep_prob)\n",
    "        return drop\n",
    "    \n",
    "    # Stack up multiple LSTM layers, for deep learning\n",
    "    dec_cell = tf.contrib.rnn.MultiRNNCell([make_cell(rnn_size, keep_prob) for _ in range(num_layers)])\n",
    "\n",
    "    # 3. Dense layer to translate the decoder's output at each time \n",
    "    # step into a choice from the target vocabulary\n",
    "    output_layer = tf.layers.Dense(\n",
    "        target_vocab_size, kernel_initializer=tf.truncated_normal_initializer(mean=0.0, stddev=0.1))\n",
    "    \n",
    "    with tf.variable_scope('decode'):\n",
    "        tr_decoder_output = decoding_layer_train(encoder_state, dec_cell, dec_embed_input, \n",
    "                                                 target_sequence_length, max_target_sequence_length, \n",
    "                                                 output_layer, keep_prob)\n",
    "        start_of_sequence_id = target_vocab_to_int['<GO>']\n",
    "        end_of_sequence_id = target_vocab_to_int['<EOS>']\n",
    "        inf_decoder_output = decoding_layer_infer(encoder_state, dec_cell, dec_embeddings, start_of_sequence_id,\n",
    "                                                  end_of_sequence_id, max_target_sequence_length,\n",
    "                                                  target_vocab_size, output_layer, batch_size, keep_prob)\n",
    "    return tr_decoder_output, inf_decoder_output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "AlXpGvx1eHAa"
   },
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "goV88PiGeEkR"
   },
   "outputs": [],
   "source": [
    "def seq2seq_model(input_data, target_data, keep_prob, batch_size,\n",
    "                  source_sequence_length, target_sequence_length,\n",
    "                  max_target_sentence_length,\n",
    "                  source_vocab_size, target_vocab_size,\n",
    "                  enc_embedding_size, dec_embedding_size,\n",
    "                  rnn_size, num_layers, target_vocab_to_int):\n",
    "    \"\"\"\n",
    "    Build the Sequence-to-Sequence part of the neural network\n",
    "    :param input_data: Input placeholder\n",
    "    :param target_data: Target placeholder\n",
    "    :param keep_prob: Dropout keep probability placeholder\n",
    "    :param batch_size: Batch Size\n",
    "    :param source_sequence_length: Sequence Lengths of source sequences in the batch\n",
    "    :param target_sequence_length: Sequence Lengths of target sequences in the batch\n",
    "    :param source_vocab_size: Source vocabulary size\n",
    "    :param target_vocab_size: Target vocabulary size\n",
    "    :param enc_embedding_size: Decoder embedding size\n",
    "    :param dec_embedding_size: Encoder embedding size\n",
    "    :param rnn_size: RNN Size\n",
    "    :param num_layers: Number of layers\n",
    "    :param target_vocab_to_int: Dictionary to go from the target words to an id\n",
    "    :return: Tuple of (Training BasicDecoderOutput, Inference BasicDecoderOutput)\n",
    "    \"\"\"\n",
    "    # Pass the input data through the encoder. We'll ignore the encoder output, but use the state\n",
    "    _, enc_state = encoding_layer(input_data, rnn_size, num_layers, keep_prob,  \n",
    "                                  source_sequence_length, source_vocab_size, \n",
    "                                  enc_embedding_size)\n",
    "    \n",
    "    # Prepare the target sequences we'll feed to the decoder in training mode\n",
    "    dec_input = process_decoder_input(target_data, target_vocab_to_int, batch_size)\n",
    "    \n",
    "    # Pass encoder state and decoder inputs to the decoders\n",
    "    tr_decoder_output, inf_decoder_output = decoding_layer(dec_input, enc_state, target_sequence_length, \n",
    "                                                           max_target_sentence_length, rnn_size, num_layers, \n",
    "                                                           target_vocab_to_int, target_vocab_size, \n",
    "                                                           batch_size, keep_prob, \n",
    "                                                           dec_embedding_size)\n",
    "    \n",
    "    return tr_decoder_output, inf_decoder_output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "T8TU6ESUek74"
   },
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "o-Eehkziemfp"
   },
   "outputs": [],
   "source": [
    "# Number of Epochs\n",
    "epochs = 10\n",
    "# Batch Size\n",
    "batch_size = 512\n",
    "# RNN Size\n",
    "rnn_size = 128\n",
    "# Number of Layers\n",
    "num_layers = 2\n",
    "# Embedding Size\n",
    "encoding_embedding_size = 128\n",
    "decoding_embedding_size = 128\n",
    "# Learning Rate\n",
    "learning_rate = 0.001\n",
    "# Dropout Keep Probability\n",
    "keep_probability = 0.55\n",
    "display_step = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CgcR6ioFf3Rl"
   },
   "outputs": [],
   "source": [
    "# %mkdir checkpoints/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "l02DgKjIer5P"
   },
   "outputs": [],
   "source": [
    "# save_path = 'checkpoints/dev'\n",
    "(source_int_text, target_int_text), (source_vocab_to_int, target_vocab_to_int), _ = load_preprocess()\n",
    "max_target_sentence_length = max([len(sentence) for sentence in source_int_text])\n",
    "\n",
    "train_graph = tf.Graph()\n",
    "with train_graph.as_default():\n",
    "    input_data, targets, lr, keep_prob, target_sequence_length, max_target_sequence_length, source_sequence_length = model_inputs()\n",
    "\n",
    "    #sequence_length = tf.placeholder_with_default(max_target_sentence_length, None, name='sequence_length')\n",
    "    input_shape = tf.shape(input_data)\n",
    "\n",
    "    train_logits, inference_logits = seq2seq_model(tf.reverse(input_data, [-1]),\n",
    "                                                   targets,\n",
    "                                                   keep_prob,\n",
    "                                                   batch_size,\n",
    "                                                   source_sequence_length,\n",
    "                                                   target_sequence_length,\n",
    "                                                   max_target_sequence_length,\n",
    "                                                   len(source_vocab_to_int),\n",
    "                                                   len(target_vocab_to_int),\n",
    "                                                   encoding_embedding_size,\n",
    "                                                   decoding_embedding_size,\n",
    "                                                   rnn_size,\n",
    "                                                   num_layers,\n",
    "                                                   target_vocab_to_int)\n",
    "\n",
    "\n",
    "    training_logits = tf.identity(train_logits.rnn_output, name='logits')\n",
    "    inference_logits = tf.identity(inference_logits.sample_id, name='predictions')\n",
    "\n",
    "    masks = tf.sequence_mask(target_sequence_length, max_target_sequence_length, dtype=tf.float32, name='masks')\n",
    "\n",
    "    with tf.name_scope(\"optimization\"):\n",
    "        # Loss function\n",
    "        cost = tf.contrib.seq2seq.sequence_loss(training_logits, targets, masks)\n",
    "\n",
    "        # Optimizer\n",
    "        optimizer = tf.train.AdamOptimizer(lr)\n",
    "\n",
    "        # Gradient Clipping\n",
    "        gradients = optimizer.compute_gradients(cost)\n",
    "        capped_gradients = [(tf.clip_by_value(grad, -1., 1.), var) for grad, var in gradients if grad is not None]\n",
    "        train_op = optimizer.apply_gradients(capped_gradients)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AEaGia3Fe2aO"
   },
   "outputs": [],
   "source": [
    "def pad_sentence_batch(sentence_batch, pad_int):\n",
    "    \"\"\"Pad sentences with <PAD> so that each sentence of a batch has the same length\"\"\"\n",
    "    max_sentence = max([len(sentence) for sentence in sentence_batch])\n",
    "    return [sentence + [pad_int] * (max_sentence - len(sentence)) for sentence in sentence_batch]\n",
    "\n",
    "\n",
    "def get_batches(sources, targets, batch_size, source_pad_int, target_pad_int):\n",
    "    \"\"\"Batch targets, sources, and the lengths of their sentences together\"\"\"\n",
    "    for batch_i in range(0, len(sources)//batch_size):\n",
    "        start_i = batch_i * batch_size\n",
    "\n",
    "        # Slice the right amount for the batch\n",
    "        sources_batch = sources[start_i:start_i + batch_size]\n",
    "        targets_batch = targets[start_i:start_i + batch_size]\n",
    "\n",
    "        # Pad\n",
    "        pad_sources_batch = np.array(pad_sentence_batch(sources_batch, source_pad_int))\n",
    "        pad_targets_batch = np.array(pad_sentence_batch(targets_batch, target_pad_int))\n",
    "\n",
    "        # Need the lengths for the _lengths parameters\n",
    "        pad_targets_lengths = []\n",
    "        for target in pad_targets_batch:\n",
    "            pad_targets_lengths.append(len(target))\n",
    "\n",
    "        pad_source_lengths = []\n",
    "        for source in pad_sources_batch:\n",
    "            pad_source_lengths.append(len(source))\n",
    "\n",
    "        yield pad_sources_batch, pad_targets_batch, pad_source_lengths, pad_targets_lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UvyzCoRse4eJ"
   },
   "outputs": [],
   "source": [
    "train_source = source_int_text[batch_size:]\n",
    "train_target = target_int_text[batch_size:]\n",
    "valid_source = source_int_text[:batch_size]\n",
    "valid_target = target_int_text[:batch_size]\n",
    "(valid_sources_batch, valid_targets_batch, valid_sources_lengths, valid_targets_lengths) = \\\n",
    "    next(get_batches(valid_source,\n",
    "                     valid_target,\n",
    "                     batch_size,\n",
    "                     source_vocab_to_int['<PAD>'],\n",
    "                     target_vocab_to_int['<PAD>']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 45424
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 679451,
     "status": "ok",
     "timestamp": 1517975850953,
     "user": {
      "displayName": "Kok Meng Tan",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "113459036002015692798"
     },
     "user_tz": -480
    },
    "id": "ydhc7rTle-K3",
    "outputId": "632a27d8-9a95-457c-dab0-0a3c21d89522"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch   0 Batch    1/269 - Train Accuracy: 0.2329, Validation Accuracy: 0.3097, Loss: 5.7307\n",
      "Epoch   0 Batch    2/269 - Train Accuracy: 0.2655, Validation Accuracy: 0.3096, Loss: 5.5308\n",
      "Epoch   0 Batch    3/269 - Train Accuracy: 0.2444, Validation Accuracy: 0.3096, Loss: 5.3812\n",
      "Epoch   0 Batch    4/269 - Train Accuracy: 0.2317, Validation Accuracy: 0.3096, Loss: 5.2445\n",
      "Epoch   0 Batch    5/269 - Train Accuracy: 0.2324, Validation Accuracy: 0.3096, Loss: 5.0761\n",
      "Epoch   0 Batch    6/269 - Train Accuracy: 0.2785, Validation Accuracy: 0.3096, Loss: 4.7712\n",
      "Epoch   0 Batch    7/269 - Train Accuracy: 0.2765, Validation Accuracy: 0.3096, Loss: 4.6169\n",
      "Epoch   0 Batch    8/269 - Train Accuracy: 0.2531, Validation Accuracy: 0.3212, Loss: 4.6467\n",
      "Epoch   0 Batch    9/269 - Train Accuracy: 0.2827, Validation Accuracy: 0.3248, Loss: 4.4119\n",
      "Epoch   0 Batch   10/269 - Train Accuracy: 0.2664, Validation Accuracy: 0.3404, Loss: 4.4268\n",
      "Epoch   0 Batch   11/269 - Train Accuracy: 0.3055, Validation Accuracy: 0.3411, Loss: 4.1408\n",
      "Epoch   0 Batch   12/269 - Train Accuracy: 0.2791, Validation Accuracy: 0.3421, Loss: 4.1846\n",
      "Epoch   0 Batch   13/269 - Train Accuracy: 0.3438, Validation Accuracy: 0.3424, Loss: 3.8091\n",
      "Epoch   0 Batch   14/269 - Train Accuracy: 0.3053, Validation Accuracy: 0.3428, Loss: 3.8993\n",
      "Epoch   0 Batch   15/269 - Train Accuracy: 0.2961, Validation Accuracy: 0.3427, Loss: 3.8458\n",
      "Epoch   0 Batch   16/269 - Train Accuracy: 0.3118, Validation Accuracy: 0.3428, Loss: 3.7169\n",
      "Epoch   0 Batch   17/269 - Train Accuracy: 0.3037, Validation Accuracy: 0.3446, Loss: 3.6803\n",
      "Epoch   0 Batch   18/269 - Train Accuracy: 0.2771, Validation Accuracy: 0.3495, Loss: 3.7842\n",
      "Epoch   0 Batch   19/269 - Train Accuracy: 0.3485, Validation Accuracy: 0.3509, Loss: 3.3934\n",
      "Epoch   0 Batch   20/269 - Train Accuracy: 0.2956, Validation Accuracy: 0.3593, Loss: 3.6352\n",
      "Epoch   0 Batch   21/269 - Train Accuracy: 0.3103, Validation Accuracy: 0.3709, Loss: 3.6039\n",
      "Epoch   0 Batch   22/269 - Train Accuracy: 0.3575, Validation Accuracy: 0.3831, Loss: 3.3678\n",
      "Epoch   0 Batch   23/269 - Train Accuracy: 0.3528, Validation Accuracy: 0.3689, Loss: 3.2961\n",
      "Epoch   0 Batch   24/269 - Train Accuracy: 0.3344, Validation Accuracy: 0.3925, Loss: 3.4626\n",
      "Epoch   0 Batch   25/269 - Train Accuracy: 0.3432, Validation Accuracy: 0.4019, Loss: 3.4060\n",
      "Epoch   0 Batch   26/269 - Train Accuracy: 0.4054, Validation Accuracy: 0.4049, Loss: 3.0860\n",
      "Epoch   0 Batch   27/269 - Train Accuracy: 0.3711, Validation Accuracy: 0.4045, Loss: 3.2082\n",
      "Epoch   0 Batch   28/269 - Train Accuracy: 0.3426, Validation Accuracy: 0.4152, Loss: 3.3693\n",
      "Epoch   0 Batch   29/269 - Train Accuracy: 0.3679, Validation Accuracy: 0.4278, Loss: 3.2892\n",
      "Epoch   0 Batch   30/269 - Train Accuracy: 0.3918, Validation Accuracy: 0.4262, Loss: 3.1306\n",
      "Epoch   0 Batch   31/269 - Train Accuracy: 0.3875, Validation Accuracy: 0.4126, Loss: 3.0775\n",
      "Epoch   0 Batch   32/269 - Train Accuracy: 0.3683, Validation Accuracy: 0.4061, Loss: 3.1032\n",
      "Epoch   0 Batch   33/269 - Train Accuracy: 0.3830, Validation Accuracy: 0.4094, Loss: 3.0157\n",
      "Epoch   0 Batch   34/269 - Train Accuracy: 0.3755, Validation Accuracy: 0.4054, Loss: 3.0365\n",
      "Epoch   0 Batch   35/269 - Train Accuracy: 0.3812, Validation Accuracy: 0.4070, Loss: 2.9981\n",
      "Epoch   0 Batch   36/269 - Train Accuracy: 0.3855, Validation Accuracy: 0.4118, Loss: 2.9970\n",
      "Epoch   0 Batch   37/269 - Train Accuracy: 0.3893, Validation Accuracy: 0.4133, Loss: 2.9791\n",
      "Epoch   0 Batch   38/269 - Train Accuracy: 0.3801, Validation Accuracy: 0.4128, Loss: 2.9682\n",
      "Epoch   0 Batch   39/269 - Train Accuracy: 0.3826, Validation Accuracy: 0.4165, Loss: 2.9441\n",
      "Epoch   0 Batch   40/269 - Train Accuracy: 0.3567, Validation Accuracy: 0.4164, Loss: 3.0475\n",
      "Epoch   0 Batch   41/269 - Train Accuracy: 0.3917, Validation Accuracy: 0.4231, Loss: 2.9194\n",
      "Epoch   0 Batch   42/269 - Train Accuracy: 0.4258, Validation Accuracy: 0.4290, Loss: 2.7753\n",
      "Epoch   0 Batch   43/269 - Train Accuracy: 0.3797, Validation Accuracy: 0.4314, Loss: 2.9806\n",
      "Epoch   0 Batch   44/269 - Train Accuracy: 0.4150, Validation Accuracy: 0.4375, Loss: 2.8339\n",
      "Epoch   0 Batch   45/269 - Train Accuracy: 0.3840, Validation Accuracy: 0.4396, Loss: 2.9687\n",
      "Epoch   0 Batch   46/269 - Train Accuracy: 0.3773, Validation Accuracy: 0.4388, Loss: 3.0117\n",
      "Epoch   0 Batch   47/269 - Train Accuracy: 0.4459, Validation Accuracy: 0.4418, Loss: 2.6833\n",
      "Epoch   0 Batch   48/269 - Train Accuracy: 0.4202, Validation Accuracy: 0.4441, Loss: 2.7806\n",
      "Epoch   0 Batch   49/269 - Train Accuracy: 0.3886, Validation Accuracy: 0.4420, Loss: 2.9120\n",
      "Epoch   0 Batch   50/269 - Train Accuracy: 0.3933, Validation Accuracy: 0.4490, Loss: 2.9027\n",
      "Epoch   0 Batch   51/269 - Train Accuracy: 0.4196, Validation Accuracy: 0.4512, Loss: 2.7950\n",
      "Epoch   0 Batch   52/269 - Train Accuracy: 0.4181, Validation Accuracy: 0.4464, Loss: 2.7454\n",
      "Epoch   0 Batch   53/269 - Train Accuracy: 0.4112, Validation Accuracy: 0.4613, Loss: 2.8753\n",
      "Epoch   0 Batch   54/269 - Train Accuracy: 0.4105, Validation Accuracy: 0.4576, Loss: 2.8632\n",
      "Epoch   0 Batch   55/269 - Train Accuracy: 0.4272, Validation Accuracy: 0.4574, Loss: 2.7159\n",
      "Epoch   0 Batch   56/269 - Train Accuracy: 0.4344, Validation Accuracy: 0.4546, Loss: 2.6972\n",
      "Epoch   0 Batch   57/269 - Train Accuracy: 0.4343, Validation Accuracy: 0.4594, Loss: 2.6928\n",
      "Epoch   0 Batch   58/269 - Train Accuracy: 0.4373, Validation Accuracy: 0.4547, Loss: 2.6804\n",
      "Epoch   0 Batch   59/269 - Train Accuracy: 0.4339, Validation Accuracy: 0.4598, Loss: 2.6628\n",
      "Epoch   0 Batch   60/269 - Train Accuracy: 0.4419, Validation Accuracy: 0.4602, Loss: 2.5923\n",
      "Epoch   0 Batch   61/269 - Train Accuracy: 0.4611, Validation Accuracy: 0.4585, Loss: 2.5300\n",
      "Epoch   0 Batch   62/269 - Train Accuracy: 0.4561, Validation Accuracy: 0.4606, Loss: 2.5535\n",
      "Epoch   0 Batch   63/269 - Train Accuracy: 0.4390, Validation Accuracy: 0.4624, Loss: 2.6278\n",
      "Epoch   0 Batch   64/269 - Train Accuracy: 0.4353, Validation Accuracy: 0.4631, Loss: 2.6328\n",
      "Epoch   0 Batch   65/269 - Train Accuracy: 0.4463, Validation Accuracy: 0.4706, Loss: 2.5982\n",
      "Epoch   0 Batch   66/269 - Train Accuracy: 0.4627, Validation Accuracy: 0.4710, Loss: 2.5276\n",
      "Epoch   0 Batch   67/269 - Train Accuracy: 0.4407, Validation Accuracy: 0.4712, Loss: 2.6026\n",
      "Epoch   0 Batch   68/269 - Train Accuracy: 0.4401, Validation Accuracy: 0.4713, Loss: 2.5924\n",
      "Epoch   0 Batch   69/269 - Train Accuracy: 0.4164, Validation Accuracy: 0.4730, Loss: 2.7385\n",
      "Epoch   0 Batch   70/269 - Train Accuracy: 0.4541, Validation Accuracy: 0.4719, Loss: 2.5397\n",
      "Epoch   0 Batch   71/269 - Train Accuracy: 0.4105, Validation Accuracy: 0.4655, Loss: 2.6919\n",
      "Epoch   0 Batch   72/269 - Train Accuracy: 0.4368, Validation Accuracy: 0.4384, Loss: 2.4793\n",
      "Epoch   0 Batch   73/269 - Train Accuracy: 0.4366, Validation Accuracy: 0.4632, Loss: 2.6039\n",
      "Epoch   0 Batch   74/269 - Train Accuracy: 0.4311, Validation Accuracy: 0.4733, Loss: 2.6498\n",
      "Epoch   0 Batch   75/269 - Train Accuracy: 0.4231, Validation Accuracy: 0.4463, Loss: 2.5237\n",
      "Epoch   0 Batch   76/269 - Train Accuracy: 0.4372, Validation Accuracy: 0.4736, Loss: 2.5935\n",
      "Epoch   0 Batch   77/269 - Train Accuracy: 0.4448, Validation Accuracy: 0.4677, Loss: 2.5087\n",
      "Epoch   0 Batch   78/269 - Train Accuracy: 0.4422, Validation Accuracy: 0.4666, Loss: 2.5723\n",
      "Epoch   0 Batch   79/269 - Train Accuracy: 0.4393, Validation Accuracy: 0.4640, Loss: 2.5245\n",
      "Epoch   0 Batch   80/269 - Train Accuracy: 0.4581, Validation Accuracy: 0.4767, Loss: 2.4465\n",
      "Epoch   0 Batch   81/269 - Train Accuracy: 0.4495, Validation Accuracy: 0.4770, Loss: 2.5036\n",
      "Epoch   0 Batch   82/269 - Train Accuracy: 0.4556, Validation Accuracy: 0.4680, Loss: 2.4414\n",
      "Epoch   0 Batch   83/269 - Train Accuracy: 0.4537, Validation Accuracy: 0.4708, Loss: 2.4432\n",
      "Epoch   0 Batch   84/269 - Train Accuracy: 0.4559, Validation Accuracy: 0.4814, Loss: 2.4639\n",
      "Epoch   0 Batch   85/269 - Train Accuracy: 0.4509, Validation Accuracy: 0.4826, Loss: 2.4672\n",
      "Epoch   0 Batch   86/269 - Train Accuracy: 0.4508, Validation Accuracy: 0.4748, Loss: 2.4866\n",
      "Epoch   0 Batch   87/269 - Train Accuracy: 0.4241, Validation Accuracy: 0.4816, Loss: 2.6288\n",
      "Epoch   0 Batch   88/269 - Train Accuracy: 0.4634, Validation Accuracy: 0.4808, Loss: 2.4280\n",
      "Epoch   0 Batch   89/269 - Train Accuracy: 0.4666, Validation Accuracy: 0.4849, Loss: 2.4327\n",
      "Epoch   0 Batch   90/269 - Train Accuracy: 0.4226, Validation Accuracy: 0.4744, Loss: 2.5616\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch   0 Batch   91/269 - Train Accuracy: 0.4642, Validation Accuracy: 0.4877, Loss: 2.4165\n",
      "Epoch   0 Batch   92/269 - Train Accuracy: 0.4452, Validation Accuracy: 0.4711, Loss: 2.4022\n",
      "Epoch   0 Batch   93/269 - Train Accuracy: 0.4801, Validation Accuracy: 0.4881, Loss: 2.3428\n",
      "Epoch   0 Batch   94/269 - Train Accuracy: 0.4619, Validation Accuracy: 0.4766, Loss: 2.3927\n",
      "Epoch   0 Batch   95/269 - Train Accuracy: 0.4681, Validation Accuracy: 0.4871, Loss: 2.3975\n",
      "Epoch   0 Batch   96/269 - Train Accuracy: 0.4488, Validation Accuracy: 0.4786, Loss: 2.3740\n",
      "Epoch   0 Batch   97/269 - Train Accuracy: 0.4594, Validation Accuracy: 0.4842, Loss: 2.3805\n",
      "Epoch   0 Batch   98/269 - Train Accuracy: 0.4799, Validation Accuracy: 0.4861, Loss: 2.3209\n",
      "Epoch   0 Batch   99/269 - Train Accuracy: 0.4396, Validation Accuracy: 0.4933, Loss: 2.4860\n",
      "Epoch   0 Batch  100/269 - Train Accuracy: 0.4657, Validation Accuracy: 0.4756, Loss: 2.2885\n",
      "Epoch   0 Batch  101/269 - Train Accuracy: 0.4299, Validation Accuracy: 0.4838, Loss: 2.4645\n",
      "Epoch   0 Batch  102/269 - Train Accuracy: 0.4733, Validation Accuracy: 0.4956, Loss: 2.3253\n",
      "Epoch   0 Batch  103/269 - Train Accuracy: 0.4602, Validation Accuracy: 0.4874, Loss: 2.3154\n",
      "Epoch   0 Batch  104/269 - Train Accuracy: 0.4439, Validation Accuracy: 0.4798, Loss: 2.3136\n",
      "Epoch   0 Batch  105/269 - Train Accuracy: 0.4490, Validation Accuracy: 0.4810, Loss: 2.3254\n",
      "Epoch   0 Batch  106/269 - Train Accuracy: 0.4533, Validation Accuracy: 0.4858, Loss: 2.3232\n",
      "Epoch   0 Batch  107/269 - Train Accuracy: 0.4198, Validation Accuracy: 0.4846, Loss: 2.4361\n",
      "Epoch   0 Batch  108/269 - Train Accuracy: 0.4366, Validation Accuracy: 0.4690, Loss: 2.2934\n",
      "Epoch   0 Batch  109/269 - Train Accuracy: 0.4438, Validation Accuracy: 0.4809, Loss: 2.2939\n",
      "Epoch   0 Batch  110/269 - Train Accuracy: 0.4576, Validation Accuracy: 0.4883, Loss: 2.2674\n",
      "Epoch   0 Batch  111/269 - Train Accuracy: 0.4231, Validation Accuracy: 0.4817, Loss: 2.4045\n",
      "Epoch   0 Batch  112/269 - Train Accuracy: 0.4362, Validation Accuracy: 0.4715, Loss: 2.2456\n",
      "Epoch   0 Batch  113/269 - Train Accuracy: 0.4770, Validation Accuracy: 0.4840, Loss: 2.1489\n",
      "Epoch   0 Batch  114/269 - Train Accuracy: 0.4644, Validation Accuracy: 0.4935, Loss: 2.2358\n",
      "Epoch   0 Batch  115/269 - Train Accuracy: 0.4258, Validation Accuracy: 0.4842, Loss: 2.3365\n",
      "Epoch   0 Batch  116/269 - Train Accuracy: 0.4600, Validation Accuracy: 0.4818, Loss: 2.2219\n",
      "Epoch   0 Batch  117/269 - Train Accuracy: 0.4558, Validation Accuracy: 0.4887, Loss: 2.2173\n",
      "Epoch   0 Batch  118/269 - Train Accuracy: 0.4833, Validation Accuracy: 0.4904, Loss: 2.1403\n",
      "Epoch   0 Batch  119/269 - Train Accuracy: 0.4347, Validation Accuracy: 0.4801, Loss: 2.2973\n",
      "Epoch   0 Batch  120/269 - Train Accuracy: 0.4294, Validation Accuracy: 0.4845, Loss: 2.2980\n",
      "Epoch   0 Batch  121/269 - Train Accuracy: 0.4629, Validation Accuracy: 0.4916, Loss: 2.1865\n",
      "Epoch   0 Batch  122/269 - Train Accuracy: 0.4697, Validation Accuracy: 0.4891, Loss: 2.1535\n",
      "Epoch   0 Batch  123/269 - Train Accuracy: 0.4170, Validation Accuracy: 0.4820, Loss: 2.2843\n",
      "Epoch   0 Batch  124/269 - Train Accuracy: 0.4621, Validation Accuracy: 0.4884, Loss: 2.1467\n",
      "Epoch   0 Batch  125/269 - Train Accuracy: 0.4589, Validation Accuracy: 0.4896, Loss: 2.1310\n",
      "Epoch   0 Batch  126/269 - Train Accuracy: 0.4662, Validation Accuracy: 0.4863, Loss: 2.1068\n",
      "Epoch   0 Batch  127/269 - Train Accuracy: 0.4305, Validation Accuracy: 0.4869, Loss: 2.2428\n",
      "Epoch   0 Batch  128/269 - Train Accuracy: 0.4727, Validation Accuracy: 0.4912, Loss: 2.1059\n",
      "Epoch   0 Batch  129/269 - Train Accuracy: 0.4615, Validation Accuracy: 0.4926, Loss: 2.1289\n",
      "Epoch   0 Batch  130/269 - Train Accuracy: 0.4219, Validation Accuracy: 0.4876, Loss: 2.2529\n",
      "Epoch   0 Batch  131/269 - Train Accuracy: 0.4339, Validation Accuracy: 0.4798, Loss: 2.1778\n",
      "Epoch   0 Batch  132/269 - Train Accuracy: 0.4542, Validation Accuracy: 0.4893, Loss: 2.1036\n",
      "Epoch   0 Batch  133/269 - Train Accuracy: 0.4609, Validation Accuracy: 0.4949, Loss: 2.0800\n",
      "Epoch   0 Batch  134/269 - Train Accuracy: 0.4203, Validation Accuracy: 0.4804, Loss: 2.1572\n",
      "Epoch   0 Batch  135/269 - Train Accuracy: 0.4295, Validation Accuracy: 0.4900, Loss: 2.2119\n",
      "Epoch   0 Batch  136/269 - Train Accuracy: 0.4342, Validation Accuracy: 0.4956, Loss: 2.1762\n",
      "Epoch   0 Batch  137/269 - Train Accuracy: 0.4461, Validation Accuracy: 0.4918, Loss: 2.1589\n",
      "Epoch   0 Batch  138/269 - Train Accuracy: 0.4491, Validation Accuracy: 0.4945, Loss: 2.1084\n",
      "Epoch   0 Batch  139/269 - Train Accuracy: 0.4690, Validation Accuracy: 0.4877, Loss: 2.0098\n",
      "Epoch   0 Batch  140/269 - Train Accuracy: 0.4513, Validation Accuracy: 0.4783, Loss: 2.0181\n",
      "Epoch   0 Batch  141/269 - Train Accuracy: 0.4546, Validation Accuracy: 0.4925, Loss: 2.0643\n",
      "Epoch   0 Batch  142/269 - Train Accuracy: 0.4641, Validation Accuracy: 0.4841, Loss: 2.0008\n",
      "Epoch   0 Batch  143/269 - Train Accuracy: 0.4471, Validation Accuracy: 0.4800, Loss: 2.0073\n",
      "Epoch   0 Batch  144/269 - Train Accuracy: 0.4701, Validation Accuracy: 0.4941, Loss: 1.9852\n",
      "Epoch   0 Batch  145/269 - Train Accuracy: 0.4546, Validation Accuracy: 0.4892, Loss: 1.9935\n",
      "Epoch   0 Batch  146/269 - Train Accuracy: 0.4638, Validation Accuracy: 0.4833, Loss: 1.9606\n",
      "Epoch   0 Batch  147/269 - Train Accuracy: 0.4930, Validation Accuracy: 0.4941, Loss: 1.8924\n",
      "Epoch   0 Batch  148/269 - Train Accuracy: 0.4621, Validation Accuracy: 0.4985, Loss: 2.0112\n",
      "Epoch   0 Batch  149/269 - Train Accuracy: 0.4670, Validation Accuracy: 0.4917, Loss: 1.9591\n",
      "Epoch   0 Batch  150/269 - Train Accuracy: 0.4740, Validation Accuracy: 0.5027, Loss: 1.9583\n",
      "Epoch   0 Batch  151/269 - Train Accuracy: 0.5066, Validation Accuracy: 0.5048, Loss: 1.8504\n",
      "Epoch   0 Batch  152/269 - Train Accuracy: 0.4571, Validation Accuracy: 0.4906, Loss: 1.9427\n",
      "Epoch   0 Batch  153/269 - Train Accuracy: 0.4642, Validation Accuracy: 0.4915, Loss: 1.9216\n",
      "Epoch   0 Batch  154/269 - Train Accuracy: 0.4391, Validation Accuracy: 0.4992, Loss: 2.0348\n",
      "Epoch   0 Batch  155/269 - Train Accuracy: 0.4930, Validation Accuracy: 0.4896, Loss: 1.8122\n",
      "Epoch   0 Batch  156/269 - Train Accuracy: 0.4611, Validation Accuracy: 0.4988, Loss: 1.9618\n",
      "Epoch   0 Batch  157/269 - Train Accuracy: 0.4804, Validation Accuracy: 0.5084, Loss: 1.8918\n",
      "Epoch   0 Batch  158/269 - Train Accuracy: 0.4625, Validation Accuracy: 0.4892, Loss: 1.8633\n",
      "Epoch   0 Batch  159/269 - Train Accuracy: 0.4755, Validation Accuracy: 0.4978, Loss: 1.8876\n",
      "Epoch   0 Batch  160/269 - Train Accuracy: 0.4738, Validation Accuracy: 0.5015, Loss: 1.8765\n",
      "Epoch   0 Batch  161/269 - Train Accuracy: 0.4515, Validation Accuracy: 0.4857, Loss: 1.8825\n",
      "Epoch   0 Batch  162/269 - Train Accuracy: 0.4737, Validation Accuracy: 0.5010, Loss: 1.8499\n",
      "Epoch   0 Batch  163/269 - Train Accuracy: 0.4747, Validation Accuracy: 0.4973, Loss: 1.8507\n",
      "Epoch   0 Batch  164/269 - Train Accuracy: 0.4694, Validation Accuracy: 0.4972, Loss: 1.8445\n",
      "Epoch   0 Batch  165/269 - Train Accuracy: 0.4317, Validation Accuracy: 0.4936, Loss: 1.9097\n",
      "Epoch   0 Batch  166/269 - Train Accuracy: 0.5024, Validation Accuracy: 0.5044, Loss: 1.7287\n",
      "Epoch   0 Batch  167/269 - Train Accuracy: 0.4783, Validation Accuracy: 0.5037, Loss: 1.8130\n",
      "Epoch   0 Batch  168/269 - Train Accuracy: 0.4713, Validation Accuracy: 0.5028, Loss: 1.8250\n",
      "Epoch   0 Batch  169/269 - Train Accuracy: 0.4619, Validation Accuracy: 0.5012, Loss: 1.8118\n",
      "Epoch   0 Batch  170/269 - Train Accuracy: 0.4708, Validation Accuracy: 0.4963, Loss: 1.7925\n",
      "Epoch   0 Batch  171/269 - Train Accuracy: 0.4441, Validation Accuracy: 0.4947, Loss: 1.8487\n",
      "Epoch   0 Batch  172/269 - Train Accuracy: 0.4663, Validation Accuracy: 0.4953, Loss: 1.8013\n",
      "Epoch   0 Batch  173/269 - Train Accuracy: 0.4783, Validation Accuracy: 0.5036, Loss: 1.7879\n",
      "Epoch   0 Batch  174/269 - Train Accuracy: 0.4719, Validation Accuracy: 0.5080, Loss: 1.7809\n",
      "Epoch   0 Batch  175/269 - Train Accuracy: 0.4745, Validation Accuracy: 0.5019, Loss: 1.7791\n",
      "Epoch   0 Batch  176/269 - Train Accuracy: 0.4562, Validation Accuracy: 0.5083, Loss: 1.8513\n",
      "Epoch   0 Batch  177/269 - Train Accuracy: 0.4871, Validation Accuracy: 0.5012, Loss: 1.7144\n",
      "Epoch   0 Batch  178/269 - Train Accuracy: 0.4455, Validation Accuracy: 0.4929, Loss: 1.8198\n",
      "Epoch   0 Batch  179/269 - Train Accuracy: 0.4770, Validation Accuracy: 0.5021, Loss: 1.7460\n",
      "Epoch   0 Batch  180/269 - Train Accuracy: 0.4734, Validation Accuracy: 0.4989, Loss: 1.7186\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch   0 Batch  181/269 - Train Accuracy: 0.4638, Validation Accuracy: 0.4912, Loss: 1.7331\n",
      "Epoch   0 Batch  182/269 - Train Accuracy: 0.4735, Validation Accuracy: 0.5004, Loss: 1.7368\n",
      "Epoch   0 Batch  183/269 - Train Accuracy: 0.5379, Validation Accuracy: 0.4996, Loss: 1.5001\n",
      "Epoch   0 Batch  184/269 - Train Accuracy: 0.4315, Validation Accuracy: 0.4878, Loss: 1.7926\n",
      "Epoch   0 Batch  185/269 - Train Accuracy: 0.4865, Validation Accuracy: 0.5024, Loss: 1.6939\n",
      "Epoch   0 Batch  186/269 - Train Accuracy: 0.4434, Validation Accuracy: 0.4978, Loss: 1.7774\n",
      "Epoch   0 Batch  187/269 - Train Accuracy: 0.4721, Validation Accuracy: 0.4930, Loss: 1.6635\n",
      "Epoch   0 Batch  188/269 - Train Accuracy: 0.4771, Validation Accuracy: 0.4972, Loss: 1.6387\n",
      "Epoch   0 Batch  189/269 - Train Accuracy: 0.4730, Validation Accuracy: 0.4915, Loss: 1.6727\n",
      "Epoch   0 Batch  190/269 - Train Accuracy: 0.4650, Validation Accuracy: 0.4949, Loss: 1.6691\n",
      "Epoch   0 Batch  191/269 - Train Accuracy: 0.4694, Validation Accuracy: 0.4954, Loss: 1.6824\n",
      "Epoch   0 Batch  192/269 - Train Accuracy: 0.4615, Validation Accuracy: 0.4890, Loss: 1.6803\n",
      "Epoch   0 Batch  193/269 - Train Accuracy: 0.4625, Validation Accuracy: 0.4952, Loss: 1.6671\n",
      "Epoch   0 Batch  194/269 - Train Accuracy: 0.4811, Validation Accuracy: 0.5004, Loss: 1.6668\n",
      "Epoch   0 Batch  195/269 - Train Accuracy: 0.4542, Validation Accuracy: 0.4962, Loss: 1.6851\n",
      "Epoch   0 Batch  196/269 - Train Accuracy: 0.4687, Validation Accuracy: 0.4988, Loss: 1.6444\n",
      "Epoch   0 Batch  197/269 - Train Accuracy: 0.4454, Validation Accuracy: 0.4997, Loss: 1.7291\n",
      "Epoch   0 Batch  198/269 - Train Accuracy: 0.4354, Validation Accuracy: 0.4930, Loss: 1.7548\n",
      "Epoch   0 Batch  199/269 - Train Accuracy: 0.4711, Validation Accuracy: 0.5026, Loss: 1.6799\n",
      "Epoch   0 Batch  200/269 - Train Accuracy: 0.4544, Validation Accuracy: 0.4936, Loss: 1.7029\n",
      "Epoch   0 Batch  201/269 - Train Accuracy: 0.4749, Validation Accuracy: 0.4946, Loss: 1.6412\n",
      "Epoch   0 Batch  202/269 - Train Accuracy: 0.4726, Validation Accuracy: 0.5067, Loss: 1.6483\n",
      "Epoch   0 Batch  203/269 - Train Accuracy: 0.4435, Validation Accuracy: 0.4949, Loss: 1.6965\n",
      "Epoch   0 Batch  204/269 - Train Accuracy: 0.4309, Validation Accuracy: 0.4877, Loss: 1.6691\n",
      "Epoch   0 Batch  205/269 - Train Accuracy: 0.4719, Validation Accuracy: 0.5075, Loss: 1.6197\n",
      "Epoch   0 Batch  206/269 - Train Accuracy: 0.4429, Validation Accuracy: 0.4963, Loss: 1.7146\n",
      "Epoch   0 Batch  207/269 - Train Accuracy: 0.4860, Validation Accuracy: 0.4957, Loss: 1.5491\n",
      "Epoch   0 Batch  208/269 - Train Accuracy: 0.4560, Validation Accuracy: 0.5060, Loss: 1.7054\n",
      "Epoch   0 Batch  209/269 - Train Accuracy: 0.4348, Validation Accuracy: 0.4847, Loss: 1.6700\n",
      "Epoch   0 Batch  210/269 - Train Accuracy: 0.4732, Validation Accuracy: 0.4958, Loss: 1.5946\n",
      "Epoch   0 Batch  211/269 - Train Accuracy: 0.4902, Validation Accuracy: 0.5140, Loss: 1.5826\n",
      "Epoch   0 Batch  212/269 - Train Accuracy: 0.4808, Validation Accuracy: 0.4912, Loss: 1.5541\n",
      "Epoch   0 Batch  213/269 - Train Accuracy: 0.4696, Validation Accuracy: 0.4959, Loss: 1.5674\n",
      "Epoch   0 Batch  214/269 - Train Accuracy: 0.4868, Validation Accuracy: 0.5069, Loss: 1.5699\n",
      "Epoch   0 Batch  215/269 - Train Accuracy: 0.5084, Validation Accuracy: 0.5035, Loss: 1.4892\n",
      "Epoch   0 Batch  216/269 - Train Accuracy: 0.4437, Validation Accuracy: 0.5053, Loss: 1.6797\n",
      "Epoch   0 Batch  217/269 - Train Accuracy: 0.4560, Validation Accuracy: 0.5083, Loss: 1.6389\n",
      "Epoch   0 Batch  218/269 - Train Accuracy: 0.4555, Validation Accuracy: 0.4997, Loss: 1.6363\n",
      "Epoch   0 Batch  219/269 - Train Accuracy: 0.4485, Validation Accuracy: 0.4939, Loss: 1.6065\n",
      "Epoch   0 Batch  220/269 - Train Accuracy: 0.4994, Validation Accuracy: 0.5129, Loss: 1.4988\n",
      "Epoch   0 Batch  221/269 - Train Accuracy: 0.4962, Validation Accuracy: 0.5098, Loss: 1.5395\n",
      "Epoch   0 Batch  222/269 - Train Accuracy: 0.4832, Validation Accuracy: 0.5021, Loss: 1.4967\n",
      "Epoch   0 Batch  223/269 - Train Accuracy: 0.4917, Validation Accuracy: 0.5088, Loss: 1.5009\n",
      "Epoch   0 Batch  224/269 - Train Accuracy: 0.4878, Validation Accuracy: 0.5059, Loss: 1.5443\n",
      "Epoch   0 Batch  225/269 - Train Accuracy: 0.4512, Validation Accuracy: 0.4964, Loss: 1.5833\n",
      "Epoch   0 Batch  226/269 - Train Accuracy: 0.4780, Validation Accuracy: 0.5023, Loss: 1.5219\n",
      "Epoch   0 Batch  227/269 - Train Accuracy: 0.5535, Validation Accuracy: 0.5048, Loss: 1.3327\n",
      "Epoch   0 Batch  228/269 - Train Accuracy: 0.4632, Validation Accuracy: 0.4925, Loss: 1.5375\n",
      "Epoch   0 Batch  229/269 - Train Accuracy: 0.4684, Validation Accuracy: 0.4980, Loss: 1.5073\n",
      "Epoch   0 Batch  230/269 - Train Accuracy: 0.4668, Validation Accuracy: 0.5061, Loss: 1.5245\n",
      "Epoch   0 Batch  231/269 - Train Accuracy: 0.4264, Validation Accuracy: 0.4909, Loss: 1.5924\n",
      "Epoch   0 Batch  232/269 - Train Accuracy: 0.4271, Validation Accuracy: 0.4973, Loss: 1.5765\n",
      "Epoch   0 Batch  233/269 - Train Accuracy: 0.4736, Validation Accuracy: 0.5063, Loss: 1.5119\n",
      "Epoch   0 Batch  234/269 - Train Accuracy: 0.4594, Validation Accuracy: 0.4988, Loss: 1.5090\n",
      "Epoch   0 Batch  235/269 - Train Accuracy: 0.4739, Validation Accuracy: 0.4978, Loss: 1.5098\n",
      "Epoch   0 Batch  236/269 - Train Accuracy: 0.4674, Validation Accuracy: 0.4994, Loss: 1.4912\n",
      "Epoch   0 Batch  237/269 - Train Accuracy: 0.4601, Validation Accuracy: 0.4889, Loss: 1.4847\n",
      "Epoch   0 Batch  238/269 - Train Accuracy: 0.4622, Validation Accuracy: 0.4828, Loss: 1.4796\n",
      "Epoch   0 Batch  239/269 - Train Accuracy: 0.4765, Validation Accuracy: 0.4980, Loss: 1.4656\n",
      "Epoch   0 Batch  240/269 - Train Accuracy: 0.5023, Validation Accuracy: 0.4958, Loss: 1.3864\n",
      "Epoch   0 Batch  241/269 - Train Accuracy: 0.4715, Validation Accuracy: 0.4893, Loss: 1.4672\n",
      "Epoch   0 Batch  242/269 - Train Accuracy: 0.4668, Validation Accuracy: 0.4973, Loss: 1.4718\n",
      "Epoch   0 Batch  243/269 - Train Accuracy: 0.4749, Validation Accuracy: 0.4899, Loss: 1.4359\n",
      "Epoch   0 Batch  244/269 - Train Accuracy: 0.4467, Validation Accuracy: 0.4829, Loss: 1.4372\n",
      "Epoch   0 Batch  245/269 - Train Accuracy: 0.4188, Validation Accuracy: 0.4761, Loss: 1.5357\n",
      "Epoch   0 Batch  246/269 - Train Accuracy: 0.4571, Validation Accuracy: 0.4941, Loss: 1.4592\n",
      "Epoch   0 Batch  247/269 - Train Accuracy: 0.4379, Validation Accuracy: 0.4866, Loss: 1.5147\n",
      "Epoch   0 Batch  248/269 - Train Accuracy: 0.4319, Validation Accuracy: 0.4743, Loss: 1.4494\n",
      "Epoch   0 Batch  249/269 - Train Accuracy: 0.4787, Validation Accuracy: 0.4699, Loss: 1.3899\n",
      "Epoch   0 Batch  250/269 - Train Accuracy: 0.4313, Validation Accuracy: 0.4672, Loss: 1.4867\n",
      "Epoch   0 Batch  251/269 - Train Accuracy: 0.4382, Validation Accuracy: 0.4648, Loss: 1.4275\n",
      "Epoch   0 Batch  252/269 - Train Accuracy: 0.4182, Validation Accuracy: 0.4644, Loss: 1.4530\n",
      "Epoch   0 Batch  253/269 - Train Accuracy: 0.4295, Validation Accuracy: 0.4656, Loss: 1.4364\n",
      "Epoch   0 Batch  254/269 - Train Accuracy: 0.4262, Validation Accuracy: 0.4691, Loss: 1.4148\n",
      "Epoch   0 Batch  255/269 - Train Accuracy: 0.4700, Validation Accuracy: 0.4688, Loss: 1.3680\n",
      "Epoch   0 Batch  256/269 - Train Accuracy: 0.4181, Validation Accuracy: 0.4628, Loss: 1.4478\n",
      "Epoch   0 Batch  257/269 - Train Accuracy: 0.4283, Validation Accuracy: 0.4587, Loss: 1.4272\n",
      "Epoch   0 Batch  258/269 - Train Accuracy: 0.4416, Validation Accuracy: 0.4801, Loss: 1.4279\n",
      "Epoch   0 Batch  259/269 - Train Accuracy: 0.4827, Validation Accuracy: 0.4914, Loss: 1.4169\n",
      "Epoch   0 Batch  260/269 - Train Accuracy: 0.4372, Validation Accuracy: 0.4851, Loss: 1.4743\n",
      "Epoch   0 Batch  261/269 - Train Accuracy: 0.4327, Validation Accuracy: 0.4972, Loss: 1.4883\n",
      "Epoch   0 Batch  262/269 - Train Accuracy: 0.4856, Validation Accuracy: 0.5044, Loss: 1.4188\n",
      "Epoch   0 Batch  263/269 - Train Accuracy: 0.4502, Validation Accuracy: 0.4795, Loss: 1.4615\n",
      "Epoch   0 Batch  264/269 - Train Accuracy: 0.4152, Validation Accuracy: 0.4616, Loss: 1.4751\n",
      "Epoch   0 Batch  265/269 - Train Accuracy: 0.4459, Validation Accuracy: 0.4883, Loss: 1.4425\n",
      "Epoch   0 Batch  266/269 - Train Accuracy: 0.4668, Validation Accuracy: 0.4929, Loss: 1.3857\n",
      "Epoch   0 Batch  267/269 - Train Accuracy: 0.4374, Validation Accuracy: 0.4664, Loss: 1.4156\n",
      "Epoch   1 Batch    1/269 - Train Accuracy: 0.4067, Validation Accuracy: 0.4643, Loss: 1.4353\n",
      "Epoch   1 Batch    2/269 - Train Accuracy: 0.4204, Validation Accuracy: 0.4655, Loss: 1.4075\n",
      "Epoch   1 Batch    3/269 - Train Accuracy: 0.4125, Validation Accuracy: 0.4671, Loss: 1.4386\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch   1 Batch    4/269 - Train Accuracy: 0.4011, Validation Accuracy: 0.4687, Loss: 1.4176\n",
      "Epoch   1 Batch    5/269 - Train Accuracy: 0.4021, Validation Accuracy: 0.4705, Loss: 1.4386\n",
      "Epoch   1 Batch    6/269 - Train Accuracy: 0.4550, Validation Accuracy: 0.4681, Loss: 1.3124\n",
      "Epoch   1 Batch    7/269 - Train Accuracy: 0.4459, Validation Accuracy: 0.4675, Loss: 1.3567\n",
      "Epoch   1 Batch    8/269 - Train Accuracy: 0.4335, Validation Accuracy: 0.4894, Loss: 1.4114\n",
      "Epoch   1 Batch    9/269 - Train Accuracy: 0.4229, Validation Accuracy: 0.4694, Loss: 1.3611\n",
      "Epoch   1 Batch   10/269 - Train Accuracy: 0.4194, Validation Accuracy: 0.4711, Loss: 1.3800\n",
      "Epoch   1 Batch   11/269 - Train Accuracy: 0.4437, Validation Accuracy: 0.4729, Loss: 1.3598\n",
      "Epoch   1 Batch   12/269 - Train Accuracy: 0.4073, Validation Accuracy: 0.4643, Loss: 1.4076\n",
      "Epoch   1 Batch   13/269 - Train Accuracy: 0.4941, Validation Accuracy: 0.4835, Loss: 1.2558\n",
      "Epoch   1 Batch   14/269 - Train Accuracy: 0.4263, Validation Accuracy: 0.4701, Loss: 1.3353\n",
      "Epoch   1 Batch   15/269 - Train Accuracy: 0.4259, Validation Accuracy: 0.4733, Loss: 1.3309\n",
      "Epoch   1 Batch   16/269 - Train Accuracy: 0.4418, Validation Accuracy: 0.4648, Loss: 1.3437\n",
      "Epoch   1 Batch   17/269 - Train Accuracy: 0.4315, Validation Accuracy: 0.4665, Loss: 1.3022\n",
      "Epoch   1 Batch   18/269 - Train Accuracy: 0.4070, Validation Accuracy: 0.4690, Loss: 1.3786\n",
      "Epoch   1 Batch   19/269 - Train Accuracy: 0.4759, Validation Accuracy: 0.4735, Loss: 1.2662\n",
      "Epoch   1 Batch   20/269 - Train Accuracy: 0.4368, Validation Accuracy: 0.4822, Loss: 1.3604\n",
      "Epoch   1 Batch   21/269 - Train Accuracy: 0.4439, Validation Accuracy: 0.4941, Loss: 1.4056\n",
      "Epoch   1 Batch   22/269 - Train Accuracy: 0.4553, Validation Accuracy: 0.4707, Loss: 1.3152\n",
      "Epoch   1 Batch   23/269 - Train Accuracy: 0.4713, Validation Accuracy: 0.4819, Loss: 1.3297\n",
      "Epoch   1 Batch   24/269 - Train Accuracy: 0.4530, Validation Accuracy: 0.5036, Loss: 1.3542\n",
      "Epoch   1 Batch   25/269 - Train Accuracy: 0.4228, Validation Accuracy: 0.4764, Loss: 1.3640\n",
      "Epoch   1 Batch   26/269 - Train Accuracy: 0.4848, Validation Accuracy: 0.4865, Loss: 1.2223\n",
      "Epoch   1 Batch   27/269 - Train Accuracy: 0.4795, Validation Accuracy: 0.5076, Loss: 1.2968\n",
      "Epoch   1 Batch   28/269 - Train Accuracy: 0.4158, Validation Accuracy: 0.4828, Loss: 1.3757\n",
      "Epoch   1 Batch   29/269 - Train Accuracy: 0.4487, Validation Accuracy: 0.4911, Loss: 1.3363\n",
      "Epoch   1 Batch   30/269 - Train Accuracy: 0.4754, Validation Accuracy: 0.5028, Loss: 1.2877\n",
      "Epoch   1 Batch   31/269 - Train Accuracy: 0.4834, Validation Accuracy: 0.4954, Loss: 1.2760\n",
      "Epoch   1 Batch   32/269 - Train Accuracy: 0.4706, Validation Accuracy: 0.4991, Loss: 1.2902\n",
      "Epoch   1 Batch   33/269 - Train Accuracy: 0.4889, Validation Accuracy: 0.5053, Loss: 1.2422\n",
      "Epoch   1 Batch   34/269 - Train Accuracy: 0.4714, Validation Accuracy: 0.4981, Loss: 1.2687\n",
      "Epoch   1 Batch   35/269 - Train Accuracy: 0.4886, Validation Accuracy: 0.5074, Loss: 1.2736\n",
      "Epoch   1 Batch   36/269 - Train Accuracy: 0.4886, Validation Accuracy: 0.5146, Loss: 1.2812\n",
      "Epoch   1 Batch   37/269 - Train Accuracy: 0.4776, Validation Accuracy: 0.4941, Loss: 1.2902\n",
      "Epoch   1 Batch   38/269 - Train Accuracy: 0.4869, Validation Accuracy: 0.5191, Loss: 1.2856\n",
      "Epoch   1 Batch   39/269 - Train Accuracy: 0.5048, Validation Accuracy: 0.5255, Loss: 1.2543\n",
      "Epoch   1 Batch   40/269 - Train Accuracy: 0.4713, Validation Accuracy: 0.5141, Loss: 1.3072\n",
      "Epoch   1 Batch   41/269 - Train Accuracy: 0.5062, Validation Accuracy: 0.5267, Loss: 1.2595\n",
      "Epoch   1 Batch   42/269 - Train Accuracy: 0.5332, Validation Accuracy: 0.5289, Loss: 1.1967\n",
      "Epoch   1 Batch   43/269 - Train Accuracy: 0.4685, Validation Accuracy: 0.5056, Loss: 1.2862\n",
      "Epoch   1 Batch   44/269 - Train Accuracy: 0.4963, Validation Accuracy: 0.4997, Loss: 1.2432\n",
      "Epoch   1 Batch   45/269 - Train Accuracy: 0.4581, Validation Accuracy: 0.5054, Loss: 1.2951\n",
      "Epoch   1 Batch   46/269 - Train Accuracy: 0.4518, Validation Accuracy: 0.5075, Loss: 1.2992\n",
      "Epoch   1 Batch   47/269 - Train Accuracy: 0.4871, Validation Accuracy: 0.4883, Loss: 1.1650\n",
      "Epoch   1 Batch   48/269 - Train Accuracy: 0.4808, Validation Accuracy: 0.4984, Loss: 1.2034\n",
      "Epoch   1 Batch   49/269 - Train Accuracy: 0.4805, Validation Accuracy: 0.5157, Loss: 1.2780\n",
      "Epoch   1 Batch   50/269 - Train Accuracy: 0.4810, Validation Accuracy: 0.5157, Loss: 1.2941\n",
      "Epoch   1 Batch   51/269 - Train Accuracy: 0.4732, Validation Accuracy: 0.5030, Loss: 1.2508\n",
      "Epoch   1 Batch   52/269 - Train Accuracy: 0.4951, Validation Accuracy: 0.5098, Loss: 1.2054\n",
      "Epoch   1 Batch   53/269 - Train Accuracy: 0.4732, Validation Accuracy: 0.5159, Loss: 1.2854\n",
      "Epoch   1 Batch   54/269 - Train Accuracy: 0.4624, Validation Accuracy: 0.5006, Loss: 1.2815\n",
      "Epoch   1 Batch   55/269 - Train Accuracy: 0.4907, Validation Accuracy: 0.5161, Loss: 1.2110\n",
      "Epoch   1 Batch   56/269 - Train Accuracy: 0.5230, Validation Accuracy: 0.5207, Loss: 1.2238\n",
      "Epoch   1 Batch   57/269 - Train Accuracy: 0.4834, Validation Accuracy: 0.4936, Loss: 1.2234\n",
      "Epoch   1 Batch   58/269 - Train Accuracy: 0.5106, Validation Accuracy: 0.5207, Loss: 1.2148\n",
      "Epoch   1 Batch   59/269 - Train Accuracy: 0.4943, Validation Accuracy: 0.5160, Loss: 1.1909\n",
      "Epoch   1 Batch   60/269 - Train Accuracy: 0.5160, Validation Accuracy: 0.5282, Loss: 1.1663\n",
      "Epoch   1 Batch   61/269 - Train Accuracy: 0.5045, Validation Accuracy: 0.4956, Loss: 1.1427\n",
      "Epoch   1 Batch   62/269 - Train Accuracy: 0.5431, Validation Accuracy: 0.5337, Loss: 1.1799\n",
      "Epoch   1 Batch   63/269 - Train Accuracy: 0.5118, Validation Accuracy: 0.5383, Loss: 1.1994\n",
      "Epoch   1 Batch   64/269 - Train Accuracy: 0.4946, Validation Accuracy: 0.5264, Loss: 1.1953\n",
      "Epoch   1 Batch   65/269 - Train Accuracy: 0.5071, Validation Accuracy: 0.5289, Loss: 1.1799\n",
      "Epoch   1 Batch   66/269 - Train Accuracy: 0.5299, Validation Accuracy: 0.5364, Loss: 1.1549\n",
      "Epoch   1 Batch   67/269 - Train Accuracy: 0.5159, Validation Accuracy: 0.5395, Loss: 1.2103\n",
      "Epoch   1 Batch   68/269 - Train Accuracy: 0.5130, Validation Accuracy: 0.5440, Loss: 1.1995\n",
      "Epoch   1 Batch   69/269 - Train Accuracy: 0.4938, Validation Accuracy: 0.5329, Loss: 1.2786\n",
      "Epoch   1 Batch   70/269 - Train Accuracy: 0.5343, Validation Accuracy: 0.5349, Loss: 1.1847\n",
      "Epoch   1 Batch   71/269 - Train Accuracy: 0.4948, Validation Accuracy: 0.5328, Loss: 1.2443\n",
      "Epoch   1 Batch   72/269 - Train Accuracy: 0.5330, Validation Accuracy: 0.5374, Loss: 1.1479\n",
      "Epoch   1 Batch   73/269 - Train Accuracy: 0.5102, Validation Accuracy: 0.5194, Loss: 1.2049\n",
      "Epoch   1 Batch   74/269 - Train Accuracy: 0.5076, Validation Accuracy: 0.5356, Loss: 1.2070\n",
      "Epoch   1 Batch   75/269 - Train Accuracy: 0.5061, Validation Accuracy: 0.5310, Loss: 1.1645\n",
      "Epoch   1 Batch   76/269 - Train Accuracy: 0.4757, Validation Accuracy: 0.5223, Loss: 1.1954\n",
      "Epoch   1 Batch   77/269 - Train Accuracy: 0.5088, Validation Accuracy: 0.5154, Loss: 1.1639\n",
      "Epoch   1 Batch   78/269 - Train Accuracy: 0.4984, Validation Accuracy: 0.5223, Loss: 1.1728\n",
      "Epoch   1 Batch   79/269 - Train Accuracy: 0.5085, Validation Accuracy: 0.5225, Loss: 1.1587\n",
      "Epoch   1 Batch   80/269 - Train Accuracy: 0.5304, Validation Accuracy: 0.5368, Loss: 1.1283\n",
      "Epoch   1 Batch   81/269 - Train Accuracy: 0.5395, Validation Accuracy: 0.5486, Loss: 1.1764\n",
      "Epoch   1 Batch   82/269 - Train Accuracy: 0.5354, Validation Accuracy: 0.5423, Loss: 1.1230\n",
      "Epoch   1 Batch   83/269 - Train Accuracy: 0.5256, Validation Accuracy: 0.5319, Loss: 1.1251\n",
      "Epoch   1 Batch   84/269 - Train Accuracy: 0.5416, Validation Accuracy: 0.5499, Loss: 1.1319\n",
      "Epoch   1 Batch   85/269 - Train Accuracy: 0.5303, Validation Accuracy: 0.5464, Loss: 1.1461\n",
      "Epoch   1 Batch   86/269 - Train Accuracy: 0.5090, Validation Accuracy: 0.5423, Loss: 1.1500\n",
      "Epoch   1 Batch   87/269 - Train Accuracy: 0.4962, Validation Accuracy: 0.5453, Loss: 1.2265\n",
      "Epoch   1 Batch   88/269 - Train Accuracy: 0.5346, Validation Accuracy: 0.5397, Loss: 1.1451\n",
      "Epoch   1 Batch   89/269 - Train Accuracy: 0.5383, Validation Accuracy: 0.5404, Loss: 1.1357\n",
      "Epoch   1 Batch   90/269 - Train Accuracy: 0.4771, Validation Accuracy: 0.5249, Loss: 1.2008\n",
      "Epoch   1 Batch   91/269 - Train Accuracy: 0.5046, Validation Accuracy: 0.5271, Loss: 1.1228\n",
      "Epoch   1 Batch   92/269 - Train Accuracy: 0.5153, Validation Accuracy: 0.5350, Loss: 1.1188\n",
      "Epoch   1 Batch   93/269 - Train Accuracy: 0.5455, Validation Accuracy: 0.5367, Loss: 1.0891\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch   1 Batch   94/269 - Train Accuracy: 0.5218, Validation Accuracy: 0.5305, Loss: 1.1412\n",
      "Epoch   1 Batch   95/269 - Train Accuracy: 0.5121, Validation Accuracy: 0.5382, Loss: 1.1212\n",
      "Epoch   1 Batch   96/269 - Train Accuracy: 0.5243, Validation Accuracy: 0.5431, Loss: 1.1055\n",
      "Epoch   1 Batch   97/269 - Train Accuracy: 0.5166, Validation Accuracy: 0.5389, Loss: 1.1188\n",
      "Epoch   1 Batch   98/269 - Train Accuracy: 0.5406, Validation Accuracy: 0.5380, Loss: 1.0988\n",
      "Epoch   1 Batch   99/269 - Train Accuracy: 0.4985, Validation Accuracy: 0.5365, Loss: 1.1737\n",
      "Epoch   1 Batch  100/269 - Train Accuracy: 0.5382, Validation Accuracy: 0.5431, Loss: 1.0833\n",
      "Epoch   1 Batch  101/269 - Train Accuracy: 0.5006, Validation Accuracy: 0.5455, Loss: 1.1705\n",
      "Epoch   1 Batch  102/269 - Train Accuracy: 0.5310, Validation Accuracy: 0.5467, Loss: 1.0958\n",
      "Epoch   1 Batch  103/269 - Train Accuracy: 0.5289, Validation Accuracy: 0.5492, Loss: 1.1016\n",
      "Epoch   1 Batch  104/269 - Train Accuracy: 0.5238, Validation Accuracy: 0.5495, Loss: 1.1104\n",
      "Epoch   1 Batch  105/269 - Train Accuracy: 0.5332, Validation Accuracy: 0.5501, Loss: 1.1167\n",
      "Epoch   1 Batch  106/269 - Train Accuracy: 0.5339, Validation Accuracy: 0.5522, Loss: 1.0977\n",
      "Epoch   1 Batch  107/269 - Train Accuracy: 0.4967, Validation Accuracy: 0.5504, Loss: 1.1526\n",
      "Epoch   1 Batch  108/269 - Train Accuracy: 0.5388, Validation Accuracy: 0.5477, Loss: 1.0865\n",
      "Epoch   1 Batch  109/269 - Train Accuracy: 0.5180, Validation Accuracy: 0.5502, Loss: 1.1043\n",
      "Epoch   1 Batch  110/269 - Train Accuracy: 0.5142, Validation Accuracy: 0.5457, Loss: 1.0845\n",
      "Epoch   1 Batch  111/269 - Train Accuracy: 0.5005, Validation Accuracy: 0.5471, Loss: 1.1729\n",
      "Epoch   1 Batch  112/269 - Train Accuracy: 0.5414, Validation Accuracy: 0.5391, Loss: 1.0727\n",
      "Epoch   1 Batch  113/269 - Train Accuracy: 0.5433, Validation Accuracy: 0.5477, Loss: 1.0351\n",
      "Epoch   1 Batch  114/269 - Train Accuracy: 0.5237, Validation Accuracy: 0.5401, Loss: 1.0741\n",
      "Epoch   1 Batch  115/269 - Train Accuracy: 0.5256, Validation Accuracy: 0.5591, Loss: 1.1106\n",
      "Epoch   1 Batch  116/269 - Train Accuracy: 0.5397, Validation Accuracy: 0.5501, Loss: 1.0827\n",
      "Epoch   1 Batch  117/269 - Train Accuracy: 0.5312, Validation Accuracy: 0.5539, Loss: 1.0716\n",
      "Epoch   1 Batch  118/269 - Train Accuracy: 0.5634, Validation Accuracy: 0.5629, Loss: 1.0445\n",
      "Epoch   1 Batch  119/269 - Train Accuracy: 0.5348, Validation Accuracy: 0.5638, Loss: 1.1295\n",
      "Epoch   1 Batch  120/269 - Train Accuracy: 0.5244, Validation Accuracy: 0.5633, Loss: 1.1172\n",
      "Epoch   1 Batch  121/269 - Train Accuracy: 0.5391, Validation Accuracy: 0.5616, Loss: 1.0575\n",
      "Epoch   1 Batch  122/269 - Train Accuracy: 0.5474, Validation Accuracy: 0.5666, Loss: 1.0547\n",
      "Epoch   1 Batch  123/269 - Train Accuracy: 0.5181, Validation Accuracy: 0.5626, Loss: 1.1100\n",
      "Epoch   1 Batch  124/269 - Train Accuracy: 0.5328, Validation Accuracy: 0.5452, Loss: 1.0335\n",
      "Epoch   1 Batch  125/269 - Train Accuracy: 0.5431, Validation Accuracy: 0.5521, Loss: 1.0329\n",
      "Epoch   1 Batch  126/269 - Train Accuracy: 0.5496, Validation Accuracy: 0.5607, Loss: 1.0373\n",
      "Epoch   1 Batch  127/269 - Train Accuracy: 0.5277, Validation Accuracy: 0.5654, Loss: 1.1032\n",
      "Epoch   1 Batch  128/269 - Train Accuracy: 0.5687, Validation Accuracy: 0.5664, Loss: 1.0413\n",
      "Epoch   1 Batch  129/269 - Train Accuracy: 0.5312, Validation Accuracy: 0.5577, Loss: 1.0649\n",
      "Epoch   1 Batch  130/269 - Train Accuracy: 0.5125, Validation Accuracy: 0.5566, Loss: 1.1114\n",
      "Epoch   1 Batch  131/269 - Train Accuracy: 0.5288, Validation Accuracy: 0.5512, Loss: 1.0830\n",
      "Epoch   1 Batch  132/269 - Train Accuracy: 0.5417, Validation Accuracy: 0.5575, Loss: 1.0516\n",
      "Epoch   1 Batch  133/269 - Train Accuracy: 0.5366, Validation Accuracy: 0.5560, Loss: 1.0206\n",
      "Epoch   1 Batch  134/269 - Train Accuracy: 0.5061, Validation Accuracy: 0.5585, Loss: 1.0795\n",
      "Epoch   1 Batch  135/269 - Train Accuracy: 0.5128, Validation Accuracy: 0.5565, Loss: 1.1151\n",
      "Epoch   1 Batch  136/269 - Train Accuracy: 0.5146, Validation Accuracy: 0.5635, Loss: 1.1010\n",
      "Epoch   1 Batch  137/269 - Train Accuracy: 0.5391, Validation Accuracy: 0.5620, Loss: 1.0868\n",
      "Epoch   1 Batch  138/269 - Train Accuracy: 0.5288, Validation Accuracy: 0.5554, Loss: 1.0484\n",
      "Epoch   1 Batch  139/269 - Train Accuracy: 0.5583, Validation Accuracy: 0.5602, Loss: 1.0084\n",
      "Epoch   1 Batch  140/269 - Train Accuracy: 0.5580, Validation Accuracy: 0.5617, Loss: 1.0301\n",
      "Epoch   1 Batch  141/269 - Train Accuracy: 0.5399, Validation Accuracy: 0.5622, Loss: 1.0464\n",
      "Epoch   1 Batch  142/269 - Train Accuracy: 0.5594, Validation Accuracy: 0.5627, Loss: 1.0068\n",
      "Epoch   1 Batch  143/269 - Train Accuracy: 0.5581, Validation Accuracy: 0.5617, Loss: 1.0231\n",
      "Epoch   1 Batch  144/269 - Train Accuracy: 0.5497, Validation Accuracy: 0.5617, Loss: 1.0025\n",
      "Epoch   1 Batch  145/269 - Train Accuracy: 0.5479, Validation Accuracy: 0.5614, Loss: 1.0177\n",
      "Epoch   1 Batch  146/269 - Train Accuracy: 0.5462, Validation Accuracy: 0.5599, Loss: 1.0040\n",
      "Epoch   1 Batch  147/269 - Train Accuracy: 0.5779, Validation Accuracy: 0.5601, Loss: 0.9716\n",
      "Epoch   1 Batch  148/269 - Train Accuracy: 0.5384, Validation Accuracy: 0.5605, Loss: 1.0396\n",
      "Epoch   1 Batch  149/269 - Train Accuracy: 0.5551, Validation Accuracy: 0.5616, Loss: 1.0146\n",
      "Epoch   1 Batch  150/269 - Train Accuracy: 0.5486, Validation Accuracy: 0.5634, Loss: 1.0243\n",
      "Epoch   1 Batch  151/269 - Train Accuracy: 0.5807, Validation Accuracy: 0.5641, Loss: 0.9737\n",
      "Epoch   1 Batch  152/269 - Train Accuracy: 0.5495, Validation Accuracy: 0.5629, Loss: 0.9981\n",
      "Epoch   1 Batch  153/269 - Train Accuracy: 0.5486, Validation Accuracy: 0.5613, Loss: 0.9928\n",
      "Epoch   1 Batch  154/269 - Train Accuracy: 0.5162, Validation Accuracy: 0.5595, Loss: 1.0360\n",
      "Epoch   1 Batch  155/269 - Train Accuracy: 0.5764, Validation Accuracy: 0.5615, Loss: 0.9481\n",
      "Epoch   1 Batch  156/269 - Train Accuracy: 0.5360, Validation Accuracy: 0.5616, Loss: 1.0335\n",
      "Epoch   1 Batch  157/269 - Train Accuracy: 0.5477, Validation Accuracy: 0.5618, Loss: 0.9914\n",
      "Epoch   1 Batch  158/269 - Train Accuracy: 0.5603, Validation Accuracy: 0.5630, Loss: 0.9847\n",
      "Epoch   1 Batch  159/269 - Train Accuracy: 0.5545, Validation Accuracy: 0.5645, Loss: 0.9896\n",
      "Epoch   1 Batch  160/269 - Train Accuracy: 0.5488, Validation Accuracy: 0.5632, Loss: 0.9960\n",
      "Epoch   1 Batch  161/269 - Train Accuracy: 0.5401, Validation Accuracy: 0.5596, Loss: 1.0015\n",
      "Epoch   1 Batch  162/269 - Train Accuracy: 0.5451, Validation Accuracy: 0.5581, Loss: 0.9807\n",
      "Epoch   1 Batch  163/269 - Train Accuracy: 0.5607, Validation Accuracy: 0.5585, Loss: 0.9752\n",
      "Epoch   1 Batch  164/269 - Train Accuracy: 0.5507, Validation Accuracy: 0.5623, Loss: 0.9788\n",
      "Epoch   1 Batch  165/269 - Train Accuracy: 0.5222, Validation Accuracy: 0.5629, Loss: 1.0060\n",
      "Epoch   1 Batch  166/269 - Train Accuracy: 0.5748, Validation Accuracy: 0.5616, Loss: 0.9258\n",
      "Epoch   1 Batch  167/269 - Train Accuracy: 0.5531, Validation Accuracy: 0.5647, Loss: 0.9812\n",
      "Epoch   1 Batch  168/269 - Train Accuracy: 0.5339, Validation Accuracy: 0.5652, Loss: 0.9935\n",
      "Epoch   1 Batch  169/269 - Train Accuracy: 0.5456, Validation Accuracy: 0.5636, Loss: 0.9752\n",
      "Epoch   1 Batch  170/269 - Train Accuracy: 0.5486, Validation Accuracy: 0.5643, Loss: 0.9641\n",
      "Epoch   1 Batch  171/269 - Train Accuracy: 0.5380, Validation Accuracy: 0.5632, Loss: 1.0011\n",
      "Epoch   1 Batch  172/269 - Train Accuracy: 0.5497, Validation Accuracy: 0.5633, Loss: 0.9727\n",
      "Epoch   1 Batch  173/269 - Train Accuracy: 0.5515, Validation Accuracy: 0.5652, Loss: 0.9516\n",
      "Epoch   1 Batch  174/269 - Train Accuracy: 0.5419, Validation Accuracy: 0.5629, Loss: 0.9625\n",
      "Epoch   1 Batch  175/269 - Train Accuracy: 0.5508, Validation Accuracy: 0.5611, Loss: 0.9792\n",
      "Epoch   1 Batch  176/269 - Train Accuracy: 0.5388, Validation Accuracy: 0.5605, Loss: 1.0137\n",
      "Epoch   1 Batch  177/269 - Train Accuracy: 0.5549, Validation Accuracy: 0.5614, Loss: 0.9384\n",
      "Epoch   1 Batch  178/269 - Train Accuracy: 0.5358, Validation Accuracy: 0.5606, Loss: 0.9942\n",
      "Epoch   1 Batch  179/269 - Train Accuracy: 0.5463, Validation Accuracy: 0.5613, Loss: 0.9626\n",
      "Epoch   1 Batch  180/269 - Train Accuracy: 0.5470, Validation Accuracy: 0.5613, Loss: 0.9418\n",
      "Epoch   1 Batch  181/269 - Train Accuracy: 0.5364, Validation Accuracy: 0.5624, Loss: 0.9536\n",
      "Epoch   1 Batch  182/269 - Train Accuracy: 0.5487, Validation Accuracy: 0.5607, Loss: 0.9634\n",
      "Epoch   1 Batch  183/269 - Train Accuracy: 0.6161, Validation Accuracy: 0.5598, Loss: 0.8302\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch   1 Batch  184/269 - Train Accuracy: 0.5319, Validation Accuracy: 0.5588, Loss: 0.9786\n",
      "Epoch   1 Batch  185/269 - Train Accuracy: 0.5607, Validation Accuracy: 0.5576, Loss: 0.9454\n",
      "Epoch   1 Batch  186/269 - Train Accuracy: 0.5174, Validation Accuracy: 0.5591, Loss: 0.9777\n",
      "Epoch   1 Batch  187/269 - Train Accuracy: 0.5570, Validation Accuracy: 0.5626, Loss: 0.9202\n",
      "Epoch   1 Batch  188/269 - Train Accuracy: 0.5565, Validation Accuracy: 0.5628, Loss: 0.9183\n",
      "Epoch   1 Batch  189/269 - Train Accuracy: 0.5547, Validation Accuracy: 0.5646, Loss: 0.9328\n",
      "Epoch   1 Batch  190/269 - Train Accuracy: 0.5421, Validation Accuracy: 0.5599, Loss: 0.9252\n",
      "Epoch   1 Batch  191/269 - Train Accuracy: 0.5379, Validation Accuracy: 0.5594, Loss: 0.9360\n",
      "Epoch   1 Batch  192/269 - Train Accuracy: 0.5516, Validation Accuracy: 0.5603, Loss: 0.9345\n",
      "Epoch   1 Batch  193/269 - Train Accuracy: 0.5464, Validation Accuracy: 0.5631, Loss: 0.9346\n",
      "Epoch   1 Batch  194/269 - Train Accuracy: 0.5546, Validation Accuracy: 0.5583, Loss: 0.9440\n",
      "Epoch   1 Batch  195/269 - Train Accuracy: 0.5312, Validation Accuracy: 0.5597, Loss: 0.9478\n",
      "Epoch   1 Batch  196/269 - Train Accuracy: 0.5406, Validation Accuracy: 0.5596, Loss: 0.9228\n",
      "Epoch   1 Batch  197/269 - Train Accuracy: 0.5178, Validation Accuracy: 0.5627, Loss: 0.9690\n",
      "Epoch   1 Batch  198/269 - Train Accuracy: 0.5223, Validation Accuracy: 0.5590, Loss: 0.9913\n",
      "Epoch   1 Batch  199/269 - Train Accuracy: 0.5333, Validation Accuracy: 0.5574, Loss: 0.9528\n",
      "Epoch   1 Batch  200/269 - Train Accuracy: 0.5335, Validation Accuracy: 0.5607, Loss: 0.9621\n",
      "Epoch   1 Batch  201/269 - Train Accuracy: 0.5419, Validation Accuracy: 0.5607, Loss: 0.9259\n",
      "Epoch   1 Batch  202/269 - Train Accuracy: 0.5373, Validation Accuracy: 0.5588, Loss: 0.9331\n",
      "Epoch   1 Batch  203/269 - Train Accuracy: 0.5147, Validation Accuracy: 0.5567, Loss: 0.9763\n",
      "Epoch   1 Batch  204/269 - Train Accuracy: 0.5221, Validation Accuracy: 0.5618, Loss: 0.9523\n",
      "Epoch   1 Batch  205/269 - Train Accuracy: 0.5299, Validation Accuracy: 0.5622, Loss: 0.9149\n",
      "Epoch   1 Batch  206/269 - Train Accuracy: 0.5152, Validation Accuracy: 0.5582, Loss: 0.9804\n",
      "Epoch   1 Batch  207/269 - Train Accuracy: 0.5670, Validation Accuracy: 0.5574, Loss: 0.8879\n",
      "Epoch   1 Batch  208/269 - Train Accuracy: 0.5167, Validation Accuracy: 0.5586, Loss: 0.9737\n",
      "Epoch   1 Batch  209/269 - Train Accuracy: 0.5280, Validation Accuracy: 0.5629, Loss: 0.9333\n",
      "Epoch   1 Batch  210/269 - Train Accuracy: 0.5524, Validation Accuracy: 0.5592, Loss: 0.9035\n",
      "Epoch   1 Batch  211/269 - Train Accuracy: 0.5456, Validation Accuracy: 0.5557, Loss: 0.9224\n",
      "Epoch   1 Batch  212/269 - Train Accuracy: 0.5635, Validation Accuracy: 0.5581, Loss: 0.8932\n",
      "Epoch   1 Batch  213/269 - Train Accuracy: 0.5568, Validation Accuracy: 0.5621, Loss: 0.8938\n",
      "Epoch   1 Batch  214/269 - Train Accuracy: 0.5517, Validation Accuracy: 0.5610, Loss: 0.9026\n",
      "Epoch   1 Batch  215/269 - Train Accuracy: 0.5669, Validation Accuracy: 0.5603, Loss: 0.8536\n",
      "Epoch   1 Batch  216/269 - Train Accuracy: 0.5178, Validation Accuracy: 0.5608, Loss: 0.9745\n",
      "Epoch   1 Batch  217/269 - Train Accuracy: 0.5167, Validation Accuracy: 0.5608, Loss: 0.9374\n",
      "Epoch   1 Batch  218/269 - Train Accuracy: 0.5394, Validation Accuracy: 0.5605, Loss: 0.9457\n",
      "Epoch   1 Batch  219/269 - Train Accuracy: 0.5442, Validation Accuracy: 0.5600, Loss: 0.9389\n",
      "Epoch   1 Batch  220/269 - Train Accuracy: 0.5571, Validation Accuracy: 0.5595, Loss: 0.8583\n",
      "Epoch   1 Batch  221/269 - Train Accuracy: 0.5620, Validation Accuracy: 0.5626, Loss: 0.8895\n",
      "Epoch   1 Batch  222/269 - Train Accuracy: 0.5587, Validation Accuracy: 0.5638, Loss: 0.8644\n",
      "Epoch   1 Batch  223/269 - Train Accuracy: 0.5557, Validation Accuracy: 0.5618, Loss: 0.8668\n",
      "Epoch   1 Batch  224/269 - Train Accuracy: 0.5600, Validation Accuracy: 0.5614, Loss: 0.9134\n",
      "Epoch   1 Batch  225/269 - Train Accuracy: 0.5368, Validation Accuracy: 0.5591, Loss: 0.9230\n",
      "Epoch   1 Batch  226/269 - Train Accuracy: 0.5386, Validation Accuracy: 0.5621, Loss: 0.8825\n",
      "Epoch   1 Batch  227/269 - Train Accuracy: 0.6100, Validation Accuracy: 0.5639, Loss: 0.7858\n",
      "Epoch   1 Batch  228/269 - Train Accuracy: 0.5390, Validation Accuracy: 0.5621, Loss: 0.8961\n",
      "Epoch   1 Batch  229/269 - Train Accuracy: 0.5454, Validation Accuracy: 0.5592, Loss: 0.8783\n",
      "Epoch   1 Batch  230/269 - Train Accuracy: 0.5420, Validation Accuracy: 0.5585, Loss: 0.8925\n",
      "Epoch   1 Batch  231/269 - Train Accuracy: 0.5257, Validation Accuracy: 0.5603, Loss: 0.9324\n",
      "Epoch   1 Batch  232/269 - Train Accuracy: 0.5180, Validation Accuracy: 0.5644, Loss: 0.9237\n",
      "Epoch   1 Batch  233/269 - Train Accuracy: 0.5489, Validation Accuracy: 0.5641, Loss: 0.8889\n",
      "Epoch   1 Batch  234/269 - Train Accuracy: 0.5470, Validation Accuracy: 0.5639, Loss: 0.8866\n",
      "Epoch   1 Batch  235/269 - Train Accuracy: 0.5473, Validation Accuracy: 0.5627, Loss: 0.8820\n",
      "Epoch   1 Batch  236/269 - Train Accuracy: 0.5368, Validation Accuracy: 0.5621, Loss: 0.8750\n",
      "Epoch   1 Batch  237/269 - Train Accuracy: 0.5408, Validation Accuracy: 0.5668, Loss: 0.8719\n",
      "Epoch   1 Batch  238/269 - Train Accuracy: 0.5560, Validation Accuracy: 0.5679, Loss: 0.8758\n",
      "Epoch   1 Batch  239/269 - Train Accuracy: 0.5724, Validation Accuracy: 0.5658, Loss: 0.8646\n",
      "Epoch   1 Batch  240/269 - Train Accuracy: 0.5773, Validation Accuracy: 0.5620, Loss: 0.8200\n",
      "Epoch   1 Batch  241/269 - Train Accuracy: 0.5511, Validation Accuracy: 0.5617, Loss: 0.8792\n",
      "Epoch   1 Batch  242/269 - Train Accuracy: 0.5449, Validation Accuracy: 0.5670, Loss: 0.8700\n",
      "Epoch   1 Batch  243/269 - Train Accuracy: 0.5745, Validation Accuracy: 0.5683, Loss: 0.8462\n",
      "Epoch   1 Batch  244/269 - Train Accuracy: 0.5514, Validation Accuracy: 0.5678, Loss: 0.8606\n",
      "Epoch   1 Batch  245/269 - Train Accuracy: 0.5429, Validation Accuracy: 0.5681, Loss: 0.9171\n",
      "Epoch   1 Batch  246/269 - Train Accuracy: 0.5496, Validation Accuracy: 0.5676, Loss: 0.8773\n",
      "Epoch   1 Batch  247/269 - Train Accuracy: 0.5447, Validation Accuracy: 0.5621, Loss: 0.9100\n",
      "Epoch   1 Batch  248/269 - Train Accuracy: 0.5420, Validation Accuracy: 0.5600, Loss: 0.8605\n",
      "Epoch   1 Batch  249/269 - Train Accuracy: 0.5758, Validation Accuracy: 0.5658, Loss: 0.8237\n",
      "Epoch   1 Batch  250/269 - Train Accuracy: 0.5400, Validation Accuracy: 0.5670, Loss: 0.8877\n",
      "Epoch   1 Batch  251/269 - Train Accuracy: 0.5660, Validation Accuracy: 0.5705, Loss: 0.8499\n",
      "Epoch   1 Batch  252/269 - Train Accuracy: 0.5523, Validation Accuracy: 0.5721, Loss: 0.8644\n",
      "Epoch   1 Batch  253/269 - Train Accuracy: 0.5523, Validation Accuracy: 0.5703, Loss: 0.8681\n",
      "Epoch   1 Batch  254/269 - Train Accuracy: 0.5604, Validation Accuracy: 0.5637, Loss: 0.8509\n",
      "Epoch   1 Batch  255/269 - Train Accuracy: 0.5763, Validation Accuracy: 0.5631, Loss: 0.8231\n",
      "Epoch   1 Batch  256/269 - Train Accuracy: 0.5278, Validation Accuracy: 0.5630, Loss: 0.8700\n",
      "Epoch   1 Batch  257/269 - Train Accuracy: 0.5378, Validation Accuracy: 0.5629, Loss: 0.8621\n",
      "Epoch   1 Batch  258/269 - Train Accuracy: 0.5402, Validation Accuracy: 0.5651, Loss: 0.8623\n",
      "Epoch   1 Batch  259/269 - Train Accuracy: 0.5725, Validation Accuracy: 0.5688, Loss: 0.8553\n",
      "Epoch   1 Batch  260/269 - Train Accuracy: 0.5489, Validation Accuracy: 0.5710, Loss: 0.8919\n",
      "Epoch   1 Batch  261/269 - Train Accuracy: 0.5221, Validation Accuracy: 0.5729, Loss: 0.9100\n",
      "Epoch   1 Batch  262/269 - Train Accuracy: 0.5580, Validation Accuracy: 0.5732, Loss: 0.8582\n",
      "Epoch   1 Batch  263/269 - Train Accuracy: 0.5521, Validation Accuracy: 0.5708, Loss: 0.8835\n",
      "Epoch   1 Batch  264/269 - Train Accuracy: 0.5330, Validation Accuracy: 0.5689, Loss: 0.8916\n",
      "Epoch   1 Batch  265/269 - Train Accuracy: 0.5382, Validation Accuracy: 0.5686, Loss: 0.8742\n",
      "Epoch   1 Batch  266/269 - Train Accuracy: 0.5617, Validation Accuracy: 0.5705, Loss: 0.8372\n",
      "Epoch   1 Batch  267/269 - Train Accuracy: 0.5554, Validation Accuracy: 0.5754, Loss: 0.8593\n",
      "Epoch   2 Batch    1/269 - Train Accuracy: 0.5373, Validation Accuracy: 0.5761, Loss: 0.8640\n",
      "Epoch   2 Batch    2/269 - Train Accuracy: 0.5345, Validation Accuracy: 0.5742, Loss: 0.8597\n",
      "Epoch   2 Batch    3/269 - Train Accuracy: 0.5452, Validation Accuracy: 0.5709, Loss: 0.8690\n",
      "Epoch   2 Batch    4/269 - Train Accuracy: 0.5364, Validation Accuracy: 0.5657, Loss: 0.8737\n",
      "Epoch   2 Batch    5/269 - Train Accuracy: 0.5239, Validation Accuracy: 0.5637, Loss: 0.8805\n",
      "Epoch   2 Batch    6/269 - Train Accuracy: 0.5666, Validation Accuracy: 0.5694, Loss: 0.8033\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch   2 Batch    7/269 - Train Accuracy: 0.5621, Validation Accuracy: 0.5721, Loss: 0.8265\n",
      "Epoch   2 Batch    8/269 - Train Accuracy: 0.5397, Validation Accuracy: 0.5716, Loss: 0.8736\n",
      "Epoch   2 Batch    9/269 - Train Accuracy: 0.5429, Validation Accuracy: 0.5679, Loss: 0.8479\n",
      "Epoch   2 Batch   10/269 - Train Accuracy: 0.5428, Validation Accuracy: 0.5673, Loss: 0.8506\n",
      "Epoch   2 Batch   11/269 - Train Accuracy: 0.5459, Validation Accuracy: 0.5715, Loss: 0.8466\n",
      "Epoch   2 Batch   12/269 - Train Accuracy: 0.5229, Validation Accuracy: 0.5709, Loss: 0.8711\n",
      "Epoch   2 Batch   13/269 - Train Accuracy: 0.5863, Validation Accuracy: 0.5718, Loss: 0.7766\n",
      "Epoch   2 Batch   14/269 - Train Accuracy: 0.5632, Validation Accuracy: 0.5740, Loss: 0.8271\n",
      "Epoch   2 Batch   15/269 - Train Accuracy: 0.5495, Validation Accuracy: 0.5785, Loss: 0.8209\n",
      "Epoch   2 Batch   16/269 - Train Accuracy: 0.5738, Validation Accuracy: 0.5787, Loss: 0.8299\n",
      "Epoch   2 Batch   17/269 - Train Accuracy: 0.5595, Validation Accuracy: 0.5754, Loss: 0.8074\n",
      "Epoch   2 Batch   18/269 - Train Accuracy: 0.5379, Validation Accuracy: 0.5719, Loss: 0.8483\n",
      "Epoch   2 Batch   19/269 - Train Accuracy: 0.5886, Validation Accuracy: 0.5771, Loss: 0.7791\n",
      "Epoch   2 Batch   20/269 - Train Accuracy: 0.5544, Validation Accuracy: 0.5770, Loss: 0.8490\n",
      "Epoch   2 Batch   21/269 - Train Accuracy: 0.5540, Validation Accuracy: 0.5799, Loss: 0.8752\n",
      "Epoch   2 Batch   22/269 - Train Accuracy: 0.5681, Validation Accuracy: 0.5828, Loss: 0.8061\n",
      "Epoch   2 Batch   23/269 - Train Accuracy: 0.5825, Validation Accuracy: 0.5843, Loss: 0.8286\n",
      "Epoch   2 Batch   24/269 - Train Accuracy: 0.5635, Validation Accuracy: 0.5850, Loss: 0.8513\n",
      "Epoch   2 Batch   25/269 - Train Accuracy: 0.5476, Validation Accuracy: 0.5787, Loss: 0.8652\n",
      "Epoch   2 Batch   26/269 - Train Accuracy: 0.5917, Validation Accuracy: 0.5707, Loss: 0.7605\n",
      "Epoch   2 Batch   27/269 - Train Accuracy: 0.5559, Validation Accuracy: 0.5712, Loss: 0.8136\n",
      "Epoch   2 Batch   28/269 - Train Accuracy: 0.5239, Validation Accuracy: 0.5726, Loss: 0.8713\n",
      "Epoch   2 Batch   29/269 - Train Accuracy: 0.5447, Validation Accuracy: 0.5764, Loss: 0.8397\n",
      "Epoch   2 Batch   30/269 - Train Accuracy: 0.5630, Validation Accuracy: 0.5755, Loss: 0.8019\n",
      "Epoch   2 Batch   31/269 - Train Accuracy: 0.5746, Validation Accuracy: 0.5841, Loss: 0.8022\n",
      "Epoch   2 Batch   32/269 - Train Accuracy: 0.5596, Validation Accuracy: 0.5840, Loss: 0.8066\n",
      "Epoch   2 Batch   33/269 - Train Accuracy: 0.5765, Validation Accuracy: 0.5850, Loss: 0.7785\n",
      "Epoch   2 Batch   34/269 - Train Accuracy: 0.5784, Validation Accuracy: 0.5824, Loss: 0.8048\n",
      "Epoch   2 Batch   35/269 - Train Accuracy: 0.5892, Validation Accuracy: 0.5722, Loss: 0.8140\n",
      "Epoch   2 Batch   36/269 - Train Accuracy: 0.5698, Validation Accuracy: 0.5787, Loss: 0.8074\n",
      "Epoch   2 Batch   37/269 - Train Accuracy: 0.5669, Validation Accuracy: 0.5779, Loss: 0.8060\n",
      "Epoch   2 Batch   38/269 - Train Accuracy: 0.5683, Validation Accuracy: 0.5779, Loss: 0.8080\n",
      "Epoch   2 Batch   39/269 - Train Accuracy: 0.5707, Validation Accuracy: 0.5723, Loss: 0.7871\n",
      "Epoch   2 Batch   40/269 - Train Accuracy: 0.5549, Validation Accuracy: 0.5705, Loss: 0.8368\n",
      "Epoch   2 Batch   41/269 - Train Accuracy: 0.5700, Validation Accuracy: 0.5749, Loss: 0.8130\n",
      "Epoch   2 Batch   42/269 - Train Accuracy: 0.5900, Validation Accuracy: 0.5778, Loss: 0.7642\n",
      "Epoch   2 Batch   43/269 - Train Accuracy: 0.5542, Validation Accuracy: 0.5782, Loss: 0.8289\n",
      "Epoch   2 Batch   44/269 - Train Accuracy: 0.5911, Validation Accuracy: 0.5784, Loss: 0.8032\n",
      "Epoch   2 Batch   45/269 - Train Accuracy: 0.5582, Validation Accuracy: 0.5801, Loss: 0.8345\n",
      "Epoch   2 Batch   46/269 - Train Accuracy: 0.5692, Validation Accuracy: 0.5834, Loss: 0.8306\n",
      "Epoch   2 Batch   47/269 - Train Accuracy: 0.6088, Validation Accuracy: 0.5851, Loss: 0.7397\n",
      "Epoch   2 Batch   48/269 - Train Accuracy: 0.5825, Validation Accuracy: 0.5827, Loss: 0.7737\n",
      "Epoch   2 Batch   49/269 - Train Accuracy: 0.5609, Validation Accuracy: 0.5827, Loss: 0.8171\n",
      "Epoch   2 Batch   50/269 - Train Accuracy: 0.5599, Validation Accuracy: 0.5806, Loss: 0.8242\n",
      "Epoch   2 Batch   51/269 - Train Accuracy: 0.5639, Validation Accuracy: 0.5882, Loss: 0.8045\n",
      "Epoch   2 Batch   52/269 - Train Accuracy: 0.5737, Validation Accuracy: 0.5946, Loss: 0.7690\n",
      "Epoch   2 Batch   53/269 - Train Accuracy: 0.5598, Validation Accuracy: 0.5935, Loss: 0.8350\n",
      "Epoch   2 Batch   54/269 - Train Accuracy: 0.5705, Validation Accuracy: 0.5916, Loss: 0.8253\n",
      "Epoch   2 Batch   55/269 - Train Accuracy: 0.5810, Validation Accuracy: 0.5898, Loss: 0.7862\n",
      "Epoch   2 Batch   56/269 - Train Accuracy: 0.5892, Validation Accuracy: 0.5929, Loss: 0.7911\n",
      "Epoch   2 Batch   57/269 - Train Accuracy: 0.5884, Validation Accuracy: 0.5903, Loss: 0.7978\n",
      "Epoch   2 Batch   58/269 - Train Accuracy: 0.5909, Validation Accuracy: 0.5836, Loss: 0.7907\n",
      "Epoch   2 Batch   59/269 - Train Accuracy: 0.5884, Validation Accuracy: 0.5843, Loss: 0.7591\n",
      "Epoch   2 Batch   60/269 - Train Accuracy: 0.5884, Validation Accuracy: 0.5842, Loss: 0.7578\n",
      "Epoch   2 Batch   61/269 - Train Accuracy: 0.6111, Validation Accuracy: 0.5878, Loss: 0.7366\n",
      "Epoch   2 Batch   62/269 - Train Accuracy: 0.5954, Validation Accuracy: 0.5834, Loss: 0.7544\n",
      "Epoch   2 Batch   63/269 - Train Accuracy: 0.5729, Validation Accuracy: 0.5817, Loss: 0.7911\n",
      "Epoch   2 Batch   64/269 - Train Accuracy: 0.5749, Validation Accuracy: 0.5796, Loss: 0.7747\n",
      "Epoch   2 Batch   65/269 - Train Accuracy: 0.5837, Validation Accuracy: 0.5823, Loss: 0.7791\n",
      "Epoch   2 Batch   66/269 - Train Accuracy: 0.5862, Validation Accuracy: 0.5850, Loss: 0.7575\n",
      "Epoch   2 Batch   67/269 - Train Accuracy: 0.5804, Validation Accuracy: 0.5850, Loss: 0.7932\n",
      "Epoch   2 Batch   68/269 - Train Accuracy: 0.5738, Validation Accuracy: 0.5823, Loss: 0.7819\n",
      "Epoch   2 Batch   69/269 - Train Accuracy: 0.5667, Validation Accuracy: 0.5835, Loss: 0.8550\n",
      "Epoch   2 Batch   70/269 - Train Accuracy: 0.6028, Validation Accuracy: 0.5865, Loss: 0.7845\n",
      "Epoch   2 Batch   71/269 - Train Accuracy: 0.5726, Validation Accuracy: 0.5906, Loss: 0.8095\n",
      "Epoch   2 Batch   72/269 - Train Accuracy: 0.6015, Validation Accuracy: 0.5933, Loss: 0.7609\n",
      "Epoch   2 Batch   73/269 - Train Accuracy: 0.5893, Validation Accuracy: 0.5935, Loss: 0.7910\n",
      "Epoch   2 Batch   74/269 - Train Accuracy: 0.5760, Validation Accuracy: 0.5898, Loss: 0.7884\n",
      "Epoch   2 Batch   75/269 - Train Accuracy: 0.5795, Validation Accuracy: 0.5862, Loss: 0.7676\n",
      "Epoch   2 Batch   76/269 - Train Accuracy: 0.5785, Validation Accuracy: 0.5928, Loss: 0.7861\n",
      "Epoch   2 Batch   77/269 - Train Accuracy: 0.6112, Validation Accuracy: 0.5938, Loss: 0.7673\n",
      "Epoch   2 Batch   78/269 - Train Accuracy: 0.5966, Validation Accuracy: 0.5953, Loss: 0.7687\n",
      "Epoch   2 Batch   79/269 - Train Accuracy: 0.5966, Validation Accuracy: 0.5935, Loss: 0.7658\n",
      "Epoch   2 Batch   80/269 - Train Accuracy: 0.6065, Validation Accuracy: 0.5915, Loss: 0.7536\n",
      "Epoch   2 Batch   81/269 - Train Accuracy: 0.5898, Validation Accuracy: 0.5924, Loss: 0.7853\n",
      "Epoch   2 Batch   82/269 - Train Accuracy: 0.6025, Validation Accuracy: 0.5984, Loss: 0.7390\n",
      "Epoch   2 Batch   83/269 - Train Accuracy: 0.5959, Validation Accuracy: 0.6040, Loss: 0.7632\n",
      "Epoch   2 Batch   84/269 - Train Accuracy: 0.6070, Validation Accuracy: 0.6028, Loss: 0.7490\n",
      "Epoch   2 Batch   85/269 - Train Accuracy: 0.5897, Validation Accuracy: 0.6041, Loss: 0.7620\n",
      "Epoch   2 Batch   86/269 - Train Accuracy: 0.5795, Validation Accuracy: 0.6002, Loss: 0.7620\n",
      "Epoch   2 Batch   87/269 - Train Accuracy: 0.5706, Validation Accuracy: 0.5939, Loss: 0.8179\n",
      "Epoch   2 Batch   88/269 - Train Accuracy: 0.5907, Validation Accuracy: 0.5945, Loss: 0.7643\n",
      "Epoch   2 Batch   89/269 - Train Accuracy: 0.6119, Validation Accuracy: 0.6000, Loss: 0.7613\n",
      "Epoch   2 Batch   90/269 - Train Accuracy: 0.5657, Validation Accuracy: 0.5951, Loss: 0.8075\n",
      "Epoch   2 Batch   91/269 - Train Accuracy: 0.5942, Validation Accuracy: 0.5930, Loss: 0.7393\n",
      "Epoch   2 Batch   92/269 - Train Accuracy: 0.5992, Validation Accuracy: 0.5973, Loss: 0.7533\n",
      "Epoch   2 Batch   93/269 - Train Accuracy: 0.6095, Validation Accuracy: 0.6001, Loss: 0.7275\n",
      "Epoch   2 Batch   94/269 - Train Accuracy: 0.6036, Validation Accuracy: 0.5987, Loss: 0.7726\n",
      "Epoch   2 Batch   95/269 - Train Accuracy: 0.5976, Validation Accuracy: 0.6001, Loss: 0.7593\n",
      "Epoch   2 Batch   96/269 - Train Accuracy: 0.6047, Validation Accuracy: 0.6024, Loss: 0.7517\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch   2 Batch   97/269 - Train Accuracy: 0.5870, Validation Accuracy: 0.5914, Loss: 0.7514\n",
      "Epoch   2 Batch   98/269 - Train Accuracy: 0.6049, Validation Accuracy: 0.5941, Loss: 0.7503\n",
      "Epoch   2 Batch   99/269 - Train Accuracy: 0.5809, Validation Accuracy: 0.6001, Loss: 0.7855\n",
      "Epoch   2 Batch  100/269 - Train Accuracy: 0.6164, Validation Accuracy: 0.6012, Loss: 0.7461\n",
      "Epoch   2 Batch  101/269 - Train Accuracy: 0.5670, Validation Accuracy: 0.5971, Loss: 0.7973\n",
      "Epoch   2 Batch  102/269 - Train Accuracy: 0.6003, Validation Accuracy: 0.5959, Loss: 0.7445\n",
      "Epoch   2 Batch  103/269 - Train Accuracy: 0.5926, Validation Accuracy: 0.5961, Loss: 0.7495\n",
      "Epoch   2 Batch  104/269 - Train Accuracy: 0.5762, Validation Accuracy: 0.5915, Loss: 0.7484\n",
      "Epoch   2 Batch  105/269 - Train Accuracy: 0.5960, Validation Accuracy: 0.5962, Loss: 0.7625\n",
      "Epoch   2 Batch  106/269 - Train Accuracy: 0.5995, Validation Accuracy: 0.5945, Loss: 0.7470\n",
      "Epoch   2 Batch  107/269 - Train Accuracy: 0.5688, Validation Accuracy: 0.5927, Loss: 0.7885\n",
      "Epoch   2 Batch  108/269 - Train Accuracy: 0.6011, Validation Accuracy: 0.5969, Loss: 0.7504\n",
      "Epoch   2 Batch  109/269 - Train Accuracy: 0.5879, Validation Accuracy: 0.6001, Loss: 0.7515\n",
      "Epoch   2 Batch  110/269 - Train Accuracy: 0.5932, Validation Accuracy: 0.5969, Loss: 0.7423\n",
      "Epoch   2 Batch  111/269 - Train Accuracy: 0.5729, Validation Accuracy: 0.5998, Loss: 0.8090\n",
      "Epoch   2 Batch  112/269 - Train Accuracy: 0.6116, Validation Accuracy: 0.6029, Loss: 0.7472\n",
      "Epoch   2 Batch  113/269 - Train Accuracy: 0.6067, Validation Accuracy: 0.6019, Loss: 0.7140\n",
      "Epoch   2 Batch  114/269 - Train Accuracy: 0.5985, Validation Accuracy: 0.6003, Loss: 0.7489\n",
      "Epoch   2 Batch  115/269 - Train Accuracy: 0.5841, Validation Accuracy: 0.6009, Loss: 0.7676\n",
      "Epoch   2 Batch  116/269 - Train Accuracy: 0.5991, Validation Accuracy: 0.6001, Loss: 0.7540\n",
      "Epoch   2 Batch  117/269 - Train Accuracy: 0.5939, Validation Accuracy: 0.6023, Loss: 0.7376\n",
      "Epoch   2 Batch  118/269 - Train Accuracy: 0.6251, Validation Accuracy: 0.6012, Loss: 0.7225\n",
      "Epoch   2 Batch  119/269 - Train Accuracy: 0.5822, Validation Accuracy: 0.6048, Loss: 0.7842\n",
      "Epoch   2 Batch  120/269 - Train Accuracy: 0.5885, Validation Accuracy: 0.6061, Loss: 0.7664\n",
      "Epoch   2 Batch  121/269 - Train Accuracy: 0.6020, Validation Accuracy: 0.6098, Loss: 0.7346\n",
      "Epoch   2 Batch  122/269 - Train Accuracy: 0.5964, Validation Accuracy: 0.6009, Loss: 0.7317\n",
      "Epoch   2 Batch  123/269 - Train Accuracy: 0.5846, Validation Accuracy: 0.6004, Loss: 0.7710\n",
      "Epoch   2 Batch  124/269 - Train Accuracy: 0.5993, Validation Accuracy: 0.5983, Loss: 0.7214\n",
      "Epoch   2 Batch  125/269 - Train Accuracy: 0.5967, Validation Accuracy: 0.6000, Loss: 0.7222\n",
      "Epoch   2 Batch  126/269 - Train Accuracy: 0.6096, Validation Accuracy: 0.6064, Loss: 0.7220\n",
      "Epoch   2 Batch  127/269 - Train Accuracy: 0.5916, Validation Accuracy: 0.6008, Loss: 0.7691\n",
      "Epoch   2 Batch  128/269 - Train Accuracy: 0.6084, Validation Accuracy: 0.5967, Loss: 0.7346\n",
      "Epoch   2 Batch  129/269 - Train Accuracy: 0.5903, Validation Accuracy: 0.5973, Loss: 0.7423\n",
      "Epoch   2 Batch  130/269 - Train Accuracy: 0.5713, Validation Accuracy: 0.6029, Loss: 0.7610\n",
      "Epoch   2 Batch  131/269 - Train Accuracy: 0.5840, Validation Accuracy: 0.6061, Loss: 0.7558\n",
      "Epoch   2 Batch  132/269 - Train Accuracy: 0.6051, Validation Accuracy: 0.6036, Loss: 0.7377\n",
      "Epoch   2 Batch  133/269 - Train Accuracy: 0.6003, Validation Accuracy: 0.6038, Loss: 0.7200\n",
      "Epoch   2 Batch  134/269 - Train Accuracy: 0.5849, Validation Accuracy: 0.6069, Loss: 0.7543\n",
      "Epoch   2 Batch  135/269 - Train Accuracy: 0.5795, Validation Accuracy: 0.6110, Loss: 0.7813\n",
      "Epoch   2 Batch  136/269 - Train Accuracy: 0.5830, Validation Accuracy: 0.6081, Loss: 0.7817\n",
      "Epoch   2 Batch  137/269 - Train Accuracy: 0.5921, Validation Accuracy: 0.6054, Loss: 0.7708\n",
      "Epoch   2 Batch  138/269 - Train Accuracy: 0.5836, Validation Accuracy: 0.6029, Loss: 0.7502\n",
      "Epoch   2 Batch  139/269 - Train Accuracy: 0.6178, Validation Accuracy: 0.6050, Loss: 0.7124\n",
      "Epoch   2 Batch  140/269 - Train Accuracy: 0.6078, Validation Accuracy: 0.6051, Loss: 0.7374\n",
      "Epoch   2 Batch  141/269 - Train Accuracy: 0.6038, Validation Accuracy: 0.6073, Loss: 0.7472\n",
      "Epoch   2 Batch  142/269 - Train Accuracy: 0.6156, Validation Accuracy: 0.6119, Loss: 0.7099\n",
      "Epoch   2 Batch  143/269 - Train Accuracy: 0.6019, Validation Accuracy: 0.6025, Loss: 0.7264\n",
      "Epoch   2 Batch  144/269 - Train Accuracy: 0.6165, Validation Accuracy: 0.6158, Loss: 0.7057\n",
      "Epoch   2 Batch  145/269 - Train Accuracy: 0.6152, Validation Accuracy: 0.6191, Loss: 0.7203\n",
      "Epoch   2 Batch  146/269 - Train Accuracy: 0.6097, Validation Accuracy: 0.6168, Loss: 0.7161\n",
      "Epoch   2 Batch  147/269 - Train Accuracy: 0.6243, Validation Accuracy: 0.6078, Loss: 0.6910\n",
      "Epoch   2 Batch  148/269 - Train Accuracy: 0.5890, Validation Accuracy: 0.6043, Loss: 0.7322\n",
      "Epoch   2 Batch  149/269 - Train Accuracy: 0.6119, Validation Accuracy: 0.6109, Loss: 0.7277\n",
      "Epoch   2 Batch  150/269 - Train Accuracy: 0.6070, Validation Accuracy: 0.6045, Loss: 0.7293\n",
      "Epoch   2 Batch  151/269 - Train Accuracy: 0.6281, Validation Accuracy: 0.5958, Loss: 0.6976\n",
      "Epoch   2 Batch  152/269 - Train Accuracy: 0.5999, Validation Accuracy: 0.6032, Loss: 0.7294\n",
      "Epoch   2 Batch  153/269 - Train Accuracy: 0.6164, Validation Accuracy: 0.6064, Loss: 0.7146\n",
      "Epoch   2 Batch  154/269 - Train Accuracy: 0.5869, Validation Accuracy: 0.6040, Loss: 0.7408\n",
      "Epoch   2 Batch  155/269 - Train Accuracy: 0.6285, Validation Accuracy: 0.6078, Loss: 0.6818\n",
      "Epoch   2 Batch  156/269 - Train Accuracy: 0.5996, Validation Accuracy: 0.6136, Loss: 0.7523\n",
      "Epoch   2 Batch  157/269 - Train Accuracy: 0.5945, Validation Accuracy: 0.6147, Loss: 0.7253\n",
      "Epoch   2 Batch  158/269 - Train Accuracy: 0.6038, Validation Accuracy: 0.6178, Loss: 0.7180\n",
      "Epoch   2 Batch  159/269 - Train Accuracy: 0.6137, Validation Accuracy: 0.6167, Loss: 0.7186\n",
      "Epoch   2 Batch  160/269 - Train Accuracy: 0.6031, Validation Accuracy: 0.6137, Loss: 0.7199\n",
      "Epoch   2 Batch  161/269 - Train Accuracy: 0.6034, Validation Accuracy: 0.6137, Loss: 0.7204\n",
      "Epoch   2 Batch  162/269 - Train Accuracy: 0.6091, Validation Accuracy: 0.6171, Loss: 0.7156\n",
      "Epoch   2 Batch  163/269 - Train Accuracy: 0.6202, Validation Accuracy: 0.6172, Loss: 0.7066\n",
      "Epoch   2 Batch  164/269 - Train Accuracy: 0.6168, Validation Accuracy: 0.6110, Loss: 0.7070\n",
      "Epoch   2 Batch  165/269 - Train Accuracy: 0.5914, Validation Accuracy: 0.6174, Loss: 0.7369\n",
      "Epoch   2 Batch  166/269 - Train Accuracy: 0.6296, Validation Accuracy: 0.6187, Loss: 0.6778\n",
      "Epoch   2 Batch  167/269 - Train Accuracy: 0.6037, Validation Accuracy: 0.6166, Loss: 0.7132\n",
      "Epoch   2 Batch  168/269 - Train Accuracy: 0.5939, Validation Accuracy: 0.6046, Loss: 0.7174\n",
      "Epoch   2 Batch  169/269 - Train Accuracy: 0.6038, Validation Accuracy: 0.6125, Loss: 0.7121\n",
      "Epoch   2 Batch  170/269 - Train Accuracy: 0.6133, Validation Accuracy: 0.6170, Loss: 0.7014\n",
      "Epoch   2 Batch  171/269 - Train Accuracy: 0.6047, Validation Accuracy: 0.6183, Loss: 0.7363\n",
      "Epoch   2 Batch  172/269 - Train Accuracy: 0.6021, Validation Accuracy: 0.6165, Loss: 0.7136\n",
      "Epoch   2 Batch  173/269 - Train Accuracy: 0.6102, Validation Accuracy: 0.6152, Loss: 0.6947\n",
      "Epoch   2 Batch  174/269 - Train Accuracy: 0.6052, Validation Accuracy: 0.6210, Loss: 0.7119\n",
      "Epoch   2 Batch  175/269 - Train Accuracy: 0.6215, Validation Accuracy: 0.6207, Loss: 0.7201\n",
      "Epoch   2 Batch  176/269 - Train Accuracy: 0.6024, Validation Accuracy: 0.6222, Loss: 0.7484\n",
      "Epoch   2 Batch  177/269 - Train Accuracy: 0.6116, Validation Accuracy: 0.6206, Loss: 0.6787\n",
      "Epoch   2 Batch  178/269 - Train Accuracy: 0.5931, Validation Accuracy: 0.6183, Loss: 0.7206\n",
      "Epoch   2 Batch  179/269 - Train Accuracy: 0.6177, Validation Accuracy: 0.6159, Loss: 0.7133\n",
      "Epoch   2 Batch  180/269 - Train Accuracy: 0.6057, Validation Accuracy: 0.6147, Loss: 0.6960\n",
      "Epoch   2 Batch  181/269 - Train Accuracy: 0.5937, Validation Accuracy: 0.6182, Loss: 0.7073\n",
      "Epoch   2 Batch  182/269 - Train Accuracy: 0.6192, Validation Accuracy: 0.6178, Loss: 0.7078\n",
      "Epoch   2 Batch  183/269 - Train Accuracy: 0.6723, Validation Accuracy: 0.6159, Loss: 0.6167\n",
      "Epoch   2 Batch  184/269 - Train Accuracy: 0.5909, Validation Accuracy: 0.6119, Loss: 0.7280\n",
      "Epoch   2 Batch  185/269 - Train Accuracy: 0.6203, Validation Accuracy: 0.6190, Loss: 0.6933\n",
      "Epoch   2 Batch  186/269 - Train Accuracy: 0.5959, Validation Accuracy: 0.6209, Loss: 0.7221\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch   2 Batch  187/269 - Train Accuracy: 0.6145, Validation Accuracy: 0.6163, Loss: 0.6850\n",
      "Epoch   2 Batch  188/269 - Train Accuracy: 0.6174, Validation Accuracy: 0.6146, Loss: 0.6827\n",
      "Epoch   2 Batch  189/269 - Train Accuracy: 0.6124, Validation Accuracy: 0.6194, Loss: 0.6831\n",
      "Epoch   2 Batch  190/269 - Train Accuracy: 0.6174, Validation Accuracy: 0.6180, Loss: 0.6888\n",
      "Epoch   2 Batch  191/269 - Train Accuracy: 0.6180, Validation Accuracy: 0.6171, Loss: 0.6940\n",
      "Epoch   2 Batch  192/269 - Train Accuracy: 0.6223, Validation Accuracy: 0.6146, Loss: 0.7000\n",
      "Epoch   2 Batch  193/269 - Train Accuracy: 0.6021, Validation Accuracy: 0.6126, Loss: 0.7028\n",
      "Epoch   2 Batch  194/269 - Train Accuracy: 0.6221, Validation Accuracy: 0.6159, Loss: 0.7085\n",
      "Epoch   2 Batch  195/269 - Train Accuracy: 0.6003, Validation Accuracy: 0.6137, Loss: 0.7069\n",
      "Epoch   2 Batch  196/269 - Train Accuracy: 0.5954, Validation Accuracy: 0.6153, Loss: 0.6995\n",
      "Epoch   2 Batch  197/269 - Train Accuracy: 0.5800, Validation Accuracy: 0.6123, Loss: 0.7271\n",
      "Epoch   2 Batch  198/269 - Train Accuracy: 0.5896, Validation Accuracy: 0.6113, Loss: 0.7439\n",
      "Epoch   2 Batch  199/269 - Train Accuracy: 0.5924, Validation Accuracy: 0.6136, Loss: 0.7094\n",
      "Epoch   2 Batch  200/269 - Train Accuracy: 0.6065, Validation Accuracy: 0.6207, Loss: 0.7205\n",
      "Epoch   2 Batch  201/269 - Train Accuracy: 0.6155, Validation Accuracy: 0.6166, Loss: 0.6957\n",
      "Epoch   2 Batch  202/269 - Train Accuracy: 0.6067, Validation Accuracy: 0.6167, Loss: 0.6949\n",
      "Epoch   2 Batch  203/269 - Train Accuracy: 0.5886, Validation Accuracy: 0.6213, Loss: 0.7353\n",
      "Epoch   2 Batch  204/269 - Train Accuracy: 0.6004, Validation Accuracy: 0.6200, Loss: 0.7233\n",
      "Epoch   2 Batch  205/269 - Train Accuracy: 0.6130, Validation Accuracy: 0.6250, Loss: 0.6826\n",
      "Epoch   2 Batch  206/269 - Train Accuracy: 0.6023, Validation Accuracy: 0.6178, Loss: 0.7270\n",
      "Epoch   2 Batch  207/269 - Train Accuracy: 0.6324, Validation Accuracy: 0.6176, Loss: 0.6651\n",
      "Epoch   2 Batch  208/269 - Train Accuracy: 0.5981, Validation Accuracy: 0.6213, Loss: 0.7178\n",
      "Epoch   2 Batch  209/269 - Train Accuracy: 0.6137, Validation Accuracy: 0.6251, Loss: 0.7026\n",
      "Epoch   2 Batch  210/269 - Train Accuracy: 0.6229, Validation Accuracy: 0.6238, Loss: 0.6767\n",
      "Epoch   2 Batch  211/269 - Train Accuracy: 0.6174, Validation Accuracy: 0.6231, Loss: 0.7013\n",
      "Epoch   2 Batch  212/269 - Train Accuracy: 0.6336, Validation Accuracy: 0.6194, Loss: 0.6765\n",
      "Epoch   2 Batch  213/269 - Train Accuracy: 0.6116, Validation Accuracy: 0.6165, Loss: 0.6826\n",
      "Epoch   2 Batch  214/269 - Train Accuracy: 0.6212, Validation Accuracy: 0.6167, Loss: 0.6761\n",
      "Epoch   2 Batch  215/269 - Train Accuracy: 0.6428, Validation Accuracy: 0.6213, Loss: 0.6440\n",
      "Epoch   2 Batch  216/269 - Train Accuracy: 0.5957, Validation Accuracy: 0.6256, Loss: 0.7329\n",
      "Epoch   2 Batch  217/269 - Train Accuracy: 0.5897, Validation Accuracy: 0.6271, Loss: 0.7206\n",
      "Epoch   2 Batch  218/269 - Train Accuracy: 0.6029, Validation Accuracy: 0.6206, Loss: 0.7095\n",
      "Epoch   2 Batch  219/269 - Train Accuracy: 0.6099, Validation Accuracy: 0.6214, Loss: 0.7117\n",
      "Epoch   2 Batch  220/269 - Train Accuracy: 0.6248, Validation Accuracy: 0.6275, Loss: 0.6462\n",
      "Epoch   2 Batch  221/269 - Train Accuracy: 0.6462, Validation Accuracy: 0.6241, Loss: 0.6758\n",
      "Epoch   2 Batch  222/269 - Train Accuracy: 0.6399, Validation Accuracy: 0.6283, Loss: 0.6594\n",
      "Epoch   2 Batch  223/269 - Train Accuracy: 0.6127, Validation Accuracy: 0.6259, Loss: 0.6679\n",
      "Epoch   2 Batch  224/269 - Train Accuracy: 0.6239, Validation Accuracy: 0.6215, Loss: 0.7004\n",
      "Epoch   2 Batch  225/269 - Train Accuracy: 0.6071, Validation Accuracy: 0.6246, Loss: 0.6967\n",
      "Epoch   2 Batch  226/269 - Train Accuracy: 0.6144, Validation Accuracy: 0.6274, Loss: 0.6768\n",
      "Epoch   2 Batch  227/269 - Train Accuracy: 0.6799, Validation Accuracy: 0.6291, Loss: 0.5963\n",
      "Epoch   2 Batch  228/269 - Train Accuracy: 0.6218, Validation Accuracy: 0.6299, Loss: 0.6789\n",
      "Epoch   2 Batch  229/269 - Train Accuracy: 0.6168, Validation Accuracy: 0.6232, Loss: 0.6637\n",
      "Epoch   2 Batch  230/269 - Train Accuracy: 0.6168, Validation Accuracy: 0.6233, Loss: 0.6805\n",
      "Epoch   2 Batch  231/269 - Train Accuracy: 0.6032, Validation Accuracy: 0.6279, Loss: 0.7138\n",
      "Epoch   2 Batch  232/269 - Train Accuracy: 0.5870, Validation Accuracy: 0.6295, Loss: 0.7073\n",
      "Epoch   2 Batch  233/269 - Train Accuracy: 0.6240, Validation Accuracy: 0.6270, Loss: 0.6787\n",
      "Epoch   2 Batch  234/269 - Train Accuracy: 0.6255, Validation Accuracy: 0.6246, Loss: 0.6776\n",
      "Epoch   2 Batch  235/269 - Train Accuracy: 0.6245, Validation Accuracy: 0.6288, Loss: 0.6601\n",
      "Epoch   2 Batch  236/269 - Train Accuracy: 0.6110, Validation Accuracy: 0.6295, Loss: 0.6626\n",
      "Epoch   2 Batch  237/269 - Train Accuracy: 0.6072, Validation Accuracy: 0.6286, Loss: 0.6714\n",
      "Epoch   2 Batch  238/269 - Train Accuracy: 0.6401, Validation Accuracy: 0.6268, Loss: 0.6617\n",
      "Epoch   2 Batch  239/269 - Train Accuracy: 0.6236, Validation Accuracy: 0.6254, Loss: 0.6638\n",
      "Epoch   2 Batch  240/269 - Train Accuracy: 0.6451, Validation Accuracy: 0.6273, Loss: 0.6157\n",
      "Epoch   2 Batch  241/269 - Train Accuracy: 0.6273, Validation Accuracy: 0.6299, Loss: 0.6732\n",
      "Epoch   2 Batch  242/269 - Train Accuracy: 0.6084, Validation Accuracy: 0.6251, Loss: 0.6697\n",
      "Epoch   2 Batch  243/269 - Train Accuracy: 0.6490, Validation Accuracy: 0.6280, Loss: 0.6547\n",
      "Epoch   2 Batch  244/269 - Train Accuracy: 0.6055, Validation Accuracy: 0.6255, Loss: 0.6707\n",
      "Epoch   2 Batch  245/269 - Train Accuracy: 0.6040, Validation Accuracy: 0.6261, Loss: 0.7046\n",
      "Epoch   2 Batch  246/269 - Train Accuracy: 0.5965, Validation Accuracy: 0.6275, Loss: 0.6776\n",
      "Epoch   2 Batch  247/269 - Train Accuracy: 0.6124, Validation Accuracy: 0.6294, Loss: 0.6927\n",
      "Epoch   2 Batch  248/269 - Train Accuracy: 0.6191, Validation Accuracy: 0.6275, Loss: 0.6544\n",
      "Epoch   2 Batch  249/269 - Train Accuracy: 0.6462, Validation Accuracy: 0.6271, Loss: 0.6381\n",
      "Epoch   2 Batch  250/269 - Train Accuracy: 0.6090, Validation Accuracy: 0.6267, Loss: 0.6757\n",
      "Epoch   2 Batch  251/269 - Train Accuracy: 0.6381, Validation Accuracy: 0.6254, Loss: 0.6517\n",
      "Epoch   2 Batch  252/269 - Train Accuracy: 0.6283, Validation Accuracy: 0.6288, Loss: 0.6708\n",
      "Epoch   2 Batch  253/269 - Train Accuracy: 0.6168, Validation Accuracy: 0.6291, Loss: 0.6771\n",
      "Epoch   2 Batch  254/269 - Train Accuracy: 0.6177, Validation Accuracy: 0.6240, Loss: 0.6634\n",
      "Epoch   2 Batch  255/269 - Train Accuracy: 0.6440, Validation Accuracy: 0.6280, Loss: 0.6367\n",
      "Epoch   2 Batch  256/269 - Train Accuracy: 0.6139, Validation Accuracy: 0.6296, Loss: 0.6739\n",
      "Epoch   2 Batch  257/269 - Train Accuracy: 0.6061, Validation Accuracy: 0.6310, Loss: 0.6736\n",
      "Epoch   2 Batch  258/269 - Train Accuracy: 0.6097, Validation Accuracy: 0.6295, Loss: 0.6677\n",
      "Epoch   2 Batch  259/269 - Train Accuracy: 0.6327, Validation Accuracy: 0.6307, Loss: 0.6638\n",
      "Epoch   2 Batch  260/269 - Train Accuracy: 0.6076, Validation Accuracy: 0.6309, Loss: 0.6949\n",
      "Epoch   2 Batch  261/269 - Train Accuracy: 0.5867, Validation Accuracy: 0.6304, Loss: 0.7064\n",
      "Epoch   2 Batch  262/269 - Train Accuracy: 0.6311, Validation Accuracy: 0.6317, Loss: 0.6640\n",
      "Epoch   2 Batch  263/269 - Train Accuracy: 0.6191, Validation Accuracy: 0.6302, Loss: 0.6791\n",
      "Epoch   2 Batch  264/269 - Train Accuracy: 0.6009, Validation Accuracy: 0.6319, Loss: 0.6939\n",
      "Epoch   2 Batch  265/269 - Train Accuracy: 0.6047, Validation Accuracy: 0.6306, Loss: 0.6823\n",
      "Epoch   2 Batch  266/269 - Train Accuracy: 0.6360, Validation Accuracy: 0.6277, Loss: 0.6484\n",
      "Epoch   2 Batch  267/269 - Train Accuracy: 0.6321, Validation Accuracy: 0.6283, Loss: 0.6631\n",
      "Epoch   3 Batch    1/269 - Train Accuracy: 0.6101, Validation Accuracy: 0.6349, Loss: 0.6768\n",
      "Epoch   3 Batch    2/269 - Train Accuracy: 0.6105, Validation Accuracy: 0.6341, Loss: 0.6669\n",
      "Epoch   3 Batch    3/269 - Train Accuracy: 0.6162, Validation Accuracy: 0.6288, Loss: 0.6700\n",
      "Epoch   3 Batch    4/269 - Train Accuracy: 0.5953, Validation Accuracy: 0.6323, Loss: 0.6818\n",
      "Epoch   3 Batch    5/269 - Train Accuracy: 0.6054, Validation Accuracy: 0.6337, Loss: 0.6730\n",
      "Epoch   3 Batch    6/269 - Train Accuracy: 0.6339, Validation Accuracy: 0.6365, Loss: 0.6293\n",
      "Epoch   3 Batch    7/269 - Train Accuracy: 0.6283, Validation Accuracy: 0.6354, Loss: 0.6403\n",
      "Epoch   3 Batch    8/269 - Train Accuracy: 0.6094, Validation Accuracy: 0.6327, Loss: 0.6930\n",
      "Epoch   3 Batch    9/269 - Train Accuracy: 0.6185, Validation Accuracy: 0.6342, Loss: 0.6681\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch   3 Batch   10/269 - Train Accuracy: 0.6170, Validation Accuracy: 0.6364, Loss: 0.6742\n",
      "Epoch   3 Batch   11/269 - Train Accuracy: 0.6194, Validation Accuracy: 0.6322, Loss: 0.6669\n",
      "Epoch   3 Batch   12/269 - Train Accuracy: 0.6022, Validation Accuracy: 0.6327, Loss: 0.6911\n",
      "Epoch   3 Batch   13/269 - Train Accuracy: 0.6481, Validation Accuracy: 0.6318, Loss: 0.6114\n",
      "Epoch   3 Batch   14/269 - Train Accuracy: 0.6187, Validation Accuracy: 0.6336, Loss: 0.6459\n",
      "Epoch   3 Batch   15/269 - Train Accuracy: 0.6123, Validation Accuracy: 0.6314, Loss: 0.6441\n",
      "Epoch   3 Batch   16/269 - Train Accuracy: 0.6376, Validation Accuracy: 0.6357, Loss: 0.6552\n",
      "Epoch   3 Batch   17/269 - Train Accuracy: 0.6248, Validation Accuracy: 0.6330, Loss: 0.6453\n",
      "Epoch   3 Batch   18/269 - Train Accuracy: 0.6068, Validation Accuracy: 0.6319, Loss: 0.6675\n",
      "Epoch   3 Batch   19/269 - Train Accuracy: 0.6546, Validation Accuracy: 0.6341, Loss: 0.6160\n",
      "Epoch   3 Batch   20/269 - Train Accuracy: 0.6128, Validation Accuracy: 0.6340, Loss: 0.6704\n",
      "Epoch   3 Batch   21/269 - Train Accuracy: 0.6194, Validation Accuracy: 0.6297, Loss: 0.6846\n",
      "Epoch   3 Batch   22/269 - Train Accuracy: 0.6383, Validation Accuracy: 0.6373, Loss: 0.6366\n",
      "Epoch   3 Batch   23/269 - Train Accuracy: 0.6380, Validation Accuracy: 0.6339, Loss: 0.6457\n",
      "Epoch   3 Batch   24/269 - Train Accuracy: 0.6155, Validation Accuracy: 0.6340, Loss: 0.6771\n",
      "Epoch   3 Batch   25/269 - Train Accuracy: 0.6116, Validation Accuracy: 0.6381, Loss: 0.6884\n",
      "Epoch   3 Batch   26/269 - Train Accuracy: 0.6532, Validation Accuracy: 0.6373, Loss: 0.6047\n",
      "Epoch   3 Batch   27/269 - Train Accuracy: 0.6214, Validation Accuracy: 0.6366, Loss: 0.6377\n",
      "Epoch   3 Batch   28/269 - Train Accuracy: 0.5905, Validation Accuracy: 0.6351, Loss: 0.6942\n",
      "Epoch   3 Batch   29/269 - Train Accuracy: 0.6275, Validation Accuracy: 0.6360, Loss: 0.6663\n",
      "Epoch   3 Batch   30/269 - Train Accuracy: 0.6325, Validation Accuracy: 0.6377, Loss: 0.6396\n",
      "Epoch   3 Batch   31/269 - Train Accuracy: 0.6302, Validation Accuracy: 0.6360, Loss: 0.6254\n",
      "Epoch   3 Batch   32/269 - Train Accuracy: 0.6234, Validation Accuracy: 0.6342, Loss: 0.6287\n",
      "Epoch   3 Batch   33/269 - Train Accuracy: 0.6401, Validation Accuracy: 0.6387, Loss: 0.6157\n",
      "Epoch   3 Batch   34/269 - Train Accuracy: 0.6335, Validation Accuracy: 0.6384, Loss: 0.6384\n",
      "Epoch   3 Batch   35/269 - Train Accuracy: 0.6283, Validation Accuracy: 0.6374, Loss: 0.6556\n",
      "Epoch   3 Batch   36/269 - Train Accuracy: 0.6267, Validation Accuracy: 0.6379, Loss: 0.6327\n",
      "Epoch   3 Batch   37/269 - Train Accuracy: 0.6345, Validation Accuracy: 0.6396, Loss: 0.6319\n",
      "Epoch   3 Batch   38/269 - Train Accuracy: 0.6329, Validation Accuracy: 0.6352, Loss: 0.6441\n",
      "Epoch   3 Batch   39/269 - Train Accuracy: 0.6292, Validation Accuracy: 0.6341, Loss: 0.6331\n",
      "Epoch   3 Batch   40/269 - Train Accuracy: 0.6064, Validation Accuracy: 0.6344, Loss: 0.6610\n",
      "Epoch   3 Batch   41/269 - Train Accuracy: 0.6157, Validation Accuracy: 0.6363, Loss: 0.6503\n",
      "Epoch   3 Batch   42/269 - Train Accuracy: 0.6586, Validation Accuracy: 0.6370, Loss: 0.6044\n",
      "Epoch   3 Batch   43/269 - Train Accuracy: 0.6201, Validation Accuracy: 0.6341, Loss: 0.6506\n",
      "Epoch   3 Batch   44/269 - Train Accuracy: 0.6362, Validation Accuracy: 0.6366, Loss: 0.6351\n",
      "Epoch   3 Batch   45/269 - Train Accuracy: 0.6156, Validation Accuracy: 0.6368, Loss: 0.6574\n",
      "Epoch   3 Batch   46/269 - Train Accuracy: 0.6285, Validation Accuracy: 0.6402, Loss: 0.6529\n",
      "Epoch   3 Batch   47/269 - Train Accuracy: 0.6687, Validation Accuracy: 0.6382, Loss: 0.5909\n",
      "Epoch   3 Batch   48/269 - Train Accuracy: 0.6374, Validation Accuracy: 0.6369, Loss: 0.6177\n",
      "Epoch   3 Batch   49/269 - Train Accuracy: 0.6131, Validation Accuracy: 0.6390, Loss: 0.6451\n",
      "Epoch   3 Batch   50/269 - Train Accuracy: 0.6238, Validation Accuracy: 0.6410, Loss: 0.6545\n",
      "Epoch   3 Batch   51/269 - Train Accuracy: 0.6290, Validation Accuracy: 0.6440, Loss: 0.6353\n",
      "Epoch   3 Batch   52/269 - Train Accuracy: 0.6243, Validation Accuracy: 0.6397, Loss: 0.6090\n",
      "Epoch   3 Batch   53/269 - Train Accuracy: 0.6144, Validation Accuracy: 0.6393, Loss: 0.6630\n",
      "Epoch   3 Batch   54/269 - Train Accuracy: 0.6373, Validation Accuracy: 0.6369, Loss: 0.6470\n",
      "Epoch   3 Batch   55/269 - Train Accuracy: 0.6452, Validation Accuracy: 0.6362, Loss: 0.6244\n",
      "Epoch   3 Batch   56/269 - Train Accuracy: 0.6491, Validation Accuracy: 0.6452, Loss: 0.6275\n",
      "Epoch   3 Batch   57/269 - Train Accuracy: 0.6443, Validation Accuracy: 0.6452, Loss: 0.6409\n",
      "Epoch   3 Batch   58/269 - Train Accuracy: 0.6450, Validation Accuracy: 0.6462, Loss: 0.6250\n",
      "Epoch   3 Batch   59/269 - Train Accuracy: 0.6509, Validation Accuracy: 0.6444, Loss: 0.6035\n",
      "Epoch   3 Batch   60/269 - Train Accuracy: 0.6449, Validation Accuracy: 0.6440, Loss: 0.6010\n",
      "Epoch   3 Batch   61/269 - Train Accuracy: 0.6454, Validation Accuracy: 0.6441, Loss: 0.5841\n",
      "Epoch   3 Batch   62/269 - Train Accuracy: 0.6496, Validation Accuracy: 0.6487, Loss: 0.6012\n",
      "Epoch   3 Batch   63/269 - Train Accuracy: 0.6363, Validation Accuracy: 0.6475, Loss: 0.6286\n",
      "Epoch   3 Batch   64/269 - Train Accuracy: 0.6246, Validation Accuracy: 0.6415, Loss: 0.6156\n",
      "Epoch   3 Batch   65/269 - Train Accuracy: 0.6290, Validation Accuracy: 0.6418, Loss: 0.6214\n",
      "Epoch   3 Batch   66/269 - Train Accuracy: 0.6393, Validation Accuracy: 0.6461, Loss: 0.6041\n",
      "Epoch   3 Batch   67/269 - Train Accuracy: 0.6380, Validation Accuracy: 0.6444, Loss: 0.6343\n",
      "Epoch   3 Batch   68/269 - Train Accuracy: 0.6228, Validation Accuracy: 0.6431, Loss: 0.6256\n",
      "Epoch   3 Batch   69/269 - Train Accuracy: 0.6143, Validation Accuracy: 0.6447, Loss: 0.6826\n",
      "Epoch   3 Batch   70/269 - Train Accuracy: 0.6403, Validation Accuracy: 0.6396, Loss: 0.6282\n",
      "Epoch   3 Batch   71/269 - Train Accuracy: 0.6229, Validation Accuracy: 0.6395, Loss: 0.6482\n",
      "Epoch   3 Batch   72/269 - Train Accuracy: 0.6360, Validation Accuracy: 0.6381, Loss: 0.6174\n",
      "Epoch   3 Batch   73/269 - Train Accuracy: 0.6333, Validation Accuracy: 0.6383, Loss: 0.6375\n",
      "Epoch   3 Batch   74/269 - Train Accuracy: 0.6318, Validation Accuracy: 0.6406, Loss: 0.6324\n",
      "Epoch   3 Batch   75/269 - Train Accuracy: 0.6327, Validation Accuracy: 0.6452, Loss: 0.6175\n",
      "Epoch   3 Batch   76/269 - Train Accuracy: 0.6318, Validation Accuracy: 0.6397, Loss: 0.6262\n",
      "Epoch   3 Batch   77/269 - Train Accuracy: 0.6494, Validation Accuracy: 0.6366, Loss: 0.6174\n",
      "Epoch   3 Batch   78/269 - Train Accuracy: 0.6355, Validation Accuracy: 0.6353, Loss: 0.6117\n",
      "Epoch   3 Batch   79/269 - Train Accuracy: 0.6248, Validation Accuracy: 0.6423, Loss: 0.6213\n",
      "Epoch   3 Batch   80/269 - Train Accuracy: 0.6465, Validation Accuracy: 0.6475, Loss: 0.6132\n",
      "Epoch   3 Batch   81/269 - Train Accuracy: 0.6439, Validation Accuracy: 0.6439, Loss: 0.6290\n",
      "Epoch   3 Batch   82/269 - Train Accuracy: 0.6437, Validation Accuracy: 0.6475, Loss: 0.5886\n",
      "Epoch   3 Batch   83/269 - Train Accuracy: 0.6395, Validation Accuracy: 0.6489, Loss: 0.6180\n",
      "Epoch   3 Batch   84/269 - Train Accuracy: 0.6514, Validation Accuracy: 0.6497, Loss: 0.6043\n",
      "Epoch   3 Batch   85/269 - Train Accuracy: 0.6312, Validation Accuracy: 0.6493, Loss: 0.6171\n",
      "Epoch   3 Batch   86/269 - Train Accuracy: 0.6153, Validation Accuracy: 0.6506, Loss: 0.6091\n",
      "Epoch   3 Batch   87/269 - Train Accuracy: 0.6175, Validation Accuracy: 0.6447, Loss: 0.6539\n",
      "Epoch   3 Batch   88/269 - Train Accuracy: 0.6267, Validation Accuracy: 0.6451, Loss: 0.6080\n",
      "Epoch   3 Batch   89/269 - Train Accuracy: 0.6511, Validation Accuracy: 0.6486, Loss: 0.6115\n",
      "Epoch   3 Batch   90/269 - Train Accuracy: 0.6129, Validation Accuracy: 0.6485, Loss: 0.6511\n",
      "Epoch   3 Batch   91/269 - Train Accuracy: 0.6403, Validation Accuracy: 0.6500, Loss: 0.5884\n",
      "Epoch   3 Batch   92/269 - Train Accuracy: 0.6363, Validation Accuracy: 0.6521, Loss: 0.6017\n",
      "Epoch   3 Batch   93/269 - Train Accuracy: 0.6520, Validation Accuracy: 0.6460, Loss: 0.5851\n",
      "Epoch   3 Batch   94/269 - Train Accuracy: 0.6390, Validation Accuracy: 0.6491, Loss: 0.6292\n",
      "Epoch   3 Batch   95/269 - Train Accuracy: 0.6336, Validation Accuracy: 0.6521, Loss: 0.6107\n",
      "Epoch   3 Batch   96/269 - Train Accuracy: 0.6480, Validation Accuracy: 0.6495, Loss: 0.6079\n",
      "Epoch   3 Batch   97/269 - Train Accuracy: 0.6384, Validation Accuracy: 0.6456, Loss: 0.6030\n",
      "Epoch   3 Batch   98/269 - Train Accuracy: 0.6443, Validation Accuracy: 0.6518, Loss: 0.6069\n",
      "Epoch   3 Batch   99/269 - Train Accuracy: 0.6335, Validation Accuracy: 0.6508, Loss: 0.6278\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch   3 Batch  100/269 - Train Accuracy: 0.6656, Validation Accuracy: 0.6516, Loss: 0.6004\n",
      "Epoch   3 Batch  101/269 - Train Accuracy: 0.6070, Validation Accuracy: 0.6559, Loss: 0.6460\n",
      "Epoch   3 Batch  102/269 - Train Accuracy: 0.6399, Validation Accuracy: 0.6531, Loss: 0.6049\n",
      "Epoch   3 Batch  103/269 - Train Accuracy: 0.6443, Validation Accuracy: 0.6499, Loss: 0.6003\n",
      "Epoch   3 Batch  104/269 - Train Accuracy: 0.6334, Validation Accuracy: 0.6474, Loss: 0.6033\n",
      "Epoch   3 Batch  105/269 - Train Accuracy: 0.6322, Validation Accuracy: 0.6507, Loss: 0.6191\n",
      "Epoch   3 Batch  106/269 - Train Accuracy: 0.6319, Validation Accuracy: 0.6482, Loss: 0.6071\n",
      "Epoch   3 Batch  107/269 - Train Accuracy: 0.6028, Validation Accuracy: 0.6486, Loss: 0.6390\n",
      "Epoch   3 Batch  108/269 - Train Accuracy: 0.6299, Validation Accuracy: 0.6452, Loss: 0.6081\n",
      "Epoch   3 Batch  109/269 - Train Accuracy: 0.6195, Validation Accuracy: 0.6438, Loss: 0.6096\n",
      "Epoch   3 Batch  110/269 - Train Accuracy: 0.6310, Validation Accuracy: 0.6454, Loss: 0.5924\n",
      "Epoch   3 Batch  111/269 - Train Accuracy: 0.6180, Validation Accuracy: 0.6451, Loss: 0.6421\n",
      "Epoch   3 Batch  112/269 - Train Accuracy: 0.6451, Validation Accuracy: 0.6495, Loss: 0.5997\n",
      "Epoch   3 Batch  113/269 - Train Accuracy: 0.6433, Validation Accuracy: 0.6490, Loss: 0.5776\n",
      "Epoch   3 Batch  114/269 - Train Accuracy: 0.6383, Validation Accuracy: 0.6501, Loss: 0.6032\n",
      "Epoch   3 Batch  115/269 - Train Accuracy: 0.6274, Validation Accuracy: 0.6466, Loss: 0.6277\n",
      "Epoch   3 Batch  116/269 - Train Accuracy: 0.6408, Validation Accuracy: 0.6464, Loss: 0.6113\n",
      "Epoch   3 Batch  117/269 - Train Accuracy: 0.6329, Validation Accuracy: 0.6475, Loss: 0.6033\n",
      "Epoch   3 Batch  118/269 - Train Accuracy: 0.6689, Validation Accuracy: 0.6499, Loss: 0.5853\n",
      "Epoch   3 Batch  119/269 - Train Accuracy: 0.6273, Validation Accuracy: 0.6497, Loss: 0.6327\n",
      "Epoch   3 Batch  120/269 - Train Accuracy: 0.6331, Validation Accuracy: 0.6460, Loss: 0.6163\n",
      "Epoch   3 Batch  121/269 - Train Accuracy: 0.6416, Validation Accuracy: 0.6505, Loss: 0.5956\n",
      "Epoch   3 Batch  122/269 - Train Accuracy: 0.6455, Validation Accuracy: 0.6520, Loss: 0.5945\n",
      "Epoch   3 Batch  123/269 - Train Accuracy: 0.6335, Validation Accuracy: 0.6525, Loss: 0.6225\n",
      "Epoch   3 Batch  124/269 - Train Accuracy: 0.6350, Validation Accuracy: 0.6529, Loss: 0.5880\n",
      "Epoch   3 Batch  125/269 - Train Accuracy: 0.6480, Validation Accuracy: 0.6554, Loss: 0.5880\n",
      "Epoch   3 Batch  126/269 - Train Accuracy: 0.6485, Validation Accuracy: 0.6515, Loss: 0.5901\n",
      "Epoch   3 Batch  127/269 - Train Accuracy: 0.6257, Validation Accuracy: 0.6519, Loss: 0.6238\n",
      "Epoch   3 Batch  128/269 - Train Accuracy: 0.6618, Validation Accuracy: 0.6552, Loss: 0.5930\n",
      "Epoch   3 Batch  129/269 - Train Accuracy: 0.6419, Validation Accuracy: 0.6523, Loss: 0.5975\n",
      "Epoch   3 Batch  130/269 - Train Accuracy: 0.6186, Validation Accuracy: 0.6500, Loss: 0.6186\n",
      "Epoch   3 Batch  131/269 - Train Accuracy: 0.6223, Validation Accuracy: 0.6531, Loss: 0.6136\n",
      "Epoch   3 Batch  132/269 - Train Accuracy: 0.6378, Validation Accuracy: 0.6531, Loss: 0.6105\n",
      "Epoch   3 Batch  133/269 - Train Accuracy: 0.6484, Validation Accuracy: 0.6506, Loss: 0.5797\n",
      "Epoch   3 Batch  134/269 - Train Accuracy: 0.6206, Validation Accuracy: 0.6493, Loss: 0.6097\n",
      "Epoch   3 Batch  135/269 - Train Accuracy: 0.6174, Validation Accuracy: 0.6488, Loss: 0.6375\n",
      "Epoch   3 Batch  136/269 - Train Accuracy: 0.6194, Validation Accuracy: 0.6502, Loss: 0.6346\n",
      "Epoch   3 Batch  137/269 - Train Accuracy: 0.6394, Validation Accuracy: 0.6512, Loss: 0.6324\n",
      "Epoch   3 Batch  138/269 - Train Accuracy: 0.6379, Validation Accuracy: 0.6496, Loss: 0.6185\n",
      "Epoch   3 Batch  139/269 - Train Accuracy: 0.6606, Validation Accuracy: 0.6525, Loss: 0.5806\n",
      "Epoch   3 Batch  140/269 - Train Accuracy: 0.6485, Validation Accuracy: 0.6564, Loss: 0.6037\n",
      "Epoch   3 Batch  141/269 - Train Accuracy: 0.6440, Validation Accuracy: 0.6533, Loss: 0.6106\n",
      "Epoch   3 Batch  142/269 - Train Accuracy: 0.6496, Validation Accuracy: 0.6532, Loss: 0.5828\n",
      "Epoch   3 Batch  143/269 - Train Accuracy: 0.6449, Validation Accuracy: 0.6535, Loss: 0.5909\n",
      "Epoch   3 Batch  144/269 - Train Accuracy: 0.6500, Validation Accuracy: 0.6526, Loss: 0.5705\n",
      "Epoch   3 Batch  145/269 - Train Accuracy: 0.6501, Validation Accuracy: 0.6540, Loss: 0.5817\n",
      "Epoch   3 Batch  146/269 - Train Accuracy: 0.6365, Validation Accuracy: 0.6517, Loss: 0.5764\n",
      "Epoch   3 Batch  147/269 - Train Accuracy: 0.6547, Validation Accuracy: 0.6495, Loss: 0.5635\n",
      "Epoch   3 Batch  148/269 - Train Accuracy: 0.6371, Validation Accuracy: 0.6491, Loss: 0.5987\n",
      "Epoch   3 Batch  149/269 - Train Accuracy: 0.6454, Validation Accuracy: 0.6545, Loss: 0.5984\n",
      "Epoch   3 Batch  150/269 - Train Accuracy: 0.6524, Validation Accuracy: 0.6543, Loss: 0.5911\n",
      "Epoch   3 Batch  151/269 - Train Accuracy: 0.6735, Validation Accuracy: 0.6553, Loss: 0.5629\n",
      "Epoch   3 Batch  152/269 - Train Accuracy: 0.6505, Validation Accuracy: 0.6548, Loss: 0.5872\n",
      "Epoch   3 Batch  153/269 - Train Accuracy: 0.6484, Validation Accuracy: 0.6555, Loss: 0.5778\n",
      "Epoch   3 Batch  154/269 - Train Accuracy: 0.6284, Validation Accuracy: 0.6555, Loss: 0.6061\n",
      "Epoch   3 Batch  155/269 - Train Accuracy: 0.6798, Validation Accuracy: 0.6555, Loss: 0.5562\n",
      "Epoch   3 Batch  156/269 - Train Accuracy: 0.6339, Validation Accuracy: 0.6568, Loss: 0.6118\n",
      "Epoch   3 Batch  157/269 - Train Accuracy: 0.6409, Validation Accuracy: 0.6565, Loss: 0.5888\n",
      "Epoch   3 Batch  158/269 - Train Accuracy: 0.6486, Validation Accuracy: 0.6581, Loss: 0.5795\n",
      "Epoch   3 Batch  159/269 - Train Accuracy: 0.6478, Validation Accuracy: 0.6578, Loss: 0.5818\n",
      "Epoch   3 Batch  160/269 - Train Accuracy: 0.6482, Validation Accuracy: 0.6562, Loss: 0.5738\n",
      "Epoch   3 Batch  161/269 - Train Accuracy: 0.6443, Validation Accuracy: 0.6539, Loss: 0.5873\n",
      "Epoch   3 Batch  162/269 - Train Accuracy: 0.6576, Validation Accuracy: 0.6543, Loss: 0.5753\n",
      "Epoch   3 Batch  163/269 - Train Accuracy: 0.6576, Validation Accuracy: 0.6539, Loss: 0.5760\n",
      "Epoch   3 Batch  164/269 - Train Accuracy: 0.6528, Validation Accuracy: 0.6561, Loss: 0.5651\n",
      "Epoch   3 Batch  165/269 - Train Accuracy: 0.6304, Validation Accuracy: 0.6552, Loss: 0.5990\n",
      "Epoch   3 Batch  166/269 - Train Accuracy: 0.6641, Validation Accuracy: 0.6531, Loss: 0.5457\n",
      "Epoch   3 Batch  167/269 - Train Accuracy: 0.6468, Validation Accuracy: 0.6521, Loss: 0.5804\n",
      "Epoch   3 Batch  168/269 - Train Accuracy: 0.6406, Validation Accuracy: 0.6514, Loss: 0.5889\n",
      "Epoch   3 Batch  169/269 - Train Accuracy: 0.6394, Validation Accuracy: 0.6518, Loss: 0.5800\n",
      "Epoch   3 Batch  170/269 - Train Accuracy: 0.6418, Validation Accuracy: 0.6574, Loss: 0.5762\n",
      "Epoch   3 Batch  171/269 - Train Accuracy: 0.6472, Validation Accuracy: 0.6518, Loss: 0.5962\n",
      "Epoch   3 Batch  172/269 - Train Accuracy: 0.6404, Validation Accuracy: 0.6534, Loss: 0.5892\n",
      "Epoch   3 Batch  173/269 - Train Accuracy: 0.6524, Validation Accuracy: 0.6564, Loss: 0.5645\n",
      "Epoch   3 Batch  174/269 - Train Accuracy: 0.6341, Validation Accuracy: 0.6562, Loss: 0.5749\n",
      "Epoch   3 Batch  175/269 - Train Accuracy: 0.6505, Validation Accuracy: 0.6552, Loss: 0.5868\n",
      "Epoch   3 Batch  176/269 - Train Accuracy: 0.6372, Validation Accuracy: 0.6551, Loss: 0.6099\n",
      "Epoch   3 Batch  177/269 - Train Accuracy: 0.6685, Validation Accuracy: 0.6562, Loss: 0.5525\n",
      "Epoch   3 Batch  178/269 - Train Accuracy: 0.6315, Validation Accuracy: 0.6517, Loss: 0.5820\n",
      "Epoch   3 Batch  179/269 - Train Accuracy: 0.6556, Validation Accuracy: 0.6553, Loss: 0.5781\n",
      "Epoch   3 Batch  180/269 - Train Accuracy: 0.6512, Validation Accuracy: 0.6552, Loss: 0.5689\n",
      "Epoch   3 Batch  181/269 - Train Accuracy: 0.6351, Validation Accuracy: 0.6546, Loss: 0.5744\n",
      "Epoch   3 Batch  182/269 - Train Accuracy: 0.6689, Validation Accuracy: 0.6654, Loss: 0.5726\n",
      "Epoch   3 Batch  183/269 - Train Accuracy: 0.6955, Validation Accuracy: 0.6586, Loss: 0.5010\n",
      "Epoch   3 Batch  184/269 - Train Accuracy: 0.6270, Validation Accuracy: 0.6559, Loss: 0.5933\n",
      "Epoch   3 Batch  185/269 - Train Accuracy: 0.6569, Validation Accuracy: 0.6559, Loss: 0.5671\n",
      "Epoch   3 Batch  186/269 - Train Accuracy: 0.6344, Validation Accuracy: 0.6576, Loss: 0.5820\n",
      "Epoch   3 Batch  187/269 - Train Accuracy: 0.6642, Validation Accuracy: 0.6566, Loss: 0.5601\n",
      "Epoch   3 Batch  188/269 - Train Accuracy: 0.6682, Validation Accuracy: 0.6574, Loss: 0.5463\n",
      "Epoch   3 Batch  189/269 - Train Accuracy: 0.6528, Validation Accuracy: 0.6523, Loss: 0.5553\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch   3 Batch  190/269 - Train Accuracy: 0.6511, Validation Accuracy: 0.6572, Loss: 0.5589\n",
      "Epoch   3 Batch  191/269 - Train Accuracy: 0.6724, Validation Accuracy: 0.6601, Loss: 0.5609\n",
      "Epoch   3 Batch  192/269 - Train Accuracy: 0.6509, Validation Accuracy: 0.6574, Loss: 0.5612\n",
      "Epoch   3 Batch  193/269 - Train Accuracy: 0.6541, Validation Accuracy: 0.6588, Loss: 0.5625\n",
      "Epoch   3 Batch  194/269 - Train Accuracy: 0.6717, Validation Accuracy: 0.6596, Loss: 0.5673\n",
      "Epoch   3 Batch  195/269 - Train Accuracy: 0.6492, Validation Accuracy: 0.6543, Loss: 0.5730\n",
      "Epoch   3 Batch  196/269 - Train Accuracy: 0.6377, Validation Accuracy: 0.6548, Loss: 0.5618\n",
      "Epoch   3 Batch  197/269 - Train Accuracy: 0.6285, Validation Accuracy: 0.6562, Loss: 0.5919\n",
      "Epoch   3 Batch  198/269 - Train Accuracy: 0.6235, Validation Accuracy: 0.6548, Loss: 0.5961\n",
      "Epoch   3 Batch  199/269 - Train Accuracy: 0.6328, Validation Accuracy: 0.6561, Loss: 0.5811\n",
      "Epoch   3 Batch  200/269 - Train Accuracy: 0.6457, Validation Accuracy: 0.6606, Loss: 0.5787\n",
      "Epoch   3 Batch  201/269 - Train Accuracy: 0.6539, Validation Accuracy: 0.6580, Loss: 0.5696\n",
      "Epoch   3 Batch  202/269 - Train Accuracy: 0.6506, Validation Accuracy: 0.6594, Loss: 0.5591\n",
      "Epoch   3 Batch  203/269 - Train Accuracy: 0.6393, Validation Accuracy: 0.6574, Loss: 0.5952\n",
      "Epoch   3 Batch  204/269 - Train Accuracy: 0.6357, Validation Accuracy: 0.6620, Loss: 0.5895\n",
      "Epoch   3 Batch  205/269 - Train Accuracy: 0.6525, Validation Accuracy: 0.6635, Loss: 0.5522\n",
      "Epoch   3 Batch  206/269 - Train Accuracy: 0.6359, Validation Accuracy: 0.6608, Loss: 0.5921\n",
      "Epoch   3 Batch  207/269 - Train Accuracy: 0.6740, Validation Accuracy: 0.6567, Loss: 0.5414\n",
      "Epoch   3 Batch  208/269 - Train Accuracy: 0.6364, Validation Accuracy: 0.6563, Loss: 0.5795\n",
      "Epoch   3 Batch  209/269 - Train Accuracy: 0.6507, Validation Accuracy: 0.6598, Loss: 0.5655\n",
      "Epoch   3 Batch  210/269 - Train Accuracy: 0.6670, Validation Accuracy: 0.6599, Loss: 0.5492\n",
      "Epoch   3 Batch  211/269 - Train Accuracy: 0.6448, Validation Accuracy: 0.6548, Loss: 0.5637\n",
      "Epoch   3 Batch  212/269 - Train Accuracy: 0.6620, Validation Accuracy: 0.6554, Loss: 0.5601\n",
      "Epoch   3 Batch  213/269 - Train Accuracy: 0.6543, Validation Accuracy: 0.6566, Loss: 0.5572\n",
      "Epoch   3 Batch  214/269 - Train Accuracy: 0.6669, Validation Accuracy: 0.6603, Loss: 0.5571\n",
      "Epoch   3 Batch  215/269 - Train Accuracy: 0.6781, Validation Accuracy: 0.6634, Loss: 0.5291\n",
      "Epoch   3 Batch  216/269 - Train Accuracy: 0.6379, Validation Accuracy: 0.6602, Loss: 0.5926\n",
      "Epoch   3 Batch  217/269 - Train Accuracy: 0.6179, Validation Accuracy: 0.6611, Loss: 0.5842\n",
      "Epoch   3 Batch  218/269 - Train Accuracy: 0.6299, Validation Accuracy: 0.6641, Loss: 0.5767\n",
      "Epoch   3 Batch  219/269 - Train Accuracy: 0.6655, Validation Accuracy: 0.6604, Loss: 0.5832\n",
      "Epoch   3 Batch  220/269 - Train Accuracy: 0.6562, Validation Accuracy: 0.6539, Loss: 0.5279\n",
      "Epoch   3 Batch  221/269 - Train Accuracy: 0.6797, Validation Accuracy: 0.6559, Loss: 0.5516\n",
      "Epoch   3 Batch  222/269 - Train Accuracy: 0.6755, Validation Accuracy: 0.6628, Loss: 0.5370\n",
      "Epoch   3 Batch  223/269 - Train Accuracy: 0.6511, Validation Accuracy: 0.6630, Loss: 0.5507\n",
      "Epoch   3 Batch  224/269 - Train Accuracy: 0.6669, Validation Accuracy: 0.6562, Loss: 0.5693\n",
      "Epoch   3 Batch  225/269 - Train Accuracy: 0.6426, Validation Accuracy: 0.6485, Loss: 0.5550\n",
      "Epoch   3 Batch  226/269 - Train Accuracy: 0.6552, Validation Accuracy: 0.6606, Loss: 0.5587\n",
      "Epoch   3 Batch  227/269 - Train Accuracy: 0.7033, Validation Accuracy: 0.6536, Loss: 0.4872\n",
      "Epoch   3 Batch  228/269 - Train Accuracy: 0.6552, Validation Accuracy: 0.6628, Loss: 0.5570\n",
      "Epoch   3 Batch  229/269 - Train Accuracy: 0.6575, Validation Accuracy: 0.6501, Loss: 0.5425\n",
      "Epoch   3 Batch  230/269 - Train Accuracy: 0.6547, Validation Accuracy: 0.6574, Loss: 0.5504\n",
      "Epoch   3 Batch  231/269 - Train Accuracy: 0.6438, Validation Accuracy: 0.6577, Loss: 0.5859\n",
      "Epoch   3 Batch  232/269 - Train Accuracy: 0.6169, Validation Accuracy: 0.6548, Loss: 0.5767\n",
      "Epoch   3 Batch  233/269 - Train Accuracy: 0.6476, Validation Accuracy: 0.6584, Loss: 0.5542\n",
      "Epoch   3 Batch  234/269 - Train Accuracy: 0.6558, Validation Accuracy: 0.6602, Loss: 0.5485\n",
      "Epoch   3 Batch  235/269 - Train Accuracy: 0.6578, Validation Accuracy: 0.6601, Loss: 0.5368\n",
      "Epoch   3 Batch  236/269 - Train Accuracy: 0.6537, Validation Accuracy: 0.6627, Loss: 0.5437\n",
      "Epoch   3 Batch  237/269 - Train Accuracy: 0.6451, Validation Accuracy: 0.6657, Loss: 0.5505\n",
      "Epoch   3 Batch  238/269 - Train Accuracy: 0.6675, Validation Accuracy: 0.6635, Loss: 0.5319\n",
      "Epoch   3 Batch  239/269 - Train Accuracy: 0.6659, Validation Accuracy: 0.6636, Loss: 0.5448\n",
      "Epoch   3 Batch  240/269 - Train Accuracy: 0.6760, Validation Accuracy: 0.6560, Loss: 0.5009\n",
      "Epoch   3 Batch  241/269 - Train Accuracy: 0.6686, Validation Accuracy: 0.6602, Loss: 0.5508\n",
      "Epoch   3 Batch  242/269 - Train Accuracy: 0.6579, Validation Accuracy: 0.6627, Loss: 0.5377\n",
      "Epoch   3 Batch  243/269 - Train Accuracy: 0.6766, Validation Accuracy: 0.6648, Loss: 0.5221\n",
      "Epoch   3 Batch  244/269 - Train Accuracy: 0.6497, Validation Accuracy: 0.6533, Loss: 0.5464\n",
      "Epoch   3 Batch  245/269 - Train Accuracy: 0.6466, Validation Accuracy: 0.6593, Loss: 0.5745\n",
      "Epoch   3 Batch  246/269 - Train Accuracy: 0.6402, Validation Accuracy: 0.6618, Loss: 0.5473\n",
      "Epoch   3 Batch  247/269 - Train Accuracy: 0.6443, Validation Accuracy: 0.6552, Loss: 0.5685\n",
      "Epoch   3 Batch  248/269 - Train Accuracy: 0.6622, Validation Accuracy: 0.6603, Loss: 0.5406\n",
      "Epoch   3 Batch  249/269 - Train Accuracy: 0.6832, Validation Accuracy: 0.6592, Loss: 0.5149\n",
      "Epoch   3 Batch  250/269 - Train Accuracy: 0.6428, Validation Accuracy: 0.6547, Loss: 0.5520\n",
      "Epoch   3 Batch  251/269 - Train Accuracy: 0.6764, Validation Accuracy: 0.6594, Loss: 0.5367\n",
      "Epoch   3 Batch  252/269 - Train Accuracy: 0.6533, Validation Accuracy: 0.6578, Loss: 0.5465\n",
      "Epoch   3 Batch  253/269 - Train Accuracy: 0.6470, Validation Accuracy: 0.6599, Loss: 0.5536\n",
      "Epoch   3 Batch  254/269 - Train Accuracy: 0.6612, Validation Accuracy: 0.6610, Loss: 0.5320\n",
      "Epoch   3 Batch  255/269 - Train Accuracy: 0.6770, Validation Accuracy: 0.6632, Loss: 0.5212\n",
      "Epoch   3 Batch  256/269 - Train Accuracy: 0.6425, Validation Accuracy: 0.6631, Loss: 0.5479\n",
      "Epoch   3 Batch  257/269 - Train Accuracy: 0.6417, Validation Accuracy: 0.6585, Loss: 0.5475\n",
      "Epoch   3 Batch  258/269 - Train Accuracy: 0.6443, Validation Accuracy: 0.6636, Loss: 0.5476\n",
      "Epoch   3 Batch  259/269 - Train Accuracy: 0.6747, Validation Accuracy: 0.6674, Loss: 0.5334\n",
      "Epoch   3 Batch  260/269 - Train Accuracy: 0.6371, Validation Accuracy: 0.6604, Loss: 0.5591\n",
      "Epoch   3 Batch  261/269 - Train Accuracy: 0.6431, Validation Accuracy: 0.6655, Loss: 0.5709\n",
      "Epoch   3 Batch  262/269 - Train Accuracy: 0.6759, Validation Accuracy: 0.6661, Loss: 0.5369\n",
      "Epoch   3 Batch  263/269 - Train Accuracy: 0.6467, Validation Accuracy: 0.6595, Loss: 0.5572\n",
      "Epoch   3 Batch  264/269 - Train Accuracy: 0.6283, Validation Accuracy: 0.6474, Loss: 0.5618\n",
      "Epoch   3 Batch  265/269 - Train Accuracy: 0.6396, Validation Accuracy: 0.6485, Loss: 0.5508\n",
      "Epoch   3 Batch  266/269 - Train Accuracy: 0.6777, Validation Accuracy: 0.6591, Loss: 0.5319\n",
      "Epoch   3 Batch  267/269 - Train Accuracy: 0.6684, Validation Accuracy: 0.6617, Loss: 0.5351\n",
      "Epoch   4 Batch    1/269 - Train Accuracy: 0.6541, Validation Accuracy: 0.6636, Loss: 0.5534\n",
      "Epoch   4 Batch    2/269 - Train Accuracy: 0.6464, Validation Accuracy: 0.6641, Loss: 0.5394\n",
      "Epoch   4 Batch    3/269 - Train Accuracy: 0.6509, Validation Accuracy: 0.6623, Loss: 0.5453\n",
      "Epoch   4 Batch    4/269 - Train Accuracy: 0.6287, Validation Accuracy: 0.6580, Loss: 0.5532\n",
      "Epoch   4 Batch    5/269 - Train Accuracy: 0.6363, Validation Accuracy: 0.6606, Loss: 0.5546\n",
      "Epoch   4 Batch    6/269 - Train Accuracy: 0.6635, Validation Accuracy: 0.6594, Loss: 0.5123\n",
      "Epoch   4 Batch    7/269 - Train Accuracy: 0.6610, Validation Accuracy: 0.6572, Loss: 0.5211\n",
      "Epoch   4 Batch    8/269 - Train Accuracy: 0.6523, Validation Accuracy: 0.6579, Loss: 0.5544\n",
      "Epoch   4 Batch    9/269 - Train Accuracy: 0.6372, Validation Accuracy: 0.6581, Loss: 0.5399\n",
      "Epoch   4 Batch   10/269 - Train Accuracy: 0.6586, Validation Accuracy: 0.6619, Loss: 0.5419\n",
      "Epoch   4 Batch   11/269 - Train Accuracy: 0.6558, Validation Accuracy: 0.6623, Loss: 0.5409\n",
      "Epoch   4 Batch   12/269 - Train Accuracy: 0.6402, Validation Accuracy: 0.6626, Loss: 0.5574\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch   4 Batch   13/269 - Train Accuracy: 0.6864, Validation Accuracy: 0.6635, Loss: 0.4902\n",
      "Epoch   4 Batch   14/269 - Train Accuracy: 0.6633, Validation Accuracy: 0.6644, Loss: 0.5261\n",
      "Epoch   4 Batch   15/269 - Train Accuracy: 0.6510, Validation Accuracy: 0.6638, Loss: 0.5158\n",
      "Epoch   4 Batch   16/269 - Train Accuracy: 0.6795, Validation Accuracy: 0.6602, Loss: 0.5249\n",
      "Epoch   4 Batch   17/269 - Train Accuracy: 0.6574, Validation Accuracy: 0.6616, Loss: 0.5119\n",
      "Epoch   4 Batch   18/269 - Train Accuracy: 0.6402, Validation Accuracy: 0.6628, Loss: 0.5425\n",
      "Epoch   4 Batch   19/269 - Train Accuracy: 0.6796, Validation Accuracy: 0.6634, Loss: 0.4884\n",
      "Epoch   4 Batch   20/269 - Train Accuracy: 0.6582, Validation Accuracy: 0.6596, Loss: 0.5419\n",
      "Epoch   4 Batch   21/269 - Train Accuracy: 0.6480, Validation Accuracy: 0.6589, Loss: 0.5598\n",
      "Epoch   4 Batch   22/269 - Train Accuracy: 0.6721, Validation Accuracy: 0.6581, Loss: 0.5072\n",
      "Epoch   4 Batch   23/269 - Train Accuracy: 0.6710, Validation Accuracy: 0.6630, Loss: 0.5073\n",
      "Epoch   4 Batch   24/269 - Train Accuracy: 0.6474, Validation Accuracy: 0.6665, Loss: 0.5432\n",
      "Epoch   4 Batch   25/269 - Train Accuracy: 0.6525, Validation Accuracy: 0.6653, Loss: 0.5536\n",
      "Epoch   4 Batch   26/269 - Train Accuracy: 0.6898, Validation Accuracy: 0.6628, Loss: 0.4809\n",
      "Epoch   4 Batch   27/269 - Train Accuracy: 0.6638, Validation Accuracy: 0.6651, Loss: 0.5133\n",
      "Epoch   4 Batch   28/269 - Train Accuracy: 0.6272, Validation Accuracy: 0.6617, Loss: 0.5599\n",
      "Epoch   4 Batch   29/269 - Train Accuracy: 0.6612, Validation Accuracy: 0.6617, Loss: 0.5463\n",
      "Epoch   4 Batch   30/269 - Train Accuracy: 0.6643, Validation Accuracy: 0.6603, Loss: 0.5112\n",
      "Epoch   4 Batch   31/269 - Train Accuracy: 0.6586, Validation Accuracy: 0.6612, Loss: 0.5043\n",
      "Epoch   4 Batch   32/269 - Train Accuracy: 0.6659, Validation Accuracy: 0.6650, Loss: 0.5091\n",
      "Epoch   4 Batch   33/269 - Train Accuracy: 0.6772, Validation Accuracy: 0.6648, Loss: 0.4965\n",
      "Epoch   4 Batch   34/269 - Train Accuracy: 0.6626, Validation Accuracy: 0.6643, Loss: 0.5041\n",
      "Epoch   4 Batch   35/269 - Train Accuracy: 0.6577, Validation Accuracy: 0.6653, Loss: 0.5267\n",
      "Epoch   4 Batch   36/269 - Train Accuracy: 0.6696, Validation Accuracy: 0.6685, Loss: 0.5103\n",
      "Epoch   4 Batch   37/269 - Train Accuracy: 0.6741, Validation Accuracy: 0.6662, Loss: 0.5085\n",
      "Epoch   4 Batch   38/269 - Train Accuracy: 0.6795, Validation Accuracy: 0.6642, Loss: 0.5121\n",
      "Epoch   4 Batch   39/269 - Train Accuracy: 0.6707, Validation Accuracy: 0.6633, Loss: 0.5071\n",
      "Epoch   4 Batch   40/269 - Train Accuracy: 0.6469, Validation Accuracy: 0.6610, Loss: 0.5305\n",
      "Epoch   4 Batch   41/269 - Train Accuracy: 0.6552, Validation Accuracy: 0.6633, Loss: 0.5251\n",
      "Epoch   4 Batch   42/269 - Train Accuracy: 0.6807, Validation Accuracy: 0.6626, Loss: 0.4918\n",
      "Epoch   4 Batch   43/269 - Train Accuracy: 0.6564, Validation Accuracy: 0.6650, Loss: 0.5244\n",
      "Epoch   4 Batch   44/269 - Train Accuracy: 0.6717, Validation Accuracy: 0.6670, Loss: 0.5143\n",
      "Epoch   4 Batch   45/269 - Train Accuracy: 0.6558, Validation Accuracy: 0.6629, Loss: 0.5290\n",
      "Epoch   4 Batch   46/269 - Train Accuracy: 0.6620, Validation Accuracy: 0.6676, Loss: 0.5333\n",
      "Epoch   4 Batch   47/269 - Train Accuracy: 0.7016, Validation Accuracy: 0.6645, Loss: 0.4776\n",
      "Epoch   4 Batch   48/269 - Train Accuracy: 0.6803, Validation Accuracy: 0.6638, Loss: 0.4929\n",
      "Epoch   4 Batch   49/269 - Train Accuracy: 0.6518, Validation Accuracy: 0.6639, Loss: 0.5200\n",
      "Epoch   4 Batch   50/269 - Train Accuracy: 0.6595, Validation Accuracy: 0.6689, Loss: 0.5282\n",
      "Epoch   4 Batch   51/269 - Train Accuracy: 0.6550, Validation Accuracy: 0.6662, Loss: 0.5076\n",
      "Epoch   4 Batch   52/269 - Train Accuracy: 0.6536, Validation Accuracy: 0.6655, Loss: 0.4838\n",
      "Epoch   4 Batch   53/269 - Train Accuracy: 0.6503, Validation Accuracy: 0.6715, Loss: 0.5289\n",
      "Epoch   4 Batch   54/269 - Train Accuracy: 0.6654, Validation Accuracy: 0.6739, Loss: 0.5232\n",
      "Epoch   4 Batch   55/269 - Train Accuracy: 0.6807, Validation Accuracy: 0.6681, Loss: 0.4957\n",
      "Epoch   4 Batch   56/269 - Train Accuracy: 0.6872, Validation Accuracy: 0.6665, Loss: 0.5125\n",
      "Epoch   4 Batch   57/269 - Train Accuracy: 0.6726, Validation Accuracy: 0.6728, Loss: 0.5183\n",
      "Epoch   4 Batch   58/269 - Train Accuracy: 0.6786, Validation Accuracy: 0.6721, Loss: 0.4961\n",
      "Epoch   4 Batch   59/269 - Train Accuracy: 0.6895, Validation Accuracy: 0.6688, Loss: 0.4723\n",
      "Epoch   4 Batch   60/269 - Train Accuracy: 0.6855, Validation Accuracy: 0.6715, Loss: 0.4837\n",
      "Epoch   4 Batch   61/269 - Train Accuracy: 0.6868, Validation Accuracy: 0.6745, Loss: 0.4689\n",
      "Epoch   4 Batch   62/269 - Train Accuracy: 0.6878, Validation Accuracy: 0.6730, Loss: 0.4840\n",
      "Epoch   4 Batch   63/269 - Train Accuracy: 0.6693, Validation Accuracy: 0.6769, Loss: 0.5078\n",
      "Epoch   4 Batch   64/269 - Train Accuracy: 0.6669, Validation Accuracy: 0.6679, Loss: 0.4954\n",
      "Epoch   4 Batch   65/269 - Train Accuracy: 0.6748, Validation Accuracy: 0.6743, Loss: 0.5071\n",
      "Epoch   4 Batch   66/269 - Train Accuracy: 0.6793, Validation Accuracy: 0.6745, Loss: 0.4834\n",
      "Epoch   4 Batch   67/269 - Train Accuracy: 0.6773, Validation Accuracy: 0.6741, Loss: 0.5094\n",
      "Epoch   4 Batch   68/269 - Train Accuracy: 0.6558, Validation Accuracy: 0.6670, Loss: 0.5074\n",
      "Epoch   4 Batch   69/269 - Train Accuracy: 0.6451, Validation Accuracy: 0.6751, Loss: 0.5448\n",
      "Epoch   4 Batch   70/269 - Train Accuracy: 0.6732, Validation Accuracy: 0.6708, Loss: 0.5077\n",
      "Epoch   4 Batch   71/269 - Train Accuracy: 0.6678, Validation Accuracy: 0.6703, Loss: 0.5214\n",
      "Epoch   4 Batch   72/269 - Train Accuracy: 0.6696, Validation Accuracy: 0.6784, Loss: 0.4970\n",
      "Epoch   4 Batch   73/269 - Train Accuracy: 0.6665, Validation Accuracy: 0.6761, Loss: 0.5078\n",
      "Epoch   4 Batch   74/269 - Train Accuracy: 0.6770, Validation Accuracy: 0.6758, Loss: 0.5029\n",
      "Epoch   4 Batch   75/269 - Train Accuracy: 0.6748, Validation Accuracy: 0.6772, Loss: 0.4870\n",
      "Epoch   4 Batch   76/269 - Train Accuracy: 0.6499, Validation Accuracy: 0.6703, Loss: 0.5005\n",
      "Epoch   4 Batch   77/269 - Train Accuracy: 0.6824, Validation Accuracy: 0.6732, Loss: 0.4972\n",
      "Epoch   4 Batch   78/269 - Train Accuracy: 0.6937, Validation Accuracy: 0.6767, Loss: 0.4927\n",
      "Epoch   4 Batch   79/269 - Train Accuracy: 0.6715, Validation Accuracy: 0.6763, Loss: 0.4910\n",
      "Epoch   4 Batch   80/269 - Train Accuracy: 0.6848, Validation Accuracy: 0.6751, Loss: 0.4863\n",
      "Epoch   4 Batch   81/269 - Train Accuracy: 0.6838, Validation Accuracy: 0.6760, Loss: 0.5017\n",
      "Epoch   4 Batch   82/269 - Train Accuracy: 0.7015, Validation Accuracy: 0.6789, Loss: 0.4720\n",
      "Epoch   4 Batch   83/269 - Train Accuracy: 0.6713, Validation Accuracy: 0.6743, Loss: 0.4969\n",
      "Epoch   4 Batch   84/269 - Train Accuracy: 0.6867, Validation Accuracy: 0.6743, Loss: 0.4829\n",
      "Epoch   4 Batch   85/269 - Train Accuracy: 0.6653, Validation Accuracy: 0.6747, Loss: 0.4919\n",
      "Epoch   4 Batch   86/269 - Train Accuracy: 0.6644, Validation Accuracy: 0.6791, Loss: 0.4809\n",
      "Epoch   4 Batch   87/269 - Train Accuracy: 0.6616, Validation Accuracy: 0.6678, Loss: 0.5230\n",
      "Epoch   4 Batch   88/269 - Train Accuracy: 0.6680, Validation Accuracy: 0.6673, Loss: 0.4885\n",
      "Epoch   4 Batch   89/269 - Train Accuracy: 0.6894, Validation Accuracy: 0.6783, Loss: 0.4903\n",
      "Epoch   4 Batch   90/269 - Train Accuracy: 0.6389, Validation Accuracy: 0.6724, Loss: 0.5223\n",
      "Epoch   4 Batch   91/269 - Train Accuracy: 0.6862, Validation Accuracy: 0.6705, Loss: 0.4764\n",
      "Epoch   4 Batch   92/269 - Train Accuracy: 0.6854, Validation Accuracy: 0.6748, Loss: 0.4879\n",
      "Epoch   4 Batch   93/269 - Train Accuracy: 0.6844, Validation Accuracy: 0.6819, Loss: 0.4717\n",
      "Epoch   4 Batch   94/269 - Train Accuracy: 0.6723, Validation Accuracy: 0.6751, Loss: 0.5021\n",
      "Epoch   4 Batch   95/269 - Train Accuracy: 0.6656, Validation Accuracy: 0.6760, Loss: 0.4920\n",
      "Epoch   4 Batch   96/269 - Train Accuracy: 0.6863, Validation Accuracy: 0.6835, Loss: 0.4830\n",
      "Epoch   4 Batch   97/269 - Train Accuracy: 0.6815, Validation Accuracy: 0.6818, Loss: 0.4847\n",
      "Epoch   4 Batch   98/269 - Train Accuracy: 0.6908, Validation Accuracy: 0.6782, Loss: 0.4978\n",
      "Epoch   4 Batch   99/269 - Train Accuracy: 0.6637, Validation Accuracy: 0.6694, Loss: 0.4975\n",
      "Epoch   4 Batch  100/269 - Train Accuracy: 0.6995, Validation Accuracy: 0.6872, Loss: 0.4819\n",
      "Epoch   4 Batch  101/269 - Train Accuracy: 0.6661, Validation Accuracy: 0.6845, Loss: 0.5126\n",
      "Epoch   4 Batch  102/269 - Train Accuracy: 0.6568, Validation Accuracy: 0.6655, Loss: 0.4884\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch   4 Batch  103/269 - Train Accuracy: 0.6897, Validation Accuracy: 0.6786, Loss: 0.5038\n",
      "Epoch   4 Batch  104/269 - Train Accuracy: 0.6612, Validation Accuracy: 0.6825, Loss: 0.4806\n",
      "Epoch   4 Batch  105/269 - Train Accuracy: 0.6629, Validation Accuracy: 0.6740, Loss: 0.5045\n",
      "Epoch   4 Batch  106/269 - Train Accuracy: 0.6616, Validation Accuracy: 0.6722, Loss: 0.4902\n",
      "Epoch   4 Batch  107/269 - Train Accuracy: 0.6598, Validation Accuracy: 0.6906, Loss: 0.5201\n",
      "Epoch   4 Batch  108/269 - Train Accuracy: 0.6764, Validation Accuracy: 0.6779, Loss: 0.4962\n",
      "Epoch   4 Batch  109/269 - Train Accuracy: 0.6665, Validation Accuracy: 0.6712, Loss: 0.4877\n",
      "Epoch   4 Batch  110/269 - Train Accuracy: 0.6615, Validation Accuracy: 0.6730, Loss: 0.4844\n",
      "Epoch   4 Batch  111/269 - Train Accuracy: 0.6610, Validation Accuracy: 0.6769, Loss: 0.5246\n",
      "Epoch   4 Batch  112/269 - Train Accuracy: 0.6841, Validation Accuracy: 0.6761, Loss: 0.4881\n",
      "Epoch   4 Batch  113/269 - Train Accuracy: 0.6735, Validation Accuracy: 0.6802, Loss: 0.4733\n",
      "Epoch   4 Batch  114/269 - Train Accuracy: 0.6759, Validation Accuracy: 0.6708, Loss: 0.4854\n",
      "Epoch   4 Batch  115/269 - Train Accuracy: 0.6659, Validation Accuracy: 0.6689, Loss: 0.5056\n",
      "Epoch   4 Batch  116/269 - Train Accuracy: 0.6924, Validation Accuracy: 0.6696, Loss: 0.4907\n",
      "Epoch   4 Batch  117/269 - Train Accuracy: 0.6689, Validation Accuracy: 0.6729, Loss: 0.4753\n",
      "Epoch   4 Batch  118/269 - Train Accuracy: 0.7074, Validation Accuracy: 0.6828, Loss: 0.4704\n",
      "Epoch   4 Batch  119/269 - Train Accuracy: 0.6855, Validation Accuracy: 0.6760, Loss: 0.5024\n",
      "Epoch   4 Batch  120/269 - Train Accuracy: 0.6669, Validation Accuracy: 0.6784, Loss: 0.4934\n",
      "Epoch   4 Batch  121/269 - Train Accuracy: 0.6905, Validation Accuracy: 0.6763, Loss: 0.4731\n",
      "Epoch   4 Batch  122/269 - Train Accuracy: 0.6849, Validation Accuracy: 0.6750, Loss: 0.4753\n",
      "Epoch   4 Batch  123/269 - Train Accuracy: 0.6844, Validation Accuracy: 0.6818, Loss: 0.4940\n",
      "Epoch   4 Batch  124/269 - Train Accuracy: 0.6838, Validation Accuracy: 0.6836, Loss: 0.4642\n",
      "Epoch   4 Batch  125/269 - Train Accuracy: 0.7018, Validation Accuracy: 0.6905, Loss: 0.4681\n",
      "Epoch   4 Batch  126/269 - Train Accuracy: 0.6810, Validation Accuracy: 0.6821, Loss: 0.4709\n",
      "Epoch   4 Batch  127/269 - Train Accuracy: 0.6691, Validation Accuracy: 0.6768, Loss: 0.4967\n",
      "Epoch   4 Batch  128/269 - Train Accuracy: 0.7016, Validation Accuracy: 0.6988, Loss: 0.4793\n",
      "Epoch   4 Batch  129/269 - Train Accuracy: 0.6822, Validation Accuracy: 0.7001, Loss: 0.4749\n",
      "Epoch   4 Batch  130/269 - Train Accuracy: 0.6761, Validation Accuracy: 0.6828, Loss: 0.4979\n",
      "Epoch   4 Batch  131/269 - Train Accuracy: 0.6718, Validation Accuracy: 0.6814, Loss: 0.4904\n",
      "Epoch   4 Batch  132/269 - Train Accuracy: 0.6773, Validation Accuracy: 0.6789, Loss: 0.4857\n",
      "Epoch   4 Batch  133/269 - Train Accuracy: 0.7028, Validation Accuracy: 0.6805, Loss: 0.4577\n",
      "Epoch   4 Batch  134/269 - Train Accuracy: 0.6652, Validation Accuracy: 0.6813, Loss: 0.4873\n",
      "Epoch   4 Batch  135/269 - Train Accuracy: 0.6611, Validation Accuracy: 0.6859, Loss: 0.5141\n",
      "Epoch   4 Batch  136/269 - Train Accuracy: 0.6760, Validation Accuracy: 0.6838, Loss: 0.5112\n",
      "Epoch   4 Batch  137/269 - Train Accuracy: 0.6658, Validation Accuracy: 0.6863, Loss: 0.5022\n",
      "Epoch   4 Batch  138/269 - Train Accuracy: 0.6781, Validation Accuracy: 0.6831, Loss: 0.5011\n",
      "Epoch   4 Batch  139/269 - Train Accuracy: 0.6896, Validation Accuracy: 0.6841, Loss: 0.4604\n",
      "Epoch   4 Batch  140/269 - Train Accuracy: 0.6919, Validation Accuracy: 0.6783, Loss: 0.4871\n",
      "Epoch   4 Batch  141/269 - Train Accuracy: 0.6825, Validation Accuracy: 0.6883, Loss: 0.4861\n",
      "Epoch   4 Batch  142/269 - Train Accuracy: 0.6870, Validation Accuracy: 0.6863, Loss: 0.4584\n",
      "Epoch   4 Batch  143/269 - Train Accuracy: 0.7002, Validation Accuracy: 0.6867, Loss: 0.4626\n",
      "Epoch   4 Batch  144/269 - Train Accuracy: 0.7084, Validation Accuracy: 0.6810, Loss: 0.4530\n",
      "Epoch   4 Batch  145/269 - Train Accuracy: 0.6935, Validation Accuracy: 0.6810, Loss: 0.4635\n",
      "Epoch   4 Batch  146/269 - Train Accuracy: 0.6928, Validation Accuracy: 0.6897, Loss: 0.4728\n",
      "Epoch   4 Batch  147/269 - Train Accuracy: 0.6976, Validation Accuracy: 0.6854, Loss: 0.4422\n",
      "Epoch   4 Batch  148/269 - Train Accuracy: 0.6705, Validation Accuracy: 0.6861, Loss: 0.4839\n",
      "Epoch   4 Batch  149/269 - Train Accuracy: 0.6694, Validation Accuracy: 0.6796, Loss: 0.4742\n",
      "Epoch   4 Batch  150/269 - Train Accuracy: 0.6917, Validation Accuracy: 0.6865, Loss: 0.4778\n",
      "Epoch   4 Batch  151/269 - Train Accuracy: 0.7100, Validation Accuracy: 0.6903, Loss: 0.4546\n",
      "Epoch   4 Batch  152/269 - Train Accuracy: 0.6984, Validation Accuracy: 0.6962, Loss: 0.4714\n",
      "Epoch   4 Batch  153/269 - Train Accuracy: 0.6856, Validation Accuracy: 0.6813, Loss: 0.4672\n",
      "Epoch   4 Batch  154/269 - Train Accuracy: 0.6817, Validation Accuracy: 0.6892, Loss: 0.4886\n",
      "Epoch   4 Batch  155/269 - Train Accuracy: 0.7095, Validation Accuracy: 0.6803, Loss: 0.4475\n",
      "Epoch   4 Batch  156/269 - Train Accuracy: 0.6627, Validation Accuracy: 0.6937, Loss: 0.4829\n",
      "Epoch   4 Batch  157/269 - Train Accuracy: 0.6734, Validation Accuracy: 0.6861, Loss: 0.4735\n",
      "Epoch   4 Batch  158/269 - Train Accuracy: 0.6887, Validation Accuracy: 0.6845, Loss: 0.4713\n",
      "Epoch   4 Batch  159/269 - Train Accuracy: 0.6850, Validation Accuracy: 0.6868, Loss: 0.4670\n",
      "Epoch   4 Batch  160/269 - Train Accuracy: 0.6908, Validation Accuracy: 0.6887, Loss: 0.4699\n",
      "Epoch   4 Batch  161/269 - Train Accuracy: 0.6904, Validation Accuracy: 0.7007, Loss: 0.4688\n",
      "Epoch   4 Batch  162/269 - Train Accuracy: 0.7110, Validation Accuracy: 0.6884, Loss: 0.4523\n",
      "Epoch   4 Batch  163/269 - Train Accuracy: 0.7073, Validation Accuracy: 0.6945, Loss: 0.4720\n",
      "Epoch   4 Batch  164/269 - Train Accuracy: 0.7118, Validation Accuracy: 0.6932, Loss: 0.4621\n",
      "Epoch   4 Batch  165/269 - Train Accuracy: 0.6813, Validation Accuracy: 0.6906, Loss: 0.4719\n",
      "Epoch   4 Batch  166/269 - Train Accuracy: 0.7061, Validation Accuracy: 0.6951, Loss: 0.4381\n",
      "Epoch   4 Batch  167/269 - Train Accuracy: 0.6996, Validation Accuracy: 0.6874, Loss: 0.4554\n",
      "Epoch   4 Batch  168/269 - Train Accuracy: 0.6798, Validation Accuracy: 0.6904, Loss: 0.4685\n",
      "Epoch   4 Batch  169/269 - Train Accuracy: 0.7001, Validation Accuracy: 0.6907, Loss: 0.4600\n",
      "Epoch   4 Batch  170/269 - Train Accuracy: 0.6868, Validation Accuracy: 0.6887, Loss: 0.4593\n",
      "Epoch   4 Batch  171/269 - Train Accuracy: 0.6991, Validation Accuracy: 0.6850, Loss: 0.4676\n",
      "Epoch   4 Batch  172/269 - Train Accuracy: 0.6938, Validation Accuracy: 0.6859, Loss: 0.4686\n",
      "Epoch   4 Batch  173/269 - Train Accuracy: 0.7031, Validation Accuracy: 0.6914, Loss: 0.4459\n",
      "Epoch   4 Batch  174/269 - Train Accuracy: 0.6933, Validation Accuracy: 0.6934, Loss: 0.4651\n",
      "Epoch   4 Batch  175/269 - Train Accuracy: 0.6802, Validation Accuracy: 0.6900, Loss: 0.4704\n",
      "Epoch   4 Batch  176/269 - Train Accuracy: 0.6788, Validation Accuracy: 0.6957, Loss: 0.4940\n",
      "Epoch   4 Batch  177/269 - Train Accuracy: 0.6970, Validation Accuracy: 0.6983, Loss: 0.4383\n",
      "Epoch   4 Batch  178/269 - Train Accuracy: 0.6973, Validation Accuracy: 0.6928, Loss: 0.4683\n",
      "Epoch   4 Batch  179/269 - Train Accuracy: 0.7001, Validation Accuracy: 0.6946, Loss: 0.4561\n",
      "Epoch   4 Batch  180/269 - Train Accuracy: 0.7003, Validation Accuracy: 0.6960, Loss: 0.4493\n",
      "Epoch   4 Batch  181/269 - Train Accuracy: 0.6955, Validation Accuracy: 0.7009, Loss: 0.4615\n",
      "Epoch   4 Batch  182/269 - Train Accuracy: 0.7134, Validation Accuracy: 0.6987, Loss: 0.4540\n",
      "Epoch   4 Batch  183/269 - Train Accuracy: 0.7355, Validation Accuracy: 0.6971, Loss: 0.3959\n",
      "Epoch   4 Batch  184/269 - Train Accuracy: 0.6950, Validation Accuracy: 0.6999, Loss: 0.4602\n",
      "Epoch   4 Batch  185/269 - Train Accuracy: 0.7118, Validation Accuracy: 0.7005, Loss: 0.4498\n",
      "Epoch   4 Batch  186/269 - Train Accuracy: 0.6969, Validation Accuracy: 0.7014, Loss: 0.4621\n",
      "Epoch   4 Batch  187/269 - Train Accuracy: 0.7147, Validation Accuracy: 0.6983, Loss: 0.4442\n",
      "Epoch   4 Batch  188/269 - Train Accuracy: 0.7161, Validation Accuracy: 0.6981, Loss: 0.4286\n",
      "Epoch   4 Batch  189/269 - Train Accuracy: 0.7080, Validation Accuracy: 0.6973, Loss: 0.4352\n",
      "Epoch   4 Batch  190/269 - Train Accuracy: 0.6922, Validation Accuracy: 0.7012, Loss: 0.4335\n",
      "Epoch   4 Batch  191/269 - Train Accuracy: 0.7163, Validation Accuracy: 0.7024, Loss: 0.4395\n",
      "Epoch   4 Batch  192/269 - Train Accuracy: 0.7204, Validation Accuracy: 0.6913, Loss: 0.4491\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch   4 Batch  193/269 - Train Accuracy: 0.7227, Validation Accuracy: 0.6998, Loss: 0.4424\n",
      "Epoch   4 Batch  194/269 - Train Accuracy: 0.7072, Validation Accuracy: 0.6937, Loss: 0.4519\n",
      "Epoch   4 Batch  195/269 - Train Accuracy: 0.6870, Validation Accuracy: 0.6868, Loss: 0.4515\n",
      "Epoch   4 Batch  196/269 - Train Accuracy: 0.6907, Validation Accuracy: 0.7006, Loss: 0.4494\n",
      "Epoch   4 Batch  197/269 - Train Accuracy: 0.6971, Validation Accuracy: 0.6978, Loss: 0.4747\n",
      "Epoch   4 Batch  198/269 - Train Accuracy: 0.6893, Validation Accuracy: 0.7138, Loss: 0.4788\n",
      "Epoch   4 Batch  199/269 - Train Accuracy: 0.7026, Validation Accuracy: 0.7094, Loss: 0.4537\n",
      "Epoch   4 Batch  200/269 - Train Accuracy: 0.6968, Validation Accuracy: 0.7048, Loss: 0.4603\n",
      "Epoch   4 Batch  201/269 - Train Accuracy: 0.7125, Validation Accuracy: 0.6999, Loss: 0.4461\n",
      "Epoch   4 Batch  202/269 - Train Accuracy: 0.6980, Validation Accuracy: 0.7002, Loss: 0.4428\n",
      "Epoch   4 Batch  203/269 - Train Accuracy: 0.6946, Validation Accuracy: 0.6995, Loss: 0.4720\n",
      "Epoch   4 Batch  204/269 - Train Accuracy: 0.6953, Validation Accuracy: 0.7061, Loss: 0.4670\n",
      "Epoch   4 Batch  205/269 - Train Accuracy: 0.7294, Validation Accuracy: 0.6998, Loss: 0.4412\n",
      "Epoch   4 Batch  206/269 - Train Accuracy: 0.6806, Validation Accuracy: 0.6959, Loss: 0.4736\n",
      "Epoch   4 Batch  207/269 - Train Accuracy: 0.7117, Validation Accuracy: 0.6944, Loss: 0.4378\n",
      "Epoch   4 Batch  208/269 - Train Accuracy: 0.7027, Validation Accuracy: 0.7047, Loss: 0.4638\n",
      "Epoch   4 Batch  209/269 - Train Accuracy: 0.7079, Validation Accuracy: 0.6950, Loss: 0.4504\n",
      "Epoch   4 Batch  210/269 - Train Accuracy: 0.6925, Validation Accuracy: 0.6925, Loss: 0.4326\n",
      "Epoch   4 Batch  211/269 - Train Accuracy: 0.7056, Validation Accuracy: 0.7031, Loss: 0.4519\n",
      "Epoch   4 Batch  212/269 - Train Accuracy: 0.7045, Validation Accuracy: 0.6977, Loss: 0.4389\n",
      "Epoch   4 Batch  213/269 - Train Accuracy: 0.6961, Validation Accuracy: 0.6911, Loss: 0.4399\n",
      "Epoch   4 Batch  214/269 - Train Accuracy: 0.7209, Validation Accuracy: 0.7022, Loss: 0.4504\n",
      "Epoch   4 Batch  215/269 - Train Accuracy: 0.7345, Validation Accuracy: 0.7088, Loss: 0.4225\n",
      "Epoch   4 Batch  216/269 - Train Accuracy: 0.6781, Validation Accuracy: 0.6979, Loss: 0.4748\n",
      "Epoch   4 Batch  217/269 - Train Accuracy: 0.6735, Validation Accuracy: 0.6990, Loss: 0.4623\n",
      "Epoch   4 Batch  218/269 - Train Accuracy: 0.7079, Validation Accuracy: 0.6958, Loss: 0.4611\n",
      "Epoch   4 Batch  219/269 - Train Accuracy: 0.7092, Validation Accuracy: 0.6966, Loss: 0.4587\n",
      "Epoch   4 Batch  220/269 - Train Accuracy: 0.7172, Validation Accuracy: 0.7035, Loss: 0.4260\n",
      "Epoch   4 Batch  221/269 - Train Accuracy: 0.7384, Validation Accuracy: 0.6980, Loss: 0.4366\n",
      "Epoch   4 Batch  222/269 - Train Accuracy: 0.7331, Validation Accuracy: 0.6871, Loss: 0.4270\n",
      "Epoch   4 Batch  223/269 - Train Accuracy: 0.7123, Validation Accuracy: 0.6974, Loss: 0.4320\n",
      "Epoch   4 Batch  224/269 - Train Accuracy: 0.7247, Validation Accuracy: 0.7082, Loss: 0.4533\n",
      "Epoch   4 Batch  225/269 - Train Accuracy: 0.7035, Validation Accuracy: 0.6947, Loss: 0.4466\n",
      "Epoch   4 Batch  226/269 - Train Accuracy: 0.7228, Validation Accuracy: 0.7091, Loss: 0.4438\n",
      "Epoch   4 Batch  227/269 - Train Accuracy: 0.7597, Validation Accuracy: 0.7155, Loss: 0.3943\n",
      "Epoch   4 Batch  228/269 - Train Accuracy: 0.7004, Validation Accuracy: 0.6971, Loss: 0.4414\n",
      "Epoch   4 Batch  229/269 - Train Accuracy: 0.7064, Validation Accuracy: 0.6922, Loss: 0.4327\n",
      "Epoch   4 Batch  230/269 - Train Accuracy: 0.7173, Validation Accuracy: 0.6999, Loss: 0.4385\n",
      "Epoch   4 Batch  231/269 - Train Accuracy: 0.7116, Validation Accuracy: 0.7165, Loss: 0.4570\n",
      "Epoch   4 Batch  232/269 - Train Accuracy: 0.7027, Validation Accuracy: 0.7081, Loss: 0.4487\n",
      "Epoch   4 Batch  233/269 - Train Accuracy: 0.7309, Validation Accuracy: 0.7120, Loss: 0.4523\n",
      "Epoch   4 Batch  234/269 - Train Accuracy: 0.7256, Validation Accuracy: 0.7032, Loss: 0.4293\n",
      "Epoch   4 Batch  235/269 - Train Accuracy: 0.7102, Validation Accuracy: 0.6923, Loss: 0.4333\n",
      "Epoch   4 Batch  236/269 - Train Accuracy: 0.7367, Validation Accuracy: 0.7088, Loss: 0.4284\n",
      "Epoch   4 Batch  237/269 - Train Accuracy: 0.7135, Validation Accuracy: 0.7169, Loss: 0.4336\n",
      "Epoch   4 Batch  238/269 - Train Accuracy: 0.7214, Validation Accuracy: 0.7054, Loss: 0.4279\n",
      "Epoch   4 Batch  239/269 - Train Accuracy: 0.7031, Validation Accuracy: 0.6988, Loss: 0.4273\n",
      "Epoch   4 Batch  240/269 - Train Accuracy: 0.7492, Validation Accuracy: 0.7069, Loss: 0.4011\n",
      "Epoch   4 Batch  241/269 - Train Accuracy: 0.7258, Validation Accuracy: 0.7118, Loss: 0.4403\n",
      "Epoch   4 Batch  242/269 - Train Accuracy: 0.7172, Validation Accuracy: 0.7027, Loss: 0.4370\n",
      "Epoch   4 Batch  243/269 - Train Accuracy: 0.7161, Validation Accuracy: 0.7064, Loss: 0.4311\n",
      "Epoch   4 Batch  244/269 - Train Accuracy: 0.6991, Validation Accuracy: 0.7059, Loss: 0.4324\n",
      "Epoch   4 Batch  245/269 - Train Accuracy: 0.6961, Validation Accuracy: 0.7078, Loss: 0.4715\n",
      "Epoch   4 Batch  246/269 - Train Accuracy: 0.7023, Validation Accuracy: 0.7012, Loss: 0.4520\n",
      "Epoch   4 Batch  247/269 - Train Accuracy: 0.6861, Validation Accuracy: 0.7001, Loss: 0.4519\n",
      "Epoch   4 Batch  248/269 - Train Accuracy: 0.7165, Validation Accuracy: 0.7148, Loss: 0.4441\n",
      "Epoch   4 Batch  249/269 - Train Accuracy: 0.7414, Validation Accuracy: 0.7116, Loss: 0.4199\n",
      "Epoch   4 Batch  250/269 - Train Accuracy: 0.6992, Validation Accuracy: 0.6787, Loss: 0.4534\n",
      "Epoch   4 Batch  251/269 - Train Accuracy: 0.7191, Validation Accuracy: 0.7035, Loss: 0.4421\n",
      "Epoch   4 Batch  252/269 - Train Accuracy: 0.7267, Validation Accuracy: 0.7092, Loss: 0.4328\n",
      "Epoch   4 Batch  253/269 - Train Accuracy: 0.7025, Validation Accuracy: 0.7207, Loss: 0.4589\n",
      "Epoch   4 Batch  254/269 - Train Accuracy: 0.7085, Validation Accuracy: 0.6993, Loss: 0.4281\n",
      "Epoch   4 Batch  255/269 - Train Accuracy: 0.7331, Validation Accuracy: 0.7107, Loss: 0.4341\n",
      "Epoch   4 Batch  256/269 - Train Accuracy: 0.6963, Validation Accuracy: 0.7062, Loss: 0.4463\n",
      "Epoch   4 Batch  257/269 - Train Accuracy: 0.7055, Validation Accuracy: 0.7081, Loss: 0.4535\n",
      "Epoch   4 Batch  258/269 - Train Accuracy: 0.7133, Validation Accuracy: 0.6965, Loss: 0.4438\n",
      "Epoch   4 Batch  259/269 - Train Accuracy: 0.7281, Validation Accuracy: 0.6982, Loss: 0.4423\n",
      "Epoch   4 Batch  260/269 - Train Accuracy: 0.7044, Validation Accuracy: 0.7159, Loss: 0.4577\n",
      "Epoch   4 Batch  261/269 - Train Accuracy: 0.6809, Validation Accuracy: 0.7059, Loss: 0.4607\n",
      "Epoch   4 Batch  262/269 - Train Accuracy: 0.7294, Validation Accuracy: 0.7003, Loss: 0.4330\n",
      "Epoch   4 Batch  263/269 - Train Accuracy: 0.7131, Validation Accuracy: 0.6928, Loss: 0.4509\n",
      "Epoch   4 Batch  264/269 - Train Accuracy: 0.6932, Validation Accuracy: 0.6998, Loss: 0.4551\n",
      "Epoch   4 Batch  265/269 - Train Accuracy: 0.7154, Validation Accuracy: 0.7085, Loss: 0.4439\n",
      "Epoch   4 Batch  266/269 - Train Accuracy: 0.7188, Validation Accuracy: 0.7063, Loss: 0.4163\n",
      "Epoch   4 Batch  267/269 - Train Accuracy: 0.7021, Validation Accuracy: 0.7108, Loss: 0.4413\n",
      "Epoch   5 Batch    1/269 - Train Accuracy: 0.7053, Validation Accuracy: 0.7068, Loss: 0.4459\n",
      "Epoch   5 Batch    2/269 - Train Accuracy: 0.7088, Validation Accuracy: 0.7163, Loss: 0.4333\n",
      "Epoch   5 Batch    3/269 - Train Accuracy: 0.7162, Validation Accuracy: 0.7175, Loss: 0.4448\n",
      "Epoch   5 Batch    4/269 - Train Accuracy: 0.6986, Validation Accuracy: 0.7064, Loss: 0.4426\n",
      "Epoch   5 Batch    5/269 - Train Accuracy: 0.6943, Validation Accuracy: 0.7055, Loss: 0.4444\n",
      "Epoch   5 Batch    6/269 - Train Accuracy: 0.7412, Validation Accuracy: 0.7153, Loss: 0.4104\n",
      "Epoch   5 Batch    7/269 - Train Accuracy: 0.7374, Validation Accuracy: 0.7167, Loss: 0.4093\n",
      "Epoch   5 Batch    8/269 - Train Accuracy: 0.7188, Validation Accuracy: 0.7245, Loss: 0.4466\n",
      "Epoch   5 Batch    9/269 - Train Accuracy: 0.7239, Validation Accuracy: 0.7164, Loss: 0.4339\n",
      "Epoch   5 Batch   10/269 - Train Accuracy: 0.7183, Validation Accuracy: 0.7216, Loss: 0.4312\n",
      "Epoch   5 Batch   11/269 - Train Accuracy: 0.7318, Validation Accuracy: 0.7244, Loss: 0.4313\n",
      "Epoch   5 Batch   12/269 - Train Accuracy: 0.7112, Validation Accuracy: 0.7190, Loss: 0.4415\n",
      "Epoch   5 Batch   13/269 - Train Accuracy: 0.7314, Validation Accuracy: 0.7278, Loss: 0.3982\n",
      "Epoch   5 Batch   14/269 - Train Accuracy: 0.7257, Validation Accuracy: 0.7238, Loss: 0.4181\n",
      "Epoch   5 Batch   15/269 - Train Accuracy: 0.7199, Validation Accuracy: 0.7262, Loss: 0.4098\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch   5 Batch   16/269 - Train Accuracy: 0.7378, Validation Accuracy: 0.7264, Loss: 0.4235\n",
      "Epoch   5 Batch   17/269 - Train Accuracy: 0.7407, Validation Accuracy: 0.7212, Loss: 0.4098\n",
      "Epoch   5 Batch   18/269 - Train Accuracy: 0.7101, Validation Accuracy: 0.7232, Loss: 0.4316\n",
      "Epoch   5 Batch   19/269 - Train Accuracy: 0.7473, Validation Accuracy: 0.7336, Loss: 0.3958\n",
      "Epoch   5 Batch   20/269 - Train Accuracy: 0.7336, Validation Accuracy: 0.7317, Loss: 0.4271\n",
      "Epoch   5 Batch   21/269 - Train Accuracy: 0.6995, Validation Accuracy: 0.7199, Loss: 0.4444\n",
      "Epoch   5 Batch   22/269 - Train Accuracy: 0.7334, Validation Accuracy: 0.7250, Loss: 0.4103\n",
      "Epoch   5 Batch   23/269 - Train Accuracy: 0.7297, Validation Accuracy: 0.7320, Loss: 0.4131\n",
      "Epoch   5 Batch   24/269 - Train Accuracy: 0.7271, Validation Accuracy: 0.7256, Loss: 0.4307\n",
      "Epoch   5 Batch   25/269 - Train Accuracy: 0.7205, Validation Accuracy: 0.7217, Loss: 0.4396\n",
      "Epoch   5 Batch   26/269 - Train Accuracy: 0.7418, Validation Accuracy: 0.7242, Loss: 0.3873\n",
      "Epoch   5 Batch   27/269 - Train Accuracy: 0.7211, Validation Accuracy: 0.7324, Loss: 0.4065\n",
      "Epoch   5 Batch   28/269 - Train Accuracy: 0.6830, Validation Accuracy: 0.7235, Loss: 0.4487\n",
      "Epoch   5 Batch   29/269 - Train Accuracy: 0.7128, Validation Accuracy: 0.7188, Loss: 0.4335\n",
      "Epoch   5 Batch   30/269 - Train Accuracy: 0.7331, Validation Accuracy: 0.7134, Loss: 0.4129\n",
      "Epoch   5 Batch   31/269 - Train Accuracy: 0.7414, Validation Accuracy: 0.7376, Loss: 0.4075\n",
      "Epoch   5 Batch   32/269 - Train Accuracy: 0.7307, Validation Accuracy: 0.7219, Loss: 0.4161\n",
      "Epoch   5 Batch   33/269 - Train Accuracy: 0.7307, Validation Accuracy: 0.7219, Loss: 0.4028\n",
      "Epoch   5 Batch   34/269 - Train Accuracy: 0.7330, Validation Accuracy: 0.7294, Loss: 0.4202\n",
      "Epoch   5 Batch   35/269 - Train Accuracy: 0.7315, Validation Accuracy: 0.7347, Loss: 0.4229\n",
      "Epoch   5 Batch   36/269 - Train Accuracy: 0.7254, Validation Accuracy: 0.7251, Loss: 0.4170\n",
      "Epoch   5 Batch   37/269 - Train Accuracy: 0.7244, Validation Accuracy: 0.7228, Loss: 0.4090\n",
      "Epoch   5 Batch   38/269 - Train Accuracy: 0.7465, Validation Accuracy: 0.7322, Loss: 0.4227\n",
      "Epoch   5 Batch   39/269 - Train Accuracy: 0.7232, Validation Accuracy: 0.7344, Loss: 0.4097\n",
      "Epoch   5 Batch   40/269 - Train Accuracy: 0.7222, Validation Accuracy: 0.7274, Loss: 0.4301\n",
      "Epoch   5 Batch   41/269 - Train Accuracy: 0.7113, Validation Accuracy: 0.7249, Loss: 0.4246\n",
      "Epoch   5 Batch   42/269 - Train Accuracy: 0.7454, Validation Accuracy: 0.7216, Loss: 0.3898\n",
      "Epoch   5 Batch   43/269 - Train Accuracy: 0.7320, Validation Accuracy: 0.7304, Loss: 0.4279\n",
      "Epoch   5 Batch   44/269 - Train Accuracy: 0.7347, Validation Accuracy: 0.7309, Loss: 0.4112\n",
      "Epoch   5 Batch   45/269 - Train Accuracy: 0.7270, Validation Accuracy: 0.7390, Loss: 0.4216\n",
      "Epoch   5 Batch   46/269 - Train Accuracy: 0.7226, Validation Accuracy: 0.7227, Loss: 0.4233\n",
      "Epoch   5 Batch   47/269 - Train Accuracy: 0.7480, Validation Accuracy: 0.7308, Loss: 0.3888\n",
      "Epoch   5 Batch   48/269 - Train Accuracy: 0.7548, Validation Accuracy: 0.7335, Loss: 0.3995\n",
      "Epoch   5 Batch   49/269 - Train Accuracy: 0.7245, Validation Accuracy: 0.7326, Loss: 0.4091\n",
      "Epoch   5 Batch   50/269 - Train Accuracy: 0.7136, Validation Accuracy: 0.7305, Loss: 0.4297\n",
      "Epoch   5 Batch   51/269 - Train Accuracy: 0.7363, Validation Accuracy: 0.7314, Loss: 0.4073\n",
      "Epoch   5 Batch   52/269 - Train Accuracy: 0.7284, Validation Accuracy: 0.7403, Loss: 0.3868\n",
      "Epoch   5 Batch   53/269 - Train Accuracy: 0.7366, Validation Accuracy: 0.7335, Loss: 0.4242\n",
      "Epoch   5 Batch   54/269 - Train Accuracy: 0.7352, Validation Accuracy: 0.7294, Loss: 0.4202\n",
      "Epoch   5 Batch   55/269 - Train Accuracy: 0.7427, Validation Accuracy: 0.7297, Loss: 0.3908\n",
      "Epoch   5 Batch   56/269 - Train Accuracy: 0.7314, Validation Accuracy: 0.7296, Loss: 0.4069\n",
      "Epoch   5 Batch   57/269 - Train Accuracy: 0.7407, Validation Accuracy: 0.7421, Loss: 0.4120\n",
      "Epoch   5 Batch   58/269 - Train Accuracy: 0.7520, Validation Accuracy: 0.7338, Loss: 0.3991\n",
      "Epoch   5 Batch   59/269 - Train Accuracy: 0.7586, Validation Accuracy: 0.7354, Loss: 0.3844\n",
      "Epoch   5 Batch   60/269 - Train Accuracy: 0.7342, Validation Accuracy: 0.7342, Loss: 0.3846\n",
      "Epoch   5 Batch   61/269 - Train Accuracy: 0.7665, Validation Accuracy: 0.7355, Loss: 0.3735\n",
      "Epoch   5 Batch   62/269 - Train Accuracy: 0.7583, Validation Accuracy: 0.7403, Loss: 0.3879\n",
      "Epoch   5 Batch   63/269 - Train Accuracy: 0.7440, Validation Accuracy: 0.7406, Loss: 0.4150\n",
      "Epoch   5 Batch   64/269 - Train Accuracy: 0.7623, Validation Accuracy: 0.7335, Loss: 0.3933\n",
      "Epoch   5 Batch   65/269 - Train Accuracy: 0.7220, Validation Accuracy: 0.7315, Loss: 0.4002\n",
      "Epoch   5 Batch   66/269 - Train Accuracy: 0.7406, Validation Accuracy: 0.7344, Loss: 0.3971\n",
      "Epoch   5 Batch   67/269 - Train Accuracy: 0.7463, Validation Accuracy: 0.7282, Loss: 0.4061\n",
      "Epoch   5 Batch   68/269 - Train Accuracy: 0.7147, Validation Accuracy: 0.7294, Loss: 0.4143\n",
      "Epoch   5 Batch   69/269 - Train Accuracy: 0.7014, Validation Accuracy: 0.7351, Loss: 0.4396\n",
      "Epoch   5 Batch   70/269 - Train Accuracy: 0.7651, Validation Accuracy: 0.7441, Loss: 0.3990\n",
      "Epoch   5 Batch   71/269 - Train Accuracy: 0.7310, Validation Accuracy: 0.7428, Loss: 0.4214\n",
      "Epoch   5 Batch   72/269 - Train Accuracy: 0.7395, Validation Accuracy: 0.7378, Loss: 0.4016\n",
      "Epoch   5 Batch   73/269 - Train Accuracy: 0.7244, Validation Accuracy: 0.7374, Loss: 0.4147\n",
      "Epoch   5 Batch   74/269 - Train Accuracy: 0.7515, Validation Accuracy: 0.7381, Loss: 0.4017\n",
      "Epoch   5 Batch   75/269 - Train Accuracy: 0.7490, Validation Accuracy: 0.7410, Loss: 0.3888\n",
      "Epoch   5 Batch   76/269 - Train Accuracy: 0.7185, Validation Accuracy: 0.7370, Loss: 0.3973\n",
      "Epoch   5 Batch   77/269 - Train Accuracy: 0.7495, Validation Accuracy: 0.7369, Loss: 0.3934\n",
      "Epoch   5 Batch   78/269 - Train Accuracy: 0.7700, Validation Accuracy: 0.7383, Loss: 0.3924\n",
      "Epoch   5 Batch   79/269 - Train Accuracy: 0.7531, Validation Accuracy: 0.7385, Loss: 0.3914\n",
      "Epoch   5 Batch   80/269 - Train Accuracy: 0.7681, Validation Accuracy: 0.7351, Loss: 0.3893\n",
      "Epoch   5 Batch   81/269 - Train Accuracy: 0.7443, Validation Accuracy: 0.7416, Loss: 0.4091\n",
      "Epoch   5 Batch   82/269 - Train Accuracy: 0.7736, Validation Accuracy: 0.7417, Loss: 0.3765\n",
      "Epoch   5 Batch   83/269 - Train Accuracy: 0.7461, Validation Accuracy: 0.7410, Loss: 0.4043\n",
      "Epoch   5 Batch   84/269 - Train Accuracy: 0.7558, Validation Accuracy: 0.7445, Loss: 0.3918\n",
      "Epoch   5 Batch   85/269 - Train Accuracy: 0.7540, Validation Accuracy: 0.7472, Loss: 0.4016\n",
      "Epoch   5 Batch   86/269 - Train Accuracy: 0.7559, Validation Accuracy: 0.7365, Loss: 0.3870\n",
      "Epoch   5 Batch   87/269 - Train Accuracy: 0.7246, Validation Accuracy: 0.7341, Loss: 0.4225\n",
      "Epoch   5 Batch   88/269 - Train Accuracy: 0.7416, Validation Accuracy: 0.7387, Loss: 0.4006\n",
      "Epoch   5 Batch   89/269 - Train Accuracy: 0.7569, Validation Accuracy: 0.7418, Loss: 0.3910\n",
      "Epoch   5 Batch   90/269 - Train Accuracy: 0.7191, Validation Accuracy: 0.7395, Loss: 0.4135\n",
      "Epoch   5 Batch   91/269 - Train Accuracy: 0.7520, Validation Accuracy: 0.7396, Loss: 0.3863\n",
      "Epoch   5 Batch   92/269 - Train Accuracy: 0.7526, Validation Accuracy: 0.7443, Loss: 0.3853\n",
      "Epoch   5 Batch   93/269 - Train Accuracy: 0.7586, Validation Accuracy: 0.7415, Loss: 0.3785\n",
      "Epoch   5 Batch   94/269 - Train Accuracy: 0.7473, Validation Accuracy: 0.7493, Loss: 0.4110\n",
      "Epoch   5 Batch   95/269 - Train Accuracy: 0.7476, Validation Accuracy: 0.7492, Loss: 0.3862\n",
      "Epoch   5 Batch   96/269 - Train Accuracy: 0.7580, Validation Accuracy: 0.7552, Loss: 0.3954\n",
      "Epoch   5 Batch   97/269 - Train Accuracy: 0.7649, Validation Accuracy: 0.7607, Loss: 0.3902\n",
      "Epoch   5 Batch   98/269 - Train Accuracy: 0.7715, Validation Accuracy: 0.7572, Loss: 0.3948\n",
      "Epoch   5 Batch   99/269 - Train Accuracy: 0.7370, Validation Accuracy: 0.7520, Loss: 0.4043\n",
      "Epoch   5 Batch  100/269 - Train Accuracy: 0.7588, Validation Accuracy: 0.7474, Loss: 0.3827\n",
      "Epoch   5 Batch  101/269 - Train Accuracy: 0.7397, Validation Accuracy: 0.7531, Loss: 0.4237\n",
      "Epoch   5 Batch  102/269 - Train Accuracy: 0.7540, Validation Accuracy: 0.7503, Loss: 0.3858\n",
      "Epoch   5 Batch  103/269 - Train Accuracy: 0.7782, Validation Accuracy: 0.7512, Loss: 0.3945\n",
      "Epoch   5 Batch  104/269 - Train Accuracy: 0.7491, Validation Accuracy: 0.7480, Loss: 0.3815\n",
      "Epoch   5 Batch  105/269 - Train Accuracy: 0.7442, Validation Accuracy: 0.7469, Loss: 0.3871\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch   5 Batch  106/269 - Train Accuracy: 0.7519, Validation Accuracy: 0.7546, Loss: 0.3869\n",
      "Epoch   5 Batch  107/269 - Train Accuracy: 0.7424, Validation Accuracy: 0.7538, Loss: 0.4028\n",
      "Epoch   5 Batch  108/269 - Train Accuracy: 0.7588, Validation Accuracy: 0.7451, Loss: 0.3875\n",
      "Epoch   5 Batch  109/269 - Train Accuracy: 0.7356, Validation Accuracy: 0.7436, Loss: 0.3918\n",
      "Epoch   5 Batch  110/269 - Train Accuracy: 0.7519, Validation Accuracy: 0.7472, Loss: 0.3883\n",
      "Epoch   5 Batch  111/269 - Train Accuracy: 0.7348, Validation Accuracy: 0.7506, Loss: 0.4129\n",
      "Epoch   5 Batch  112/269 - Train Accuracy: 0.7701, Validation Accuracy: 0.7531, Loss: 0.3853\n",
      "Epoch   5 Batch  113/269 - Train Accuracy: 0.7428, Validation Accuracy: 0.7532, Loss: 0.3769\n",
      "Epoch   5 Batch  114/269 - Train Accuracy: 0.7533, Validation Accuracy: 0.7449, Loss: 0.3849\n",
      "Epoch   5 Batch  115/269 - Train Accuracy: 0.7377, Validation Accuracy: 0.7471, Loss: 0.3988\n",
      "Epoch   5 Batch  116/269 - Train Accuracy: 0.7680, Validation Accuracy: 0.7414, Loss: 0.3979\n",
      "Epoch   5 Batch  117/269 - Train Accuracy: 0.7615, Validation Accuracy: 0.7531, Loss: 0.3831\n",
      "Epoch   5 Batch  118/269 - Train Accuracy: 0.7749, Validation Accuracy: 0.7510, Loss: 0.3649\n",
      "Epoch   5 Batch  119/269 - Train Accuracy: 0.7432, Validation Accuracy: 0.7546, Loss: 0.4095\n",
      "Epoch   5 Batch  120/269 - Train Accuracy: 0.7613, Validation Accuracy: 0.7575, Loss: 0.3993\n",
      "Epoch   5 Batch  121/269 - Train Accuracy: 0.7612, Validation Accuracy: 0.7511, Loss: 0.3775\n",
      "Epoch   5 Batch  122/269 - Train Accuracy: 0.7578, Validation Accuracy: 0.7528, Loss: 0.3730\n",
      "Epoch   5 Batch  123/269 - Train Accuracy: 0.7574, Validation Accuracy: 0.7619, Loss: 0.4009\n",
      "Epoch   5 Batch  124/269 - Train Accuracy: 0.7600, Validation Accuracy: 0.7634, Loss: 0.3706\n",
      "Epoch   5 Batch  125/269 - Train Accuracy: 0.7767, Validation Accuracy: 0.7559, Loss: 0.3782\n",
      "Epoch   5 Batch  126/269 - Train Accuracy: 0.7561, Validation Accuracy: 0.7501, Loss: 0.3795\n",
      "Epoch   5 Batch  127/269 - Train Accuracy: 0.7454, Validation Accuracy: 0.7603, Loss: 0.3964\n",
      "Epoch   5 Batch  128/269 - Train Accuracy: 0.7633, Validation Accuracy: 0.7579, Loss: 0.3824\n",
      "Epoch   5 Batch  129/269 - Train Accuracy: 0.7649, Validation Accuracy: 0.7493, Loss: 0.3770\n",
      "Epoch   5 Batch  130/269 - Train Accuracy: 0.7606, Validation Accuracy: 0.7500, Loss: 0.3997\n",
      "Epoch   5 Batch  131/269 - Train Accuracy: 0.7636, Validation Accuracy: 0.7631, Loss: 0.3935\n",
      "Epoch   5 Batch  132/269 - Train Accuracy: 0.7593, Validation Accuracy: 0.7540, Loss: 0.3873\n",
      "Epoch   5 Batch  133/269 - Train Accuracy: 0.7626, Validation Accuracy: 0.7473, Loss: 0.3670\n",
      "Epoch   5 Batch  134/269 - Train Accuracy: 0.7528, Validation Accuracy: 0.7639, Loss: 0.3964\n",
      "Epoch   5 Batch  135/269 - Train Accuracy: 0.7472, Validation Accuracy: 0.7700, Loss: 0.4053\n",
      "Epoch   5 Batch  136/269 - Train Accuracy: 0.7370, Validation Accuracy: 0.7533, Loss: 0.4060\n",
      "Epoch   5 Batch  137/269 - Train Accuracy: 0.7297, Validation Accuracy: 0.7505, Loss: 0.4070\n",
      "Epoch   5 Batch  138/269 - Train Accuracy: 0.7707, Validation Accuracy: 0.7592, Loss: 0.3904\n",
      "Epoch   5 Batch  139/269 - Train Accuracy: 0.7624, Validation Accuracy: 0.7592, Loss: 0.3687\n",
      "Epoch   5 Batch  140/269 - Train Accuracy: 0.7732, Validation Accuracy: 0.7607, Loss: 0.3936\n",
      "Epoch   5 Batch  141/269 - Train Accuracy: 0.7661, Validation Accuracy: 0.7522, Loss: 0.3914\n",
      "Epoch   5 Batch  142/269 - Train Accuracy: 0.7599, Validation Accuracy: 0.7589, Loss: 0.3757\n",
      "Epoch   5 Batch  143/269 - Train Accuracy: 0.7675, Validation Accuracy: 0.7646, Loss: 0.3746\n",
      "Epoch   5 Batch  144/269 - Train Accuracy: 0.7734, Validation Accuracy: 0.7569, Loss: 0.3621\n",
      "Epoch   5 Batch  145/269 - Train Accuracy: 0.7561, Validation Accuracy: 0.7531, Loss: 0.3757\n",
      "Epoch   5 Batch  146/269 - Train Accuracy: 0.7629, Validation Accuracy: 0.7596, Loss: 0.3739\n",
      "Epoch   5 Batch  147/269 - Train Accuracy: 0.7699, Validation Accuracy: 0.7625, Loss: 0.3612\n",
      "Epoch   5 Batch  148/269 - Train Accuracy: 0.7573, Validation Accuracy: 0.7615, Loss: 0.3863\n",
      "Epoch   5 Batch  149/269 - Train Accuracy: 0.7535, Validation Accuracy: 0.7585, Loss: 0.3861\n",
      "Epoch   5 Batch  150/269 - Train Accuracy: 0.7454, Validation Accuracy: 0.7552, Loss: 0.3785\n",
      "Epoch   5 Batch  151/269 - Train Accuracy: 0.7626, Validation Accuracy: 0.7556, Loss: 0.3638\n",
      "Epoch   5 Batch  152/269 - Train Accuracy: 0.7664, Validation Accuracy: 0.7574, Loss: 0.3767\n",
      "Epoch   5 Batch  153/269 - Train Accuracy: 0.7687, Validation Accuracy: 0.7550, Loss: 0.3731\n",
      "Epoch   5 Batch  154/269 - Train Accuracy: 0.7539, Validation Accuracy: 0.7575, Loss: 0.3848\n",
      "Epoch   5 Batch  155/269 - Train Accuracy: 0.7789, Validation Accuracy: 0.7579, Loss: 0.3596\n",
      "Epoch   5 Batch  156/269 - Train Accuracy: 0.7366, Validation Accuracy: 0.7625, Loss: 0.3838\n",
      "Epoch   5 Batch  157/269 - Train Accuracy: 0.7662, Validation Accuracy: 0.7676, Loss: 0.3725\n",
      "Epoch   5 Batch  158/269 - Train Accuracy: 0.7656, Validation Accuracy: 0.7707, Loss: 0.3720\n",
      "Epoch   5 Batch  159/269 - Train Accuracy: 0.7461, Validation Accuracy: 0.7671, Loss: 0.3765\n",
      "Epoch   5 Batch  160/269 - Train Accuracy: 0.7719, Validation Accuracy: 0.7708, Loss: 0.3759\n",
      "Epoch   5 Batch  161/269 - Train Accuracy: 0.7725, Validation Accuracy: 0.7682, Loss: 0.3705\n",
      "Epoch   5 Batch  162/269 - Train Accuracy: 0.7857, Validation Accuracy: 0.7613, Loss: 0.3651\n",
      "Epoch   5 Batch  163/269 - Train Accuracy: 0.7840, Validation Accuracy: 0.7712, Loss: 0.3770\n",
      "Epoch   5 Batch  164/269 - Train Accuracy: 0.7853, Validation Accuracy: 0.7654, Loss: 0.3582\n",
      "Epoch   5 Batch  165/269 - Train Accuracy: 0.7825, Validation Accuracy: 0.7652, Loss: 0.3777\n",
      "Epoch   5 Batch  166/269 - Train Accuracy: 0.7757, Validation Accuracy: 0.7633, Loss: 0.3490\n",
      "Epoch   5 Batch  167/269 - Train Accuracy: 0.7696, Validation Accuracy: 0.7672, Loss: 0.3660\n",
      "Epoch   5 Batch  168/269 - Train Accuracy: 0.7697, Validation Accuracy: 0.7683, Loss: 0.3658\n",
      "Epoch   5 Batch  169/269 - Train Accuracy: 0.7818, Validation Accuracy: 0.7698, Loss: 0.3668\n",
      "Epoch   5 Batch  170/269 - Train Accuracy: 0.7790, Validation Accuracy: 0.7682, Loss: 0.3652\n",
      "Epoch   5 Batch  171/269 - Train Accuracy: 0.7805, Validation Accuracy: 0.7657, Loss: 0.3718\n",
      "Epoch   5 Batch  172/269 - Train Accuracy: 0.7644, Validation Accuracy: 0.7580, Loss: 0.3720\n",
      "Epoch   5 Batch  173/269 - Train Accuracy: 0.7841, Validation Accuracy: 0.7624, Loss: 0.3555\n",
      "Epoch   5 Batch  174/269 - Train Accuracy: 0.7884, Validation Accuracy: 0.7690, Loss: 0.3661\n",
      "Epoch   5 Batch  175/269 - Train Accuracy: 0.7733, Validation Accuracy: 0.7693, Loss: 0.3828\n",
      "Epoch   5 Batch  176/269 - Train Accuracy: 0.7613, Validation Accuracy: 0.7715, Loss: 0.3963\n",
      "Epoch   5 Batch  177/269 - Train Accuracy: 0.7876, Validation Accuracy: 0.7715, Loss: 0.3487\n",
      "Epoch   5 Batch  178/269 - Train Accuracy: 0.7788, Validation Accuracy: 0.7665, Loss: 0.3660\n",
      "Epoch   5 Batch  179/269 - Train Accuracy: 0.7578, Validation Accuracy: 0.7597, Loss: 0.3670\n",
      "Epoch   5 Batch  180/269 - Train Accuracy: 0.7800, Validation Accuracy: 0.7671, Loss: 0.3536\n",
      "Epoch   5 Batch  181/269 - Train Accuracy: 0.7683, Validation Accuracy: 0.7682, Loss: 0.3675\n",
      "Epoch   5 Batch  182/269 - Train Accuracy: 0.7858, Validation Accuracy: 0.7649, Loss: 0.3673\n",
      "Epoch   5 Batch  183/269 - Train Accuracy: 0.8112, Validation Accuracy: 0.7666, Loss: 0.3183\n",
      "Epoch   5 Batch  184/269 - Train Accuracy: 0.7721, Validation Accuracy: 0.7566, Loss: 0.3777\n",
      "Epoch   5 Batch  185/269 - Train Accuracy: 0.7962, Validation Accuracy: 0.7692, Loss: 0.3609\n",
      "Epoch   5 Batch  186/269 - Train Accuracy: 0.7773, Validation Accuracy: 0.7706, Loss: 0.3610\n",
      "Epoch   5 Batch  187/269 - Train Accuracy: 0.7810, Validation Accuracy: 0.7630, Loss: 0.3467\n",
      "Epoch   5 Batch  188/269 - Train Accuracy: 0.7780, Validation Accuracy: 0.7693, Loss: 0.3473\n",
      "Epoch   5 Batch  189/269 - Train Accuracy: 0.7843, Validation Accuracy: 0.7698, Loss: 0.3434\n",
      "Epoch   5 Batch  190/269 - Train Accuracy: 0.7781, Validation Accuracy: 0.7706, Loss: 0.3478\n",
      "Epoch   5 Batch  191/269 - Train Accuracy: 0.7827, Validation Accuracy: 0.7723, Loss: 0.3507\n",
      "Epoch   5 Batch  192/269 - Train Accuracy: 0.7933, Validation Accuracy: 0.7710, Loss: 0.3631\n",
      "Epoch   5 Batch  193/269 - Train Accuracy: 0.8116, Validation Accuracy: 0.7762, Loss: 0.3558\n",
      "Epoch   5 Batch  194/269 - Train Accuracy: 0.7780, Validation Accuracy: 0.7681, Loss: 0.3669\n",
      "Epoch   5 Batch  195/269 - Train Accuracy: 0.7780, Validation Accuracy: 0.7718, Loss: 0.3609\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch   5 Batch  196/269 - Train Accuracy: 0.7646, Validation Accuracy: 0.7725, Loss: 0.3540\n",
      "Epoch   5 Batch  197/269 - Train Accuracy: 0.7755, Validation Accuracy: 0.7654, Loss: 0.3727\n",
      "Epoch   5 Batch  198/269 - Train Accuracy: 0.7662, Validation Accuracy: 0.7646, Loss: 0.3856\n",
      "Epoch   5 Batch  199/269 - Train Accuracy: 0.7688, Validation Accuracy: 0.7671, Loss: 0.3757\n",
      "Epoch   5 Batch  200/269 - Train Accuracy: 0.7782, Validation Accuracy: 0.7712, Loss: 0.3685\n",
      "Epoch   5 Batch  201/269 - Train Accuracy: 0.7826, Validation Accuracy: 0.7686, Loss: 0.3549\n",
      "Epoch   5 Batch  202/269 - Train Accuracy: 0.7656, Validation Accuracy: 0.7752, Loss: 0.3616\n",
      "Epoch   5 Batch  203/269 - Train Accuracy: 0.7620, Validation Accuracy: 0.7685, Loss: 0.3870\n",
      "Epoch   5 Batch  204/269 - Train Accuracy: 0.7736, Validation Accuracy: 0.7601, Loss: 0.3842\n",
      "Epoch   5 Batch  205/269 - Train Accuracy: 0.7967, Validation Accuracy: 0.7637, Loss: 0.3548\n",
      "Epoch   5 Batch  206/269 - Train Accuracy: 0.7745, Validation Accuracy: 0.7753, Loss: 0.3767\n",
      "Epoch   5 Batch  207/269 - Train Accuracy: 0.7882, Validation Accuracy: 0.7802, Loss: 0.3547\n",
      "Epoch   5 Batch  208/269 - Train Accuracy: 0.7812, Validation Accuracy: 0.7660, Loss: 0.3749\n",
      "Epoch   5 Batch  209/269 - Train Accuracy: 0.8063, Validation Accuracy: 0.7694, Loss: 0.3584\n",
      "Epoch   5 Batch  210/269 - Train Accuracy: 0.7898, Validation Accuracy: 0.7764, Loss: 0.3438\n",
      "Epoch   5 Batch  211/269 - Train Accuracy: 0.7897, Validation Accuracy: 0.7745, Loss: 0.3619\n",
      "Epoch   5 Batch  212/269 - Train Accuracy: 0.7817, Validation Accuracy: 0.7692, Loss: 0.3524\n",
      "Epoch   5 Batch  213/269 - Train Accuracy: 0.7883, Validation Accuracy: 0.7735, Loss: 0.3530\n",
      "Epoch   5 Batch  214/269 - Train Accuracy: 0.7838, Validation Accuracy: 0.7796, Loss: 0.3603\n",
      "Epoch   5 Batch  215/269 - Train Accuracy: 0.7951, Validation Accuracy: 0.7745, Loss: 0.3343\n",
      "Epoch   5 Batch  216/269 - Train Accuracy: 0.7607, Validation Accuracy: 0.7709, Loss: 0.3921\n",
      "Epoch   5 Batch  217/269 - Train Accuracy: 0.7704, Validation Accuracy: 0.7719, Loss: 0.3713\n",
      "Epoch   5 Batch  218/269 - Train Accuracy: 0.7845, Validation Accuracy: 0.7696, Loss: 0.3662\n",
      "Epoch   5 Batch  219/269 - Train Accuracy: 0.7897, Validation Accuracy: 0.7710, Loss: 0.3743\n",
      "Epoch   5 Batch  220/269 - Train Accuracy: 0.7805, Validation Accuracy: 0.7743, Loss: 0.3362\n",
      "Epoch   5 Batch  221/269 - Train Accuracy: 0.8100, Validation Accuracy: 0.7778, Loss: 0.3568\n",
      "Epoch   5 Batch  222/269 - Train Accuracy: 0.8123, Validation Accuracy: 0.7739, Loss: 0.3403\n",
      "Epoch   5 Batch  223/269 - Train Accuracy: 0.7762, Validation Accuracy: 0.7686, Loss: 0.3502\n",
      "Epoch   5 Batch  224/269 - Train Accuracy: 0.7904, Validation Accuracy: 0.7723, Loss: 0.3648\n",
      "Epoch   5 Batch  225/269 - Train Accuracy: 0.7663, Validation Accuracy: 0.7701, Loss: 0.3519\n",
      "Epoch   5 Batch  226/269 - Train Accuracy: 0.7914, Validation Accuracy: 0.7803, Loss: 0.3550\n",
      "Epoch   5 Batch  227/269 - Train Accuracy: 0.8163, Validation Accuracy: 0.7755, Loss: 0.3245\n",
      "Epoch   5 Batch  228/269 - Train Accuracy: 0.7759, Validation Accuracy: 0.7846, Loss: 0.3514\n",
      "Epoch   5 Batch  229/269 - Train Accuracy: 0.7830, Validation Accuracy: 0.7834, Loss: 0.3501\n",
      "Epoch   5 Batch  230/269 - Train Accuracy: 0.7899, Validation Accuracy: 0.7752, Loss: 0.3426\n",
      "Epoch   5 Batch  231/269 - Train Accuracy: 0.7846, Validation Accuracy: 0.7773, Loss: 0.3694\n",
      "Epoch   5 Batch  232/269 - Train Accuracy: 0.7797, Validation Accuracy: 0.7731, Loss: 0.3582\n",
      "Epoch   5 Batch  233/269 - Train Accuracy: 0.8003, Validation Accuracy: 0.7702, Loss: 0.3600\n",
      "Epoch   5 Batch  234/269 - Train Accuracy: 0.7846, Validation Accuracy: 0.7750, Loss: 0.3530\n",
      "Epoch   5 Batch  235/269 - Train Accuracy: 0.7924, Validation Accuracy: 0.7659, Loss: 0.3369\n",
      "Epoch   5 Batch  236/269 - Train Accuracy: 0.7850, Validation Accuracy: 0.7732, Loss: 0.3424\n",
      "Epoch   5 Batch  237/269 - Train Accuracy: 0.7860, Validation Accuracy: 0.7732, Loss: 0.3463\n",
      "Epoch   5 Batch  238/269 - Train Accuracy: 0.7936, Validation Accuracy: 0.7778, Loss: 0.3374\n",
      "Epoch   5 Batch  239/269 - Train Accuracy: 0.7833, Validation Accuracy: 0.7776, Loss: 0.3503\n",
      "Epoch   5 Batch  240/269 - Train Accuracy: 0.8088, Validation Accuracy: 0.7727, Loss: 0.3097\n",
      "Epoch   5 Batch  241/269 - Train Accuracy: 0.7773, Validation Accuracy: 0.7661, Loss: 0.3575\n",
      "Epoch   5 Batch  242/269 - Train Accuracy: 0.8026, Validation Accuracy: 0.7812, Loss: 0.3461\n",
      "Epoch   5 Batch  243/269 - Train Accuracy: 0.7843, Validation Accuracy: 0.7767, Loss: 0.3321\n",
      "Epoch   5 Batch  244/269 - Train Accuracy: 0.8013, Validation Accuracy: 0.7826, Loss: 0.3526\n",
      "Epoch   5 Batch  245/269 - Train Accuracy: 0.7571, Validation Accuracy: 0.7804, Loss: 0.3621\n",
      "Epoch   5 Batch  246/269 - Train Accuracy: 0.7752, Validation Accuracy: 0.7722, Loss: 0.3474\n",
      "Epoch   5 Batch  247/269 - Train Accuracy: 0.7866, Validation Accuracy: 0.7810, Loss: 0.3600\n",
      "Epoch   5 Batch  248/269 - Train Accuracy: 0.7921, Validation Accuracy: 0.7858, Loss: 0.3432\n",
      "Epoch   5 Batch  249/269 - Train Accuracy: 0.8053, Validation Accuracy: 0.7831, Loss: 0.3220\n",
      "Epoch   5 Batch  250/269 - Train Accuracy: 0.7937, Validation Accuracy: 0.7718, Loss: 0.3520\n",
      "Epoch   5 Batch  251/269 - Train Accuracy: 0.8064, Validation Accuracy: 0.7738, Loss: 0.3344\n",
      "Epoch   5 Batch  252/269 - Train Accuracy: 0.7900, Validation Accuracy: 0.7843, Loss: 0.3461\n",
      "Epoch   5 Batch  253/269 - Train Accuracy: 0.7659, Validation Accuracy: 0.7851, Loss: 0.3530\n",
      "Epoch   5 Batch  254/269 - Train Accuracy: 0.7950, Validation Accuracy: 0.7832, Loss: 0.3447\n",
      "Epoch   5 Batch  255/269 - Train Accuracy: 0.7988, Validation Accuracy: 0.7812, Loss: 0.3377\n",
      "Epoch   5 Batch  256/269 - Train Accuracy: 0.7819, Validation Accuracy: 0.7846, Loss: 0.3459\n",
      "Epoch   5 Batch  257/269 - Train Accuracy: 0.7711, Validation Accuracy: 0.7825, Loss: 0.3598\n",
      "Epoch   5 Batch  258/269 - Train Accuracy: 0.7932, Validation Accuracy: 0.7814, Loss: 0.3573\n",
      "Epoch   5 Batch  259/269 - Train Accuracy: 0.7958, Validation Accuracy: 0.7845, Loss: 0.3434\n",
      "Epoch   5 Batch  260/269 - Train Accuracy: 0.7749, Validation Accuracy: 0.7868, Loss: 0.3585\n",
      "Epoch   5 Batch  261/269 - Train Accuracy: 0.7713, Validation Accuracy: 0.7841, Loss: 0.3605\n",
      "Epoch   5 Batch  262/269 - Train Accuracy: 0.7982, Validation Accuracy: 0.7822, Loss: 0.3440\n",
      "Epoch   5 Batch  263/269 - Train Accuracy: 0.7812, Validation Accuracy: 0.7746, Loss: 0.3523\n",
      "Epoch   5 Batch  264/269 - Train Accuracy: 0.7837, Validation Accuracy: 0.7866, Loss: 0.3607\n",
      "Epoch   5 Batch  265/269 - Train Accuracy: 0.8016, Validation Accuracy: 0.7820, Loss: 0.3365\n",
      "Epoch   5 Batch  266/269 - Train Accuracy: 0.8037, Validation Accuracy: 0.7785, Loss: 0.3326\n",
      "Epoch   5 Batch  267/269 - Train Accuracy: 0.7957, Validation Accuracy: 0.7718, Loss: 0.3421\n",
      "Epoch   6 Batch    1/269 - Train Accuracy: 0.8085, Validation Accuracy: 0.7807, Loss: 0.3499\n",
      "Epoch   6 Batch    2/269 - Train Accuracy: 0.7941, Validation Accuracy: 0.7794, Loss: 0.3526\n",
      "Epoch   6 Batch    3/269 - Train Accuracy: 0.7980, Validation Accuracy: 0.7812, Loss: 0.3434\n",
      "Epoch   6 Batch    4/269 - Train Accuracy: 0.7744, Validation Accuracy: 0.7823, Loss: 0.3500\n",
      "Epoch   6 Batch    5/269 - Train Accuracy: 0.7740, Validation Accuracy: 0.7797, Loss: 0.3488\n",
      "Epoch   6 Batch    6/269 - Train Accuracy: 0.8154, Validation Accuracy: 0.7870, Loss: 0.3230\n",
      "Epoch   6 Batch    7/269 - Train Accuracy: 0.8011, Validation Accuracy: 0.7900, Loss: 0.3278\n",
      "Epoch   6 Batch    8/269 - Train Accuracy: 0.7874, Validation Accuracy: 0.7847, Loss: 0.3487\n",
      "Epoch   6 Batch    9/269 - Train Accuracy: 0.7959, Validation Accuracy: 0.7870, Loss: 0.3396\n",
      "Epoch   6 Batch   10/269 - Train Accuracy: 0.8050, Validation Accuracy: 0.7886, Loss: 0.3349\n",
      "Epoch   6 Batch   11/269 - Train Accuracy: 0.8144, Validation Accuracy: 0.7930, Loss: 0.3425\n",
      "Epoch   6 Batch   12/269 - Train Accuracy: 0.7893, Validation Accuracy: 0.7879, Loss: 0.3534\n",
      "Epoch   6 Batch   13/269 - Train Accuracy: 0.7991, Validation Accuracy: 0.7917, Loss: 0.3117\n",
      "Epoch   6 Batch   14/269 - Train Accuracy: 0.7864, Validation Accuracy: 0.7930, Loss: 0.3370\n",
      "Epoch   6 Batch   15/269 - Train Accuracy: 0.7989, Validation Accuracy: 0.7836, Loss: 0.3240\n",
      "Epoch   6 Batch   16/269 - Train Accuracy: 0.7867, Validation Accuracy: 0.7860, Loss: 0.3373\n",
      "Epoch   6 Batch   17/269 - Train Accuracy: 0.8013, Validation Accuracy: 0.7868, Loss: 0.3204\n",
      "Epoch   6 Batch   18/269 - Train Accuracy: 0.7882, Validation Accuracy: 0.7885, Loss: 0.3405\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch   6 Batch   19/269 - Train Accuracy: 0.8080, Validation Accuracy: 0.7972, Loss: 0.3064\n",
      "Epoch   6 Batch   20/269 - Train Accuracy: 0.7979, Validation Accuracy: 0.7935, Loss: 0.3435\n",
      "Epoch   6 Batch   21/269 - Train Accuracy: 0.7679, Validation Accuracy: 0.7962, Loss: 0.3645\n",
      "Epoch   6 Batch   22/269 - Train Accuracy: 0.8114, Validation Accuracy: 0.7914, Loss: 0.3216\n",
      "Epoch   6 Batch   23/269 - Train Accuracy: 0.7976, Validation Accuracy: 0.7903, Loss: 0.3276\n",
      "Epoch   6 Batch   24/269 - Train Accuracy: 0.8133, Validation Accuracy: 0.7954, Loss: 0.3398\n",
      "Epoch   6 Batch   25/269 - Train Accuracy: 0.7937, Validation Accuracy: 0.7917, Loss: 0.3531\n",
      "Epoch   6 Batch   26/269 - Train Accuracy: 0.8077, Validation Accuracy: 0.7939, Loss: 0.3091\n",
      "Epoch   6 Batch   27/269 - Train Accuracy: 0.7911, Validation Accuracy: 0.7888, Loss: 0.3285\n",
      "Epoch   6 Batch   28/269 - Train Accuracy: 0.7723, Validation Accuracy: 0.7955, Loss: 0.3527\n",
      "Epoch   6 Batch   29/269 - Train Accuracy: 0.8012, Validation Accuracy: 0.8011, Loss: 0.3457\n",
      "Epoch   6 Batch   30/269 - Train Accuracy: 0.8022, Validation Accuracy: 0.7964, Loss: 0.3217\n",
      "Epoch   6 Batch   31/269 - Train Accuracy: 0.8122, Validation Accuracy: 0.7999, Loss: 0.3198\n",
      "Epoch   6 Batch   32/269 - Train Accuracy: 0.8028, Validation Accuracy: 0.7955, Loss: 0.3282\n",
      "Epoch   6 Batch   33/269 - Train Accuracy: 0.8137, Validation Accuracy: 0.7987, Loss: 0.3178\n",
      "Epoch   6 Batch   34/269 - Train Accuracy: 0.7983, Validation Accuracy: 0.7942, Loss: 0.3233\n",
      "Epoch   6 Batch   35/269 - Train Accuracy: 0.7875, Validation Accuracy: 0.7916, Loss: 0.3365\n",
      "Epoch   6 Batch   36/269 - Train Accuracy: 0.7815, Validation Accuracy: 0.7891, Loss: 0.3263\n",
      "Epoch   6 Batch   37/269 - Train Accuracy: 0.7933, Validation Accuracy: 0.7931, Loss: 0.3353\n",
      "Epoch   6 Batch   38/269 - Train Accuracy: 0.8016, Validation Accuracy: 0.7923, Loss: 0.3274\n",
      "Epoch   6 Batch   39/269 - Train Accuracy: 0.7919, Validation Accuracy: 0.7883, Loss: 0.3291\n",
      "Epoch   6 Batch   40/269 - Train Accuracy: 0.7876, Validation Accuracy: 0.8002, Loss: 0.3357\n",
      "Epoch   6 Batch   41/269 - Train Accuracy: 0.7840, Validation Accuracy: 0.7930, Loss: 0.3291\n",
      "Epoch   6 Batch   42/269 - Train Accuracy: 0.8185, Validation Accuracy: 0.7994, Loss: 0.3064\n",
      "Epoch   6 Batch   43/269 - Train Accuracy: 0.8064, Validation Accuracy: 0.8001, Loss: 0.3288\n",
      "Epoch   6 Batch   44/269 - Train Accuracy: 0.7967, Validation Accuracy: 0.8066, Loss: 0.3221\n",
      "Epoch   6 Batch   45/269 - Train Accuracy: 0.7942, Validation Accuracy: 0.7998, Loss: 0.3291\n",
      "Epoch   6 Batch   46/269 - Train Accuracy: 0.8066, Validation Accuracy: 0.7936, Loss: 0.3357\n",
      "Epoch   6 Batch   47/269 - Train Accuracy: 0.8089, Validation Accuracy: 0.7945, Loss: 0.3085\n",
      "Epoch   6 Batch   48/269 - Train Accuracy: 0.8203, Validation Accuracy: 0.7976, Loss: 0.3124\n",
      "Epoch   6 Batch   49/269 - Train Accuracy: 0.7893, Validation Accuracy: 0.7963, Loss: 0.3230\n",
      "Epoch   6 Batch   50/269 - Train Accuracy: 0.7816, Validation Accuracy: 0.7926, Loss: 0.3379\n",
      "Epoch   6 Batch   51/269 - Train Accuracy: 0.8056, Validation Accuracy: 0.7910, Loss: 0.3194\n",
      "Epoch   6 Batch   52/269 - Train Accuracy: 0.7855, Validation Accuracy: 0.7894, Loss: 0.3091\n",
      "Epoch   6 Batch   53/269 - Train Accuracy: 0.8035, Validation Accuracy: 0.7963, Loss: 0.3533\n",
      "Epoch   6 Batch   54/269 - Train Accuracy: 0.8183, Validation Accuracy: 0.7974, Loss: 0.3304\n",
      "Epoch   6 Batch   55/269 - Train Accuracy: 0.8202, Validation Accuracy: 0.7864, Loss: 0.3165\n",
      "Epoch   6 Batch   56/269 - Train Accuracy: 0.8025, Validation Accuracy: 0.7994, Loss: 0.3306\n",
      "Epoch   6 Batch   57/269 - Train Accuracy: 0.8007, Validation Accuracy: 0.7974, Loss: 0.3300\n",
      "Epoch   6 Batch   58/269 - Train Accuracy: 0.8072, Validation Accuracy: 0.7890, Loss: 0.3204\n",
      "Epoch   6 Batch   59/269 - Train Accuracy: 0.8175, Validation Accuracy: 0.7965, Loss: 0.3037\n",
      "Epoch   6 Batch   60/269 - Train Accuracy: 0.8123, Validation Accuracy: 0.8002, Loss: 0.3019\n",
      "Epoch   6 Batch   61/269 - Train Accuracy: 0.8161, Validation Accuracy: 0.7990, Loss: 0.2995\n",
      "Epoch   6 Batch   62/269 - Train Accuracy: 0.8103, Validation Accuracy: 0.7998, Loss: 0.3127\n",
      "Epoch   6 Batch   63/269 - Train Accuracy: 0.8044, Validation Accuracy: 0.7962, Loss: 0.3280\n",
      "Epoch   6 Batch   64/269 - Train Accuracy: 0.8198, Validation Accuracy: 0.8005, Loss: 0.3064\n",
      "Epoch   6 Batch   65/269 - Train Accuracy: 0.7936, Validation Accuracy: 0.8069, Loss: 0.3183\n",
      "Epoch   6 Batch   66/269 - Train Accuracy: 0.8137, Validation Accuracy: 0.8018, Loss: 0.3100\n",
      "Epoch   6 Batch   67/269 - Train Accuracy: 0.8288, Validation Accuracy: 0.8050, Loss: 0.3222\n",
      "Epoch   6 Batch   68/269 - Train Accuracy: 0.7927, Validation Accuracy: 0.7968, Loss: 0.3259\n",
      "Epoch   6 Batch   69/269 - Train Accuracy: 0.7898, Validation Accuracy: 0.8037, Loss: 0.3566\n",
      "Epoch   6 Batch   70/269 - Train Accuracy: 0.8175, Validation Accuracy: 0.8046, Loss: 0.3205\n",
      "Epoch   6 Batch   71/269 - Train Accuracy: 0.7953, Validation Accuracy: 0.7949, Loss: 0.3325\n",
      "Epoch   6 Batch   72/269 - Train Accuracy: 0.8096, Validation Accuracy: 0.7973, Loss: 0.3140\n",
      "Epoch   6 Batch   73/269 - Train Accuracy: 0.7924, Validation Accuracy: 0.7948, Loss: 0.3312\n",
      "Epoch   6 Batch   74/269 - Train Accuracy: 0.8038, Validation Accuracy: 0.7999, Loss: 0.3209\n",
      "Epoch   6 Batch   75/269 - Train Accuracy: 0.8213, Validation Accuracy: 0.8039, Loss: 0.3157\n",
      "Epoch   6 Batch   76/269 - Train Accuracy: 0.8044, Validation Accuracy: 0.8022, Loss: 0.3203\n",
      "Epoch   6 Batch   77/269 - Train Accuracy: 0.8151, Validation Accuracy: 0.8060, Loss: 0.3128\n",
      "Epoch   6 Batch   78/269 - Train Accuracy: 0.8227, Validation Accuracy: 0.7999, Loss: 0.3112\n",
      "Epoch   6 Batch   79/269 - Train Accuracy: 0.8044, Validation Accuracy: 0.8006, Loss: 0.3158\n",
      "Epoch   6 Batch   80/269 - Train Accuracy: 0.8238, Validation Accuracy: 0.8066, Loss: 0.3101\n",
      "Epoch   6 Batch   81/269 - Train Accuracy: 0.8035, Validation Accuracy: 0.8075, Loss: 0.3298\n",
      "Epoch   6 Batch   82/269 - Train Accuracy: 0.8181, Validation Accuracy: 0.8037, Loss: 0.2982\n",
      "Epoch   6 Batch   83/269 - Train Accuracy: 0.7989, Validation Accuracy: 0.8000, Loss: 0.3166\n",
      "Epoch   6 Batch   84/269 - Train Accuracy: 0.8088, Validation Accuracy: 0.8020, Loss: 0.3132\n",
      "Epoch   6 Batch   85/269 - Train Accuracy: 0.8161, Validation Accuracy: 0.8042, Loss: 0.3173\n",
      "Epoch   6 Batch   86/269 - Train Accuracy: 0.8157, Validation Accuracy: 0.8074, Loss: 0.3117\n",
      "Epoch   6 Batch   87/269 - Train Accuracy: 0.7904, Validation Accuracy: 0.8106, Loss: 0.3414\n",
      "Epoch   6 Batch   88/269 - Train Accuracy: 0.7928, Validation Accuracy: 0.8026, Loss: 0.3125\n",
      "Epoch   6 Batch   89/269 - Train Accuracy: 0.8195, Validation Accuracy: 0.8074, Loss: 0.3148\n",
      "Epoch   6 Batch   90/269 - Train Accuracy: 0.7942, Validation Accuracy: 0.8041, Loss: 0.3257\n",
      "Epoch   6 Batch   91/269 - Train Accuracy: 0.8341, Validation Accuracy: 0.8054, Loss: 0.3025\n",
      "Epoch   6 Batch   92/269 - Train Accuracy: 0.8219, Validation Accuracy: 0.8100, Loss: 0.2984\n",
      "Epoch   6 Batch   93/269 - Train Accuracy: 0.8171, Validation Accuracy: 0.8204, Loss: 0.2969\n",
      "Epoch   6 Batch   94/269 - Train Accuracy: 0.7947, Validation Accuracy: 0.8051, Loss: 0.3237\n",
      "Epoch   6 Batch   95/269 - Train Accuracy: 0.8073, Validation Accuracy: 0.8124, Loss: 0.3005\n",
      "Epoch   6 Batch   96/269 - Train Accuracy: 0.8072, Validation Accuracy: 0.8109, Loss: 0.3035\n",
      "Epoch   6 Batch   97/269 - Train Accuracy: 0.8139, Validation Accuracy: 0.8046, Loss: 0.3116\n",
      "Epoch   6 Batch   98/269 - Train Accuracy: 0.8342, Validation Accuracy: 0.8113, Loss: 0.3091\n",
      "Epoch   6 Batch   99/269 - Train Accuracy: 0.7860, Validation Accuracy: 0.8100, Loss: 0.3268\n",
      "Epoch   6 Batch  100/269 - Train Accuracy: 0.8239, Validation Accuracy: 0.8056, Loss: 0.3042\n",
      "Epoch   6 Batch  101/269 - Train Accuracy: 0.7983, Validation Accuracy: 0.8192, Loss: 0.3333\n",
      "Epoch   6 Batch  102/269 - Train Accuracy: 0.8093, Validation Accuracy: 0.8146, Loss: 0.3011\n",
      "Epoch   6 Batch  103/269 - Train Accuracy: 0.8160, Validation Accuracy: 0.8078, Loss: 0.3185\n",
      "Epoch   6 Batch  104/269 - Train Accuracy: 0.8104, Validation Accuracy: 0.8088, Loss: 0.3083\n",
      "Epoch   6 Batch  105/269 - Train Accuracy: 0.8124, Validation Accuracy: 0.8076, Loss: 0.3128\n",
      "Epoch   6 Batch  106/269 - Train Accuracy: 0.8006, Validation Accuracy: 0.8134, Loss: 0.3112\n",
      "Epoch   6 Batch  107/269 - Train Accuracy: 0.8287, Validation Accuracy: 0.8112, Loss: 0.3268\n",
      "Epoch   6 Batch  108/269 - Train Accuracy: 0.8220, Validation Accuracy: 0.8087, Loss: 0.3164\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch   6 Batch  109/269 - Train Accuracy: 0.7919, Validation Accuracy: 0.7951, Loss: 0.3113\n",
      "Epoch   6 Batch  110/269 - Train Accuracy: 0.8086, Validation Accuracy: 0.8006, Loss: 0.3021\n",
      "Epoch   6 Batch  111/269 - Train Accuracy: 0.8013, Validation Accuracy: 0.8033, Loss: 0.3350\n",
      "Epoch   6 Batch  112/269 - Train Accuracy: 0.8225, Validation Accuracy: 0.8127, Loss: 0.3029\n",
      "Epoch   6 Batch  113/269 - Train Accuracy: 0.8031, Validation Accuracy: 0.8112, Loss: 0.2979\n",
      "Epoch   6 Batch  114/269 - Train Accuracy: 0.8211, Validation Accuracy: 0.8139, Loss: 0.3117\n",
      "Epoch   6 Batch  115/269 - Train Accuracy: 0.7886, Validation Accuracy: 0.8093, Loss: 0.3212\n",
      "Epoch   6 Batch  116/269 - Train Accuracy: 0.8256, Validation Accuracy: 0.8115, Loss: 0.3171\n",
      "Epoch   6 Batch  117/269 - Train Accuracy: 0.8113, Validation Accuracy: 0.8072, Loss: 0.3081\n",
      "Epoch   6 Batch  118/269 - Train Accuracy: 0.8280, Validation Accuracy: 0.8098, Loss: 0.2985\n",
      "Epoch   6 Batch  119/269 - Train Accuracy: 0.8043, Validation Accuracy: 0.8110, Loss: 0.3270\n",
      "Epoch   6 Batch  120/269 - Train Accuracy: 0.8148, Validation Accuracy: 0.8081, Loss: 0.3138\n",
      "Epoch   6 Batch  121/269 - Train Accuracy: 0.8052, Validation Accuracy: 0.8068, Loss: 0.2999\n",
      "Epoch   6 Batch  122/269 - Train Accuracy: 0.8078, Validation Accuracy: 0.8102, Loss: 0.3021\n",
      "Epoch   6 Batch  123/269 - Train Accuracy: 0.8229, Validation Accuracy: 0.8099, Loss: 0.3215\n",
      "Epoch   6 Batch  124/269 - Train Accuracy: 0.8180, Validation Accuracy: 0.8102, Loss: 0.2952\n",
      "Epoch   6 Batch  125/269 - Train Accuracy: 0.8354, Validation Accuracy: 0.8121, Loss: 0.2969\n",
      "Epoch   6 Batch  126/269 - Train Accuracy: 0.8183, Validation Accuracy: 0.8161, Loss: 0.3006\n",
      "Epoch   6 Batch  127/269 - Train Accuracy: 0.8032, Validation Accuracy: 0.8134, Loss: 0.3190\n",
      "Epoch   6 Batch  128/269 - Train Accuracy: 0.8259, Validation Accuracy: 0.8184, Loss: 0.3061\n",
      "Epoch   6 Batch  129/269 - Train Accuracy: 0.8115, Validation Accuracy: 0.8104, Loss: 0.3051\n",
      "Epoch   6 Batch  130/269 - Train Accuracy: 0.8073, Validation Accuracy: 0.8071, Loss: 0.3167\n",
      "Epoch   6 Batch  131/269 - Train Accuracy: 0.8069, Validation Accuracy: 0.8158, Loss: 0.3099\n",
      "Epoch   6 Batch  132/269 - Train Accuracy: 0.7906, Validation Accuracy: 0.8035, Loss: 0.3116\n",
      "Epoch   6 Batch  133/269 - Train Accuracy: 0.8185, Validation Accuracy: 0.8078, Loss: 0.2983\n",
      "Epoch   6 Batch  134/269 - Train Accuracy: 0.8035, Validation Accuracy: 0.8139, Loss: 0.3138\n",
      "Epoch   6 Batch  135/269 - Train Accuracy: 0.8121, Validation Accuracy: 0.8169, Loss: 0.3224\n",
      "Epoch   6 Batch  136/269 - Train Accuracy: 0.7813, Validation Accuracy: 0.8127, Loss: 0.3228\n",
      "Epoch   6 Batch  137/269 - Train Accuracy: 0.8139, Validation Accuracy: 0.8186, Loss: 0.3221\n",
      "Epoch   6 Batch  138/269 - Train Accuracy: 0.8170, Validation Accuracy: 0.8087, Loss: 0.3020\n",
      "Epoch   6 Batch  139/269 - Train Accuracy: 0.8161, Validation Accuracy: 0.8209, Loss: 0.2980\n",
      "Epoch   6 Batch  140/269 - Train Accuracy: 0.8284, Validation Accuracy: 0.8150, Loss: 0.3129\n",
      "Epoch   6 Batch  141/269 - Train Accuracy: 0.8107, Validation Accuracy: 0.8108, Loss: 0.3166\n",
      "Epoch   6 Batch  142/269 - Train Accuracy: 0.8142, Validation Accuracy: 0.8206, Loss: 0.3016\n",
      "Epoch   6 Batch  143/269 - Train Accuracy: 0.8181, Validation Accuracy: 0.8052, Loss: 0.2933\n",
      "Epoch   6 Batch  144/269 - Train Accuracy: 0.8170, Validation Accuracy: 0.8112, Loss: 0.2989\n",
      "Epoch   6 Batch  145/269 - Train Accuracy: 0.8172, Validation Accuracy: 0.8168, Loss: 0.3009\n",
      "Epoch   6 Batch  146/269 - Train Accuracy: 0.8058, Validation Accuracy: 0.8091, Loss: 0.3036\n",
      "Epoch   6 Batch  147/269 - Train Accuracy: 0.8261, Validation Accuracy: 0.8058, Loss: 0.2923\n",
      "Epoch   6 Batch  148/269 - Train Accuracy: 0.8010, Validation Accuracy: 0.8038, Loss: 0.3072\n",
      "Epoch   6 Batch  149/269 - Train Accuracy: 0.7874, Validation Accuracy: 0.8008, Loss: 0.3112\n",
      "Epoch   6 Batch  150/269 - Train Accuracy: 0.8078, Validation Accuracy: 0.8138, Loss: 0.3063\n",
      "Epoch   6 Batch  151/269 - Train Accuracy: 0.8103, Validation Accuracy: 0.8102, Loss: 0.2886\n",
      "Epoch   6 Batch  152/269 - Train Accuracy: 0.8282, Validation Accuracy: 0.8138, Loss: 0.2990\n",
      "Epoch   6 Batch  153/269 - Train Accuracy: 0.8168, Validation Accuracy: 0.8055, Loss: 0.2969\n",
      "Epoch   6 Batch  154/269 - Train Accuracy: 0.8258, Validation Accuracy: 0.8192, Loss: 0.3080\n",
      "Epoch   6 Batch  155/269 - Train Accuracy: 0.8174, Validation Accuracy: 0.8167, Loss: 0.2867\n",
      "Epoch   6 Batch  156/269 - Train Accuracy: 0.7990, Validation Accuracy: 0.8199, Loss: 0.3082\n",
      "Epoch   6 Batch  157/269 - Train Accuracy: 0.7985, Validation Accuracy: 0.8130, Loss: 0.2943\n",
      "Epoch   6 Batch  158/269 - Train Accuracy: 0.8184, Validation Accuracy: 0.8226, Loss: 0.2961\n",
      "Epoch   6 Batch  159/269 - Train Accuracy: 0.8062, Validation Accuracy: 0.8254, Loss: 0.2973\n",
      "Epoch   6 Batch  160/269 - Train Accuracy: 0.8301, Validation Accuracy: 0.8251, Loss: 0.3009\n",
      "Epoch   6 Batch  161/269 - Train Accuracy: 0.8246, Validation Accuracy: 0.8123, Loss: 0.3008\n",
      "Epoch   6 Batch  162/269 - Train Accuracy: 0.8217, Validation Accuracy: 0.8114, Loss: 0.2923\n",
      "Epoch   6 Batch  163/269 - Train Accuracy: 0.8278, Validation Accuracy: 0.8263, Loss: 0.3029\n",
      "Epoch   6 Batch  164/269 - Train Accuracy: 0.8337, Validation Accuracy: 0.8205, Loss: 0.2916\n",
      "Epoch   6 Batch  165/269 - Train Accuracy: 0.8368, Validation Accuracy: 0.8231, Loss: 0.3094\n",
      "Epoch   6 Batch  166/269 - Train Accuracy: 0.8250, Validation Accuracy: 0.8158, Loss: 0.2781\n",
      "Epoch   6 Batch  167/269 - Train Accuracy: 0.8328, Validation Accuracy: 0.8269, Loss: 0.2945\n",
      "Epoch   6 Batch  168/269 - Train Accuracy: 0.8209, Validation Accuracy: 0.8314, Loss: 0.3078\n",
      "Epoch   6 Batch  169/269 - Train Accuracy: 0.8329, Validation Accuracy: 0.8300, Loss: 0.3026\n",
      "Epoch   6 Batch  170/269 - Train Accuracy: 0.8161, Validation Accuracy: 0.8238, Loss: 0.2906\n",
      "Epoch   6 Batch  171/269 - Train Accuracy: 0.8299, Validation Accuracy: 0.8294, Loss: 0.3045\n",
      "Epoch   6 Batch  172/269 - Train Accuracy: 0.8134, Validation Accuracy: 0.8270, Loss: 0.3059\n",
      "Epoch   6 Batch  173/269 - Train Accuracy: 0.8294, Validation Accuracy: 0.8267, Loss: 0.2828\n",
      "Epoch   6 Batch  174/269 - Train Accuracy: 0.8384, Validation Accuracy: 0.8256, Loss: 0.2882\n",
      "Epoch   6 Batch  175/269 - Train Accuracy: 0.8299, Validation Accuracy: 0.8248, Loss: 0.3049\n",
      "Epoch   6 Batch  176/269 - Train Accuracy: 0.8169, Validation Accuracy: 0.8247, Loss: 0.3141\n",
      "Epoch   6 Batch  177/269 - Train Accuracy: 0.8427, Validation Accuracy: 0.8336, Loss: 0.2811\n",
      "Epoch   6 Batch  178/269 - Train Accuracy: 0.8327, Validation Accuracy: 0.8330, Loss: 0.2930\n",
      "Epoch   6 Batch  179/269 - Train Accuracy: 0.8066, Validation Accuracy: 0.8263, Loss: 0.2904\n",
      "Epoch   6 Batch  180/269 - Train Accuracy: 0.8379, Validation Accuracy: 0.8290, Loss: 0.2783\n",
      "Epoch   6 Batch  181/269 - Train Accuracy: 0.8257, Validation Accuracy: 0.8238, Loss: 0.2947\n",
      "Epoch   6 Batch  182/269 - Train Accuracy: 0.8280, Validation Accuracy: 0.8240, Loss: 0.2919\n",
      "Epoch   6 Batch  183/269 - Train Accuracy: 0.8594, Validation Accuracy: 0.8224, Loss: 0.2534\n",
      "Epoch   6 Batch  184/269 - Train Accuracy: 0.8183, Validation Accuracy: 0.8158, Loss: 0.2953\n",
      "Epoch   6 Batch  185/269 - Train Accuracy: 0.8418, Validation Accuracy: 0.8275, Loss: 0.2824\n",
      "Epoch   6 Batch  186/269 - Train Accuracy: 0.8286, Validation Accuracy: 0.8278, Loss: 0.2906\n",
      "Epoch   6 Batch  187/269 - Train Accuracy: 0.8318, Validation Accuracy: 0.8365, Loss: 0.2809\n",
      "Epoch   6 Batch  188/269 - Train Accuracy: 0.8226, Validation Accuracy: 0.8323, Loss: 0.2737\n",
      "Epoch   6 Batch  189/269 - Train Accuracy: 0.8351, Validation Accuracy: 0.8294, Loss: 0.2774\n",
      "Epoch   6 Batch  190/269 - Train Accuracy: 0.8322, Validation Accuracy: 0.8303, Loss: 0.2786\n",
      "Epoch   6 Batch  191/269 - Train Accuracy: 0.8201, Validation Accuracy: 0.8266, Loss: 0.2881\n",
      "Epoch   6 Batch  192/269 - Train Accuracy: 0.8395, Validation Accuracy: 0.8319, Loss: 0.2891\n",
      "Epoch   6 Batch  193/269 - Train Accuracy: 0.8452, Validation Accuracy: 0.8303, Loss: 0.2809\n",
      "Epoch   6 Batch  194/269 - Train Accuracy: 0.8231, Validation Accuracy: 0.8312, Loss: 0.2956\n",
      "Epoch   6 Batch  195/269 - Train Accuracy: 0.8350, Validation Accuracy: 0.8307, Loss: 0.2899\n",
      "Epoch   6 Batch  196/269 - Train Accuracy: 0.8347, Validation Accuracy: 0.8260, Loss: 0.2756\n",
      "Epoch   6 Batch  197/269 - Train Accuracy: 0.8208, Validation Accuracy: 0.8345, Loss: 0.3074\n",
      "Epoch   6 Batch  198/269 - Train Accuracy: 0.8291, Validation Accuracy: 0.8384, Loss: 0.3095\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch   6 Batch  199/269 - Train Accuracy: 0.8313, Validation Accuracy: 0.8238, Loss: 0.2915\n",
      "Epoch   6 Batch  200/269 - Train Accuracy: 0.8152, Validation Accuracy: 0.8298, Loss: 0.3017\n",
      "Epoch   6 Batch  201/269 - Train Accuracy: 0.8265, Validation Accuracy: 0.8290, Loss: 0.2915\n",
      "Epoch   6 Batch  202/269 - Train Accuracy: 0.8049, Validation Accuracy: 0.8294, Loss: 0.2897\n",
      "Epoch   6 Batch  203/269 - Train Accuracy: 0.8241, Validation Accuracy: 0.8244, Loss: 0.3118\n",
      "Epoch   6 Batch  204/269 - Train Accuracy: 0.8218, Validation Accuracy: 0.8321, Loss: 0.3058\n",
      "Epoch   6 Batch  205/269 - Train Accuracy: 0.8410, Validation Accuracy: 0.8232, Loss: 0.2894\n",
      "Epoch   6 Batch  206/269 - Train Accuracy: 0.8106, Validation Accuracy: 0.8357, Loss: 0.3061\n",
      "Epoch   6 Batch  207/269 - Train Accuracy: 0.8352, Validation Accuracy: 0.8306, Loss: 0.2772\n",
      "Epoch   6 Batch  208/269 - Train Accuracy: 0.8369, Validation Accuracy: 0.8283, Loss: 0.2986\n",
      "Epoch   6 Batch  209/269 - Train Accuracy: 0.8487, Validation Accuracy: 0.8282, Loss: 0.2825\n",
      "Epoch   6 Batch  210/269 - Train Accuracy: 0.8283, Validation Accuracy: 0.8271, Loss: 0.2739\n",
      "Epoch   6 Batch  211/269 - Train Accuracy: 0.8259, Validation Accuracy: 0.8335, Loss: 0.2885\n",
      "Epoch   6 Batch  212/269 - Train Accuracy: 0.8251, Validation Accuracy: 0.8296, Loss: 0.2837\n",
      "Epoch   6 Batch  213/269 - Train Accuracy: 0.8344, Validation Accuracy: 0.8204, Loss: 0.2754\n",
      "Epoch   6 Batch  214/269 - Train Accuracy: 0.8133, Validation Accuracy: 0.8322, Loss: 0.2915\n",
      "Epoch   6 Batch  215/269 - Train Accuracy: 0.8471, Validation Accuracy: 0.8349, Loss: 0.2648\n",
      "Epoch   6 Batch  216/269 - Train Accuracy: 0.8150, Validation Accuracy: 0.8346, Loss: 0.3136\n",
      "Epoch   6 Batch  217/269 - Train Accuracy: 0.8302, Validation Accuracy: 0.8318, Loss: 0.2917\n",
      "Epoch   6 Batch  218/269 - Train Accuracy: 0.8406, Validation Accuracy: 0.8310, Loss: 0.2951\n",
      "Epoch   6 Batch  219/269 - Train Accuracy: 0.8633, Validation Accuracy: 0.8388, Loss: 0.2995\n",
      "Epoch   6 Batch  220/269 - Train Accuracy: 0.8466, Validation Accuracy: 0.8339, Loss: 0.2670\n",
      "Epoch   6 Batch  221/269 - Train Accuracy: 0.8456, Validation Accuracy: 0.8368, Loss: 0.2863\n",
      "Epoch   6 Batch  222/269 - Train Accuracy: 0.8560, Validation Accuracy: 0.8297, Loss: 0.2705\n",
      "Epoch   6 Batch  223/269 - Train Accuracy: 0.8313, Validation Accuracy: 0.8370, Loss: 0.2710\n",
      "Epoch   6 Batch  224/269 - Train Accuracy: 0.8338, Validation Accuracy: 0.8413, Loss: 0.2971\n",
      "Epoch   6 Batch  225/269 - Train Accuracy: 0.8384, Validation Accuracy: 0.8447, Loss: 0.2811\n",
      "Epoch   6 Batch  226/269 - Train Accuracy: 0.8487, Validation Accuracy: 0.8359, Loss: 0.2821\n",
      "Epoch   6 Batch  227/269 - Train Accuracy: 0.8526, Validation Accuracy: 0.8370, Loss: 0.2623\n",
      "Epoch   6 Batch  228/269 - Train Accuracy: 0.8351, Validation Accuracy: 0.8374, Loss: 0.2793\n",
      "Epoch   6 Batch  229/269 - Train Accuracy: 0.8276, Validation Accuracy: 0.8361, Loss: 0.2795\n",
      "Epoch   6 Batch  230/269 - Train Accuracy: 0.8346, Validation Accuracy: 0.8344, Loss: 0.2752\n",
      "Epoch   6 Batch  231/269 - Train Accuracy: 0.8450, Validation Accuracy: 0.8368, Loss: 0.2972\n",
      "Epoch   6 Batch  232/269 - Train Accuracy: 0.8253, Validation Accuracy: 0.8414, Loss: 0.2911\n",
      "Epoch   6 Batch  233/269 - Train Accuracy: 0.8474, Validation Accuracy: 0.8395, Loss: 0.2849\n",
      "Epoch   6 Batch  234/269 - Train Accuracy: 0.8368, Validation Accuracy: 0.8371, Loss: 0.2809\n",
      "Epoch   6 Batch  235/269 - Train Accuracy: 0.8313, Validation Accuracy: 0.8238, Loss: 0.2608\n",
      "Epoch   6 Batch  236/269 - Train Accuracy: 0.8372, Validation Accuracy: 0.8300, Loss: 0.2730\n",
      "Epoch   6 Batch  237/269 - Train Accuracy: 0.8344, Validation Accuracy: 0.8339, Loss: 0.2758\n",
      "Epoch   6 Batch  238/269 - Train Accuracy: 0.8461, Validation Accuracy: 0.8374, Loss: 0.2721\n",
      "Epoch   6 Batch  239/269 - Train Accuracy: 0.8387, Validation Accuracy: 0.8284, Loss: 0.2781\n",
      "Epoch   6 Batch  240/269 - Train Accuracy: 0.8483, Validation Accuracy: 0.8197, Loss: 0.2535\n",
      "Epoch   6 Batch  241/269 - Train Accuracy: 0.8368, Validation Accuracy: 0.8291, Loss: 0.2970\n",
      "Epoch   6 Batch  242/269 - Train Accuracy: 0.8451, Validation Accuracy: 0.8374, Loss: 0.2695\n",
      "Epoch   6 Batch  243/269 - Train Accuracy: 0.8346, Validation Accuracy: 0.8274, Loss: 0.2726\n",
      "Epoch   6 Batch  244/269 - Train Accuracy: 0.8440, Validation Accuracy: 0.8329, Loss: 0.2875\n",
      "Epoch   6 Batch  245/269 - Train Accuracy: 0.8155, Validation Accuracy: 0.8404, Loss: 0.2929\n",
      "Epoch   6 Batch  246/269 - Train Accuracy: 0.8185, Validation Accuracy: 0.8283, Loss: 0.2791\n",
      "Epoch   6 Batch  247/269 - Train Accuracy: 0.8400, Validation Accuracy: 0.8331, Loss: 0.2837\n",
      "Epoch   6 Batch  248/269 - Train Accuracy: 0.8281, Validation Accuracy: 0.8199, Loss: 0.2646\n",
      "Epoch   6 Batch  249/269 - Train Accuracy: 0.8592, Validation Accuracy: 0.8341, Loss: 0.2663\n",
      "Epoch   6 Batch  250/269 - Train Accuracy: 0.8513, Validation Accuracy: 0.8365, Loss: 0.2708\n",
      "Epoch   6 Batch  251/269 - Train Accuracy: 0.8716, Validation Accuracy: 0.8422, Loss: 0.2680\n",
      "Epoch   6 Batch  252/269 - Train Accuracy: 0.8303, Validation Accuracy: 0.8361, Loss: 0.2722\n",
      "Epoch   6 Batch  253/269 - Train Accuracy: 0.8153, Validation Accuracy: 0.8395, Loss: 0.2873\n",
      "Epoch   6 Batch  254/269 - Train Accuracy: 0.8516, Validation Accuracy: 0.8512, Loss: 0.2700\n",
      "Epoch   6 Batch  255/269 - Train Accuracy: 0.8295, Validation Accuracy: 0.8492, Loss: 0.2700\n",
      "Epoch   6 Batch  256/269 - Train Accuracy: 0.8277, Validation Accuracy: 0.8483, Loss: 0.2797\n",
      "Epoch   6 Batch  257/269 - Train Accuracy: 0.8141, Validation Accuracy: 0.8345, Loss: 0.2814\n",
      "Epoch   6 Batch  258/269 - Train Accuracy: 0.8529, Validation Accuracy: 0.8380, Loss: 0.2821\n",
      "Epoch   6 Batch  259/269 - Train Accuracy: 0.8460, Validation Accuracy: 0.8421, Loss: 0.2713\n",
      "Epoch   6 Batch  260/269 - Train Accuracy: 0.8227, Validation Accuracy: 0.8374, Loss: 0.2897\n",
      "Epoch   6 Batch  261/269 - Train Accuracy: 0.8265, Validation Accuracy: 0.8382, Loss: 0.2896\n",
      "Epoch   6 Batch  262/269 - Train Accuracy: 0.8449, Validation Accuracy: 0.8358, Loss: 0.2766\n",
      "Epoch   6 Batch  263/269 - Train Accuracy: 0.8392, Validation Accuracy: 0.8393, Loss: 0.2857\n",
      "Epoch   6 Batch  264/269 - Train Accuracy: 0.8224, Validation Accuracy: 0.8358, Loss: 0.2895\n",
      "Epoch   6 Batch  265/269 - Train Accuracy: 0.8573, Validation Accuracy: 0.8333, Loss: 0.2832\n",
      "Epoch   6 Batch  266/269 - Train Accuracy: 0.8391, Validation Accuracy: 0.8289, Loss: 0.2611\n",
      "Epoch   6 Batch  267/269 - Train Accuracy: 0.8516, Validation Accuracy: 0.8426, Loss: 0.2788\n",
      "Epoch   7 Batch    1/269 - Train Accuracy: 0.8478, Validation Accuracy: 0.8408, Loss: 0.2749\n",
      "Epoch   7 Batch    2/269 - Train Accuracy: 0.8229, Validation Accuracy: 0.8404, Loss: 0.2825\n",
      "Epoch   7 Batch    3/269 - Train Accuracy: 0.8412, Validation Accuracy: 0.8430, Loss: 0.2801\n",
      "Epoch   7 Batch    4/269 - Train Accuracy: 0.8282, Validation Accuracy: 0.8397, Loss: 0.2814\n",
      "Epoch   7 Batch    5/269 - Train Accuracy: 0.8377, Validation Accuracy: 0.8372, Loss: 0.2818\n",
      "Epoch   7 Batch    6/269 - Train Accuracy: 0.8528, Validation Accuracy: 0.8400, Loss: 0.2583\n",
      "Epoch   7 Batch    7/269 - Train Accuracy: 0.8397, Validation Accuracy: 0.8366, Loss: 0.2664\n",
      "Epoch   7 Batch    8/269 - Train Accuracy: 0.8509, Validation Accuracy: 0.8382, Loss: 0.2822\n",
      "Epoch   7 Batch    9/269 - Train Accuracy: 0.8461, Validation Accuracy: 0.8443, Loss: 0.2802\n",
      "Epoch   7 Batch   10/269 - Train Accuracy: 0.8452, Validation Accuracy: 0.8414, Loss: 0.2735\n",
      "Epoch   7 Batch   11/269 - Train Accuracy: 0.8399, Validation Accuracy: 0.8329, Loss: 0.2772\n",
      "Epoch   7 Batch   12/269 - Train Accuracy: 0.8321, Validation Accuracy: 0.8353, Loss: 0.2893\n",
      "Epoch   7 Batch   13/269 - Train Accuracy: 0.8486, Validation Accuracy: 0.8408, Loss: 0.2397\n",
      "Epoch   7 Batch   14/269 - Train Accuracy: 0.8293, Validation Accuracy: 0.8478, Loss: 0.2675\n",
      "Epoch   7 Batch   15/269 - Train Accuracy: 0.8558, Validation Accuracy: 0.8406, Loss: 0.2532\n",
      "Epoch   7 Batch   16/269 - Train Accuracy: 0.8396, Validation Accuracy: 0.8445, Loss: 0.2716\n",
      "Epoch   7 Batch   17/269 - Train Accuracy: 0.8459, Validation Accuracy: 0.8452, Loss: 0.2525\n",
      "Epoch   7 Batch   18/269 - Train Accuracy: 0.8441, Validation Accuracy: 0.8489, Loss: 0.2705\n",
      "Epoch   7 Batch   19/269 - Train Accuracy: 0.8537, Validation Accuracy: 0.8530, Loss: 0.2480\n",
      "Epoch   7 Batch   20/269 - Train Accuracy: 0.8511, Validation Accuracy: 0.8500, Loss: 0.2684\n",
      "Epoch   7 Batch   21/269 - Train Accuracy: 0.8200, Validation Accuracy: 0.8421, Loss: 0.2935\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch   7 Batch   22/269 - Train Accuracy: 0.8623, Validation Accuracy: 0.8557, Loss: 0.2602\n",
      "Epoch   7 Batch   23/269 - Train Accuracy: 0.8498, Validation Accuracy: 0.8574, Loss: 0.2644\n",
      "Epoch   7 Batch   24/269 - Train Accuracy: 0.8570, Validation Accuracy: 0.8533, Loss: 0.2733\n",
      "Epoch   7 Batch   25/269 - Train Accuracy: 0.8447, Validation Accuracy: 0.8518, Loss: 0.2826\n",
      "Epoch   7 Batch   26/269 - Train Accuracy: 0.8515, Validation Accuracy: 0.8522, Loss: 0.2424\n",
      "Epoch   7 Batch   27/269 - Train Accuracy: 0.8372, Validation Accuracy: 0.8540, Loss: 0.2608\n",
      "Epoch   7 Batch   28/269 - Train Accuracy: 0.8024, Validation Accuracy: 0.8520, Loss: 0.2888\n",
      "Epoch   7 Batch   29/269 - Train Accuracy: 0.8587, Validation Accuracy: 0.8622, Loss: 0.2808\n",
      "Epoch   7 Batch   30/269 - Train Accuracy: 0.8473, Validation Accuracy: 0.8521, Loss: 0.2617\n",
      "Epoch   7 Batch   31/269 - Train Accuracy: 0.8544, Validation Accuracy: 0.8517, Loss: 0.2550\n",
      "Epoch   7 Batch   32/269 - Train Accuracy: 0.8488, Validation Accuracy: 0.8525, Loss: 0.2556\n",
      "Epoch   7 Batch   33/269 - Train Accuracy: 0.8521, Validation Accuracy: 0.8553, Loss: 0.2495\n",
      "Epoch   7 Batch   34/269 - Train Accuracy: 0.8436, Validation Accuracy: 0.8452, Loss: 0.2679\n",
      "Epoch   7 Batch   35/269 - Train Accuracy: 0.8442, Validation Accuracy: 0.8487, Loss: 0.2665\n",
      "Epoch   7 Batch   36/269 - Train Accuracy: 0.8285, Validation Accuracy: 0.8568, Loss: 0.2650\n",
      "Epoch   7 Batch   37/269 - Train Accuracy: 0.8488, Validation Accuracy: 0.8587, Loss: 0.2682\n",
      "Epoch   7 Batch   38/269 - Train Accuracy: 0.8455, Validation Accuracy: 0.8524, Loss: 0.2665\n",
      "Epoch   7 Batch   39/269 - Train Accuracy: 0.8317, Validation Accuracy: 0.8453, Loss: 0.2597\n",
      "Epoch   7 Batch   40/269 - Train Accuracy: 0.8347, Validation Accuracy: 0.8547, Loss: 0.2688\n",
      "Epoch   7 Batch   41/269 - Train Accuracy: 0.8386, Validation Accuracy: 0.8558, Loss: 0.2684\n",
      "Epoch   7 Batch   42/269 - Train Accuracy: 0.8730, Validation Accuracy: 0.8459, Loss: 0.2433\n",
      "Epoch   7 Batch   43/269 - Train Accuracy: 0.8463, Validation Accuracy: 0.8579, Loss: 0.2695\n",
      "Epoch   7 Batch   44/269 - Train Accuracy: 0.8338, Validation Accuracy: 0.8618, Loss: 0.2623\n",
      "Epoch   7 Batch   45/269 - Train Accuracy: 0.8515, Validation Accuracy: 0.8548, Loss: 0.2705\n",
      "Epoch   7 Batch   46/269 - Train Accuracy: 0.8521, Validation Accuracy: 0.8574, Loss: 0.2787\n",
      "Epoch   7 Batch   47/269 - Train Accuracy: 0.8610, Validation Accuracy: 0.8578, Loss: 0.2466\n",
      "Epoch   7 Batch   48/269 - Train Accuracy: 0.8559, Validation Accuracy: 0.8473, Loss: 0.2579\n",
      "Epoch   7 Batch   49/269 - Train Accuracy: 0.8509, Validation Accuracy: 0.8451, Loss: 0.2607\n",
      "Epoch   7 Batch   50/269 - Train Accuracy: 0.8238, Validation Accuracy: 0.8502, Loss: 0.2759\n",
      "Epoch   7 Batch   51/269 - Train Accuracy: 0.8575, Validation Accuracy: 0.8540, Loss: 0.2565\n",
      "Epoch   7 Batch   52/269 - Train Accuracy: 0.8427, Validation Accuracy: 0.8525, Loss: 0.2470\n",
      "Epoch   7 Batch   53/269 - Train Accuracy: 0.8472, Validation Accuracy: 0.8493, Loss: 0.2772\n",
      "Epoch   7 Batch   54/269 - Train Accuracy: 0.8479, Validation Accuracy: 0.8433, Loss: 0.2682\n",
      "Epoch   7 Batch   55/269 - Train Accuracy: 0.8706, Validation Accuracy: 0.8442, Loss: 0.2559\n",
      "Epoch   7 Batch   56/269 - Train Accuracy: 0.8480, Validation Accuracy: 0.8502, Loss: 0.2632\n",
      "Epoch   7 Batch   57/269 - Train Accuracy: 0.8460, Validation Accuracy: 0.8517, Loss: 0.2695\n",
      "Epoch   7 Batch   58/269 - Train Accuracy: 0.8489, Validation Accuracy: 0.8538, Loss: 0.2599\n",
      "Epoch   7 Batch   59/269 - Train Accuracy: 0.8652, Validation Accuracy: 0.8450, Loss: 0.2319\n",
      "Epoch   7 Batch   60/269 - Train Accuracy: 0.8673, Validation Accuracy: 0.8559, Loss: 0.2501\n",
      "Epoch   7 Batch   61/269 - Train Accuracy: 0.8517, Validation Accuracy: 0.8601, Loss: 0.2411\n",
      "Epoch   7 Batch   62/269 - Train Accuracy: 0.8499, Validation Accuracy: 0.8508, Loss: 0.2492\n",
      "Epoch   7 Batch   63/269 - Train Accuracy: 0.8516, Validation Accuracy: 0.8601, Loss: 0.2675\n",
      "Epoch   7 Batch   64/269 - Train Accuracy: 0.8570, Validation Accuracy: 0.8619, Loss: 0.2428\n",
      "Epoch   7 Batch   65/269 - Train Accuracy: 0.8404, Validation Accuracy: 0.8613, Loss: 0.2587\n",
      "Epoch   7 Batch   66/269 - Train Accuracy: 0.8479, Validation Accuracy: 0.8585, Loss: 0.2540\n",
      "Epoch   7 Batch   67/269 - Train Accuracy: 0.8567, Validation Accuracy: 0.8562, Loss: 0.2654\n",
      "Epoch   7 Batch   68/269 - Train Accuracy: 0.8400, Validation Accuracy: 0.8544, Loss: 0.2678\n",
      "Epoch   7 Batch   69/269 - Train Accuracy: 0.8293, Validation Accuracy: 0.8555, Loss: 0.2880\n",
      "Epoch   7 Batch   70/269 - Train Accuracy: 0.8553, Validation Accuracy: 0.8588, Loss: 0.2646\n",
      "Epoch   7 Batch   71/269 - Train Accuracy: 0.8473, Validation Accuracy: 0.8562, Loss: 0.2728\n",
      "Epoch   7 Batch   72/269 - Train Accuracy: 0.8461, Validation Accuracy: 0.8568, Loss: 0.2605\n",
      "Epoch   7 Batch   73/269 - Train Accuracy: 0.8545, Validation Accuracy: 0.8491, Loss: 0.2664\n",
      "Epoch   7 Batch   74/269 - Train Accuracy: 0.8490, Validation Accuracy: 0.8582, Loss: 0.2472\n",
      "Epoch   7 Batch   75/269 - Train Accuracy: 0.8582, Validation Accuracy: 0.8548, Loss: 0.2616\n",
      "Epoch   7 Batch   76/269 - Train Accuracy: 0.8358, Validation Accuracy: 0.8503, Loss: 0.2520\n",
      "Epoch   7 Batch   77/269 - Train Accuracy: 0.8613, Validation Accuracy: 0.8545, Loss: 0.2515\n",
      "Epoch   7 Batch   78/269 - Train Accuracy: 0.8586, Validation Accuracy: 0.8613, Loss: 0.2575\n",
      "Epoch   7 Batch   79/269 - Train Accuracy: 0.8533, Validation Accuracy: 0.8545, Loss: 0.2548\n",
      "Epoch   7 Batch   80/269 - Train Accuracy: 0.8640, Validation Accuracy: 0.8611, Loss: 0.2481\n",
      "Epoch   7 Batch   81/269 - Train Accuracy: 0.8422, Validation Accuracy: 0.8605, Loss: 0.2588\n",
      "Epoch   7 Batch   82/269 - Train Accuracy: 0.8677, Validation Accuracy: 0.8532, Loss: 0.2387\n",
      "Epoch   7 Batch   83/269 - Train Accuracy: 0.8397, Validation Accuracy: 0.8546, Loss: 0.2667\n",
      "Epoch   7 Batch   84/269 - Train Accuracy: 0.8496, Validation Accuracy: 0.8517, Loss: 0.2516\n",
      "Epoch   7 Batch   85/269 - Train Accuracy: 0.8564, Validation Accuracy: 0.8595, Loss: 0.2503\n",
      "Epoch   7 Batch   86/269 - Train Accuracy: 0.8513, Validation Accuracy: 0.8664, Loss: 0.2420\n",
      "Epoch   7 Batch   87/269 - Train Accuracy: 0.8317, Validation Accuracy: 0.8580, Loss: 0.2731\n",
      "Epoch   7 Batch   88/269 - Train Accuracy: 0.8379, Validation Accuracy: 0.8583, Loss: 0.2559\n",
      "Epoch   7 Batch   89/269 - Train Accuracy: 0.8518, Validation Accuracy: 0.8592, Loss: 0.2583\n",
      "Epoch   7 Batch   90/269 - Train Accuracy: 0.8348, Validation Accuracy: 0.8522, Loss: 0.2756\n",
      "Epoch   7 Batch   91/269 - Train Accuracy: 0.8710, Validation Accuracy: 0.8503, Loss: 0.2515\n",
      "Epoch   7 Batch   92/269 - Train Accuracy: 0.8643, Validation Accuracy: 0.8559, Loss: 0.2451\n",
      "Epoch   7 Batch   93/269 - Train Accuracy: 0.8603, Validation Accuracy: 0.8572, Loss: 0.2482\n",
      "Epoch   7 Batch   94/269 - Train Accuracy: 0.8399, Validation Accuracy: 0.8552, Loss: 0.2698\n",
      "Epoch   7 Batch   95/269 - Train Accuracy: 0.8504, Validation Accuracy: 0.8542, Loss: 0.2521\n",
      "Epoch   7 Batch   96/269 - Train Accuracy: 0.8556, Validation Accuracy: 0.8577, Loss: 0.2552\n",
      "Epoch   7 Batch   97/269 - Train Accuracy: 0.8499, Validation Accuracy: 0.8526, Loss: 0.2505\n",
      "Epoch   7 Batch   98/269 - Train Accuracy: 0.8645, Validation Accuracy: 0.8576, Loss: 0.2596\n",
      "Epoch   7 Batch   99/269 - Train Accuracy: 0.8406, Validation Accuracy: 0.8575, Loss: 0.2571\n",
      "Epoch   7 Batch  100/269 - Train Accuracy: 0.8640, Validation Accuracy: 0.8612, Loss: 0.2462\n",
      "Epoch   7 Batch  101/269 - Train Accuracy: 0.8445, Validation Accuracy: 0.8628, Loss: 0.2695\n",
      "Epoch   7 Batch  102/269 - Train Accuracy: 0.8480, Validation Accuracy: 0.8612, Loss: 0.2471\n",
      "Epoch   7 Batch  103/269 - Train Accuracy: 0.8637, Validation Accuracy: 0.8604, Loss: 0.2621\n",
      "Epoch   7 Batch  104/269 - Train Accuracy: 0.8626, Validation Accuracy: 0.8647, Loss: 0.2446\n",
      "Epoch   7 Batch  105/269 - Train Accuracy: 0.8506, Validation Accuracy: 0.8645, Loss: 0.2438\n",
      "Epoch   7 Batch  106/269 - Train Accuracy: 0.8542, Validation Accuracy: 0.8630, Loss: 0.2473\n",
      "Epoch   7 Batch  107/269 - Train Accuracy: 0.8655, Validation Accuracy: 0.8600, Loss: 0.2591\n",
      "Epoch   7 Batch  108/269 - Train Accuracy: 0.8679, Validation Accuracy: 0.8658, Loss: 0.2468\n",
      "Epoch   7 Batch  109/269 - Train Accuracy: 0.8324, Validation Accuracy: 0.8582, Loss: 0.2587\n",
      "Epoch   7 Batch  110/269 - Train Accuracy: 0.8646, Validation Accuracy: 0.8562, Loss: 0.2434\n",
      "Epoch   7 Batch  111/269 - Train Accuracy: 0.8446, Validation Accuracy: 0.8551, Loss: 0.2679\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch   7 Batch  112/269 - Train Accuracy: 0.8656, Validation Accuracy: 0.8568, Loss: 0.2451\n",
      "Epoch   7 Batch  113/269 - Train Accuracy: 0.8512, Validation Accuracy: 0.8574, Loss: 0.2401\n",
      "Epoch   7 Batch  114/269 - Train Accuracy: 0.8639, Validation Accuracy: 0.8574, Loss: 0.2475\n",
      "Epoch   7 Batch  115/269 - Train Accuracy: 0.8429, Validation Accuracy: 0.8601, Loss: 0.2587\n",
      "Epoch   7 Batch  116/269 - Train Accuracy: 0.8671, Validation Accuracy: 0.8543, Loss: 0.2554\n",
      "Epoch   7 Batch  117/269 - Train Accuracy: 0.8485, Validation Accuracy: 0.8604, Loss: 0.2496\n",
      "Epoch   7 Batch  118/269 - Train Accuracy: 0.8705, Validation Accuracy: 0.8577, Loss: 0.2347\n",
      "Epoch   7 Batch  119/269 - Train Accuracy: 0.8477, Validation Accuracy: 0.8568, Loss: 0.2627\n",
      "Epoch   7 Batch  120/269 - Train Accuracy: 0.8649, Validation Accuracy: 0.8559, Loss: 0.2486\n",
      "Epoch   7 Batch  121/269 - Train Accuracy: 0.8590, Validation Accuracy: 0.8583, Loss: 0.2425\n",
      "Epoch   7 Batch  122/269 - Train Accuracy: 0.8570, Validation Accuracy: 0.8593, Loss: 0.2368\n",
      "Epoch   7 Batch  123/269 - Train Accuracy: 0.8693, Validation Accuracy: 0.8562, Loss: 0.2566\n",
      "Epoch   7 Batch  124/269 - Train Accuracy: 0.8544, Validation Accuracy: 0.8644, Loss: 0.2369\n",
      "Epoch   7 Batch  125/269 - Train Accuracy: 0.8761, Validation Accuracy: 0.8650, Loss: 0.2351\n",
      "Epoch   7 Batch  126/269 - Train Accuracy: 0.8509, Validation Accuracy: 0.8664, Loss: 0.2424\n",
      "Epoch   7 Batch  127/269 - Train Accuracy: 0.8537, Validation Accuracy: 0.8606, Loss: 0.2516\n",
      "Epoch   7 Batch  128/269 - Train Accuracy: 0.8633, Validation Accuracy: 0.8654, Loss: 0.2426\n",
      "Epoch   7 Batch  129/269 - Train Accuracy: 0.8580, Validation Accuracy: 0.8595, Loss: 0.2438\n",
      "Epoch   7 Batch  130/269 - Train Accuracy: 0.8624, Validation Accuracy: 0.8651, Loss: 0.2546\n",
      "Epoch   7 Batch  131/269 - Train Accuracy: 0.8391, Validation Accuracy: 0.8596, Loss: 0.2446\n",
      "Epoch   7 Batch  132/269 - Train Accuracy: 0.8527, Validation Accuracy: 0.8680, Loss: 0.2554\n",
      "Epoch   7 Batch  133/269 - Train Accuracy: 0.8707, Validation Accuracy: 0.8695, Loss: 0.2313\n",
      "Epoch   7 Batch  134/269 - Train Accuracy: 0.8497, Validation Accuracy: 0.8651, Loss: 0.2408\n",
      "Epoch   7 Batch  135/269 - Train Accuracy: 0.8580, Validation Accuracy: 0.8604, Loss: 0.2522\n",
      "Epoch   7 Batch  136/269 - Train Accuracy: 0.8364, Validation Accuracy: 0.8637, Loss: 0.2547\n",
      "Epoch   7 Batch  137/269 - Train Accuracy: 0.8547, Validation Accuracy: 0.8630, Loss: 0.2526\n",
      "Epoch   7 Batch  138/269 - Train Accuracy: 0.8710, Validation Accuracy: 0.8639, Loss: 0.2414\n",
      "Epoch   7 Batch  139/269 - Train Accuracy: 0.8555, Validation Accuracy: 0.8717, Loss: 0.2317\n",
      "Epoch   7 Batch  140/269 - Train Accuracy: 0.8661, Validation Accuracy: 0.8659, Loss: 0.2489\n",
      "Epoch   7 Batch  141/269 - Train Accuracy: 0.8616, Validation Accuracy: 0.8578, Loss: 0.2509\n",
      "Epoch   7 Batch  142/269 - Train Accuracy: 0.8374, Validation Accuracy: 0.8592, Loss: 0.2311\n",
      "Epoch   7 Batch  143/269 - Train Accuracy: 0.8726, Validation Accuracy: 0.8693, Loss: 0.2394\n",
      "Epoch   7 Batch  144/269 - Train Accuracy: 0.8662, Validation Accuracy: 0.8669, Loss: 0.2264\n",
      "Epoch   7 Batch  145/269 - Train Accuracy: 0.8594, Validation Accuracy: 0.8683, Loss: 0.2295\n",
      "Epoch   7 Batch  146/269 - Train Accuracy: 0.8676, Validation Accuracy: 0.8590, Loss: 0.2359\n",
      "Epoch   7 Batch  147/269 - Train Accuracy: 0.8658, Validation Accuracy: 0.8612, Loss: 0.2331\n",
      "Epoch   7 Batch  148/269 - Train Accuracy: 0.8504, Validation Accuracy: 0.8571, Loss: 0.2456\n",
      "Epoch   7 Batch  149/269 - Train Accuracy: 0.8342, Validation Accuracy: 0.8572, Loss: 0.2482\n",
      "Epoch   7 Batch  150/269 - Train Accuracy: 0.8502, Validation Accuracy: 0.8531, Loss: 0.2356\n",
      "Epoch   7 Batch  151/269 - Train Accuracy: 0.8473, Validation Accuracy: 0.8476, Loss: 0.2367\n",
      "Epoch   7 Batch  152/269 - Train Accuracy: 0.8697, Validation Accuracy: 0.8604, Loss: 0.2420\n",
      "Epoch   7 Batch  153/269 - Train Accuracy: 0.8605, Validation Accuracy: 0.8568, Loss: 0.2373\n",
      "Epoch   7 Batch  154/269 - Train Accuracy: 0.8691, Validation Accuracy: 0.8635, Loss: 0.2450\n",
      "Epoch   7 Batch  155/269 - Train Accuracy: 0.8510, Validation Accuracy: 0.8665, Loss: 0.2212\n",
      "Epoch   7 Batch  156/269 - Train Accuracy: 0.8384, Validation Accuracy: 0.8636, Loss: 0.2516\n",
      "Epoch   7 Batch  157/269 - Train Accuracy: 0.8451, Validation Accuracy: 0.8605, Loss: 0.2285\n",
      "Epoch   7 Batch  158/269 - Train Accuracy: 0.8682, Validation Accuracy: 0.8627, Loss: 0.2322\n",
      "Epoch   7 Batch  159/269 - Train Accuracy: 0.8508, Validation Accuracy: 0.8632, Loss: 0.2367\n",
      "Epoch   7 Batch  160/269 - Train Accuracy: 0.8674, Validation Accuracy: 0.8669, Loss: 0.2494\n",
      "Epoch   7 Batch  161/269 - Train Accuracy: 0.8648, Validation Accuracy: 0.8642, Loss: 0.2327\n",
      "Epoch   7 Batch  162/269 - Train Accuracy: 0.8692, Validation Accuracy: 0.8644, Loss: 0.2276\n",
      "Epoch   7 Batch  163/269 - Train Accuracy: 0.8627, Validation Accuracy: 0.8682, Loss: 0.2363\n",
      "Epoch   7 Batch  164/269 - Train Accuracy: 0.8705, Validation Accuracy: 0.8706, Loss: 0.2324\n",
      "Epoch   7 Batch  165/269 - Train Accuracy: 0.8671, Validation Accuracy: 0.8668, Loss: 0.2393\n",
      "Epoch   7 Batch  166/269 - Train Accuracy: 0.8630, Validation Accuracy: 0.8682, Loss: 0.2297\n",
      "Epoch   7 Batch  167/269 - Train Accuracy: 0.8717, Validation Accuracy: 0.8655, Loss: 0.2369\n",
      "Epoch   7 Batch  168/269 - Train Accuracy: 0.8622, Validation Accuracy: 0.8677, Loss: 0.2397\n",
      "Epoch   7 Batch  169/269 - Train Accuracy: 0.8609, Validation Accuracy: 0.8708, Loss: 0.2393\n",
      "Epoch   7 Batch  170/269 - Train Accuracy: 0.8540, Validation Accuracy: 0.8730, Loss: 0.2317\n",
      "Epoch   7 Batch  171/269 - Train Accuracy: 0.8862, Validation Accuracy: 0.8674, Loss: 0.2381\n",
      "Epoch   7 Batch  172/269 - Train Accuracy: 0.8449, Validation Accuracy: 0.8669, Loss: 0.2453\n",
      "Epoch   7 Batch  173/269 - Train Accuracy: 0.8700, Validation Accuracy: 0.8742, Loss: 0.2285\n",
      "Epoch   7 Batch  174/269 - Train Accuracy: 0.8760, Validation Accuracy: 0.8615, Loss: 0.2341\n",
      "Epoch   7 Batch  175/269 - Train Accuracy: 0.8629, Validation Accuracy: 0.8751, Loss: 0.2448\n",
      "Epoch   7 Batch  176/269 - Train Accuracy: 0.8409, Validation Accuracy: 0.8695, Loss: 0.2475\n",
      "Epoch   7 Batch  177/269 - Train Accuracy: 0.8732, Validation Accuracy: 0.8551, Loss: 0.2317\n",
      "Epoch   7 Batch  178/269 - Train Accuracy: 0.8615, Validation Accuracy: 0.8625, Loss: 0.2330\n",
      "Epoch   7 Batch  179/269 - Train Accuracy: 0.8467, Validation Accuracy: 0.8630, Loss: 0.2270\n",
      "Epoch   7 Batch  180/269 - Train Accuracy: 0.8623, Validation Accuracy: 0.8724, Loss: 0.2241\n",
      "Epoch   7 Batch  181/269 - Train Accuracy: 0.8531, Validation Accuracy: 0.8686, Loss: 0.2416\n",
      "Epoch   7 Batch  182/269 - Train Accuracy: 0.8655, Validation Accuracy: 0.8677, Loss: 0.2323\n",
      "Epoch   7 Batch  183/269 - Train Accuracy: 0.8882, Validation Accuracy: 0.8649, Loss: 0.1976\n",
      "Epoch   7 Batch  184/269 - Train Accuracy: 0.8565, Validation Accuracy: 0.8660, Loss: 0.2395\n",
      "Epoch   7 Batch  185/269 - Train Accuracy: 0.8844, Validation Accuracy: 0.8737, Loss: 0.2228\n",
      "Epoch   7 Batch  186/269 - Train Accuracy: 0.8599, Validation Accuracy: 0.8673, Loss: 0.2265\n",
      "Epoch   7 Batch  187/269 - Train Accuracy: 0.8700, Validation Accuracy: 0.8689, Loss: 0.2206\n",
      "Epoch   7 Batch  188/269 - Train Accuracy: 0.8788, Validation Accuracy: 0.8734, Loss: 0.2180\n",
      "Epoch   7 Batch  189/269 - Train Accuracy: 0.8762, Validation Accuracy: 0.8715, Loss: 0.2197\n",
      "Epoch   7 Batch  190/269 - Train Accuracy: 0.8730, Validation Accuracy: 0.8728, Loss: 0.2170\n",
      "Epoch   7 Batch  191/269 - Train Accuracy: 0.8576, Validation Accuracy: 0.8678, Loss: 0.2215\n",
      "Epoch   7 Batch  192/269 - Train Accuracy: 0.8703, Validation Accuracy: 0.8714, Loss: 0.2317\n",
      "Epoch   7 Batch  193/269 - Train Accuracy: 0.8835, Validation Accuracy: 0.8703, Loss: 0.2172\n",
      "Epoch   7 Batch  194/269 - Train Accuracy: 0.8590, Validation Accuracy: 0.8746, Loss: 0.2328\n",
      "Epoch   7 Batch  195/269 - Train Accuracy: 0.8598, Validation Accuracy: 0.8786, Loss: 0.2329\n",
      "Epoch   7 Batch  196/269 - Train Accuracy: 0.8682, Validation Accuracy: 0.8709, Loss: 0.2225\n",
      "Epoch   7 Batch  197/269 - Train Accuracy: 0.8621, Validation Accuracy: 0.8726, Loss: 0.2431\n",
      "Epoch   7 Batch  198/269 - Train Accuracy: 0.8545, Validation Accuracy: 0.8719, Loss: 0.2419\n",
      "Epoch   7 Batch  199/269 - Train Accuracy: 0.8532, Validation Accuracy: 0.8700, Loss: 0.2366\n",
      "Epoch   7 Batch  200/269 - Train Accuracy: 0.8578, Validation Accuracy: 0.8716, Loss: 0.2372\n",
      "Epoch   7 Batch  201/269 - Train Accuracy: 0.8521, Validation Accuracy: 0.8665, Loss: 0.2214\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch   7 Batch  202/269 - Train Accuracy: 0.8542, Validation Accuracy: 0.8723, Loss: 0.2384\n",
      "Epoch   7 Batch  203/269 - Train Accuracy: 0.8572, Validation Accuracy: 0.8634, Loss: 0.2422\n",
      "Epoch   7 Batch  204/269 - Train Accuracy: 0.8695, Validation Accuracy: 0.8721, Loss: 0.2457\n",
      "Epoch   7 Batch  205/269 - Train Accuracy: 0.8751, Validation Accuracy: 0.8706, Loss: 0.2200\n",
      "Epoch   7 Batch  206/269 - Train Accuracy: 0.8512, Validation Accuracy: 0.8706, Loss: 0.2498\n",
      "Epoch   7 Batch  207/269 - Train Accuracy: 0.8608, Validation Accuracy: 0.8651, Loss: 0.2149\n",
      "Epoch   7 Batch  208/269 - Train Accuracy: 0.8689, Validation Accuracy: 0.8726, Loss: 0.2406\n",
      "Epoch   7 Batch  209/269 - Train Accuracy: 0.8832, Validation Accuracy: 0.8707, Loss: 0.2266\n",
      "Epoch   7 Batch  210/269 - Train Accuracy: 0.8725, Validation Accuracy: 0.8706, Loss: 0.2226\n",
      "Epoch   7 Batch  211/269 - Train Accuracy: 0.8677, Validation Accuracy: 0.8574, Loss: 0.2267\n",
      "Epoch   7 Batch  212/269 - Train Accuracy: 0.8704, Validation Accuracy: 0.8620, Loss: 0.2363\n",
      "Epoch   7 Batch  213/269 - Train Accuracy: 0.8664, Validation Accuracy: 0.8736, Loss: 0.2245\n",
      "Epoch   7 Batch  214/269 - Train Accuracy: 0.8454, Validation Accuracy: 0.8731, Loss: 0.2319\n",
      "Epoch   7 Batch  215/269 - Train Accuracy: 0.8797, Validation Accuracy: 0.8743, Loss: 0.2104\n",
      "Epoch   7 Batch  216/269 - Train Accuracy: 0.8413, Validation Accuracy: 0.8750, Loss: 0.2542\n",
      "Epoch   7 Batch  217/269 - Train Accuracy: 0.8648, Validation Accuracy: 0.8763, Loss: 0.2349\n",
      "Epoch   7 Batch  218/269 - Train Accuracy: 0.8830, Validation Accuracy: 0.8761, Loss: 0.2268\n",
      "Epoch   7 Batch  219/269 - Train Accuracy: 0.8789, Validation Accuracy: 0.8751, Loss: 0.2394\n",
      "Epoch   7 Batch  220/269 - Train Accuracy: 0.8817, Validation Accuracy: 0.8672, Loss: 0.2102\n",
      "Epoch   7 Batch  221/269 - Train Accuracy: 0.8795, Validation Accuracy: 0.8746, Loss: 0.2329\n",
      "Epoch   7 Batch  222/269 - Train Accuracy: 0.8820, Validation Accuracy: 0.8708, Loss: 0.2154\n",
      "Epoch   7 Batch  223/269 - Train Accuracy: 0.8711, Validation Accuracy: 0.8748, Loss: 0.2136\n",
      "Epoch   7 Batch  224/269 - Train Accuracy: 0.8642, Validation Accuracy: 0.8666, Loss: 0.2286\n",
      "Epoch   7 Batch  225/269 - Train Accuracy: 0.8643, Validation Accuracy: 0.8745, Loss: 0.2205\n",
      "Epoch   7 Batch  226/269 - Train Accuracy: 0.8778, Validation Accuracy: 0.8678, Loss: 0.2252\n",
      "Epoch   7 Batch  227/269 - Train Accuracy: 0.8868, Validation Accuracy: 0.8718, Loss: 0.2153\n",
      "Epoch   7 Batch  228/269 - Train Accuracy: 0.8635, Validation Accuracy: 0.8681, Loss: 0.2194\n",
      "Epoch   7 Batch  229/269 - Train Accuracy: 0.8679, Validation Accuracy: 0.8669, Loss: 0.2187\n",
      "Epoch   7 Batch  230/269 - Train Accuracy: 0.8632, Validation Accuracy: 0.8652, Loss: 0.2178\n",
      "Epoch   7 Batch  231/269 - Train Accuracy: 0.8718, Validation Accuracy: 0.8747, Loss: 0.2356\n",
      "Epoch   7 Batch  232/269 - Train Accuracy: 0.8592, Validation Accuracy: 0.8767, Loss: 0.2278\n",
      "Epoch   7 Batch  233/269 - Train Accuracy: 0.8904, Validation Accuracy: 0.8756, Loss: 0.2323\n",
      "Epoch   7 Batch  234/269 - Train Accuracy: 0.8726, Validation Accuracy: 0.8667, Loss: 0.2213\n",
      "Epoch   7 Batch  235/269 - Train Accuracy: 0.8740, Validation Accuracy: 0.8708, Loss: 0.2154\n",
      "Epoch   7 Batch  236/269 - Train Accuracy: 0.8654, Validation Accuracy: 0.8680, Loss: 0.2100\n",
      "Epoch   7 Batch  237/269 - Train Accuracy: 0.8624, Validation Accuracy: 0.8691, Loss: 0.2163\n",
      "Epoch   7 Batch  238/269 - Train Accuracy: 0.8660, Validation Accuracy: 0.8746, Loss: 0.2230\n",
      "Epoch   7 Batch  239/269 - Train Accuracy: 0.8649, Validation Accuracy: 0.8650, Loss: 0.2247\n",
      "Epoch   7 Batch  240/269 - Train Accuracy: 0.8758, Validation Accuracy: 0.8652, Loss: 0.2017\n",
      "Epoch   7 Batch  241/269 - Train Accuracy: 0.8537, Validation Accuracy: 0.8724, Loss: 0.2439\n",
      "Epoch   7 Batch  242/269 - Train Accuracy: 0.8762, Validation Accuracy: 0.8717, Loss: 0.2118\n",
      "Epoch   7 Batch  243/269 - Train Accuracy: 0.8761, Validation Accuracy: 0.8684, Loss: 0.2096\n",
      "Epoch   7 Batch  244/269 - Train Accuracy: 0.8689, Validation Accuracy: 0.8777, Loss: 0.2250\n",
      "Epoch   7 Batch  245/269 - Train Accuracy: 0.8476, Validation Accuracy: 0.8717, Loss: 0.2335\n",
      "Epoch   7 Batch  246/269 - Train Accuracy: 0.8552, Validation Accuracy: 0.8701, Loss: 0.2267\n",
      "Epoch   7 Batch  247/269 - Train Accuracy: 0.8814, Validation Accuracy: 0.8738, Loss: 0.2296\n",
      "Epoch   7 Batch  248/269 - Train Accuracy: 0.8797, Validation Accuracy: 0.8721, Loss: 0.2170\n",
      "Epoch   7 Batch  249/269 - Train Accuracy: 0.8845, Validation Accuracy: 0.8714, Loss: 0.2112\n",
      "Epoch   7 Batch  250/269 - Train Accuracy: 0.8819, Validation Accuracy: 0.8605, Loss: 0.2243\n",
      "Epoch   7 Batch  251/269 - Train Accuracy: 0.9005, Validation Accuracy: 0.8676, Loss: 0.2173\n",
      "Epoch   7 Batch  252/269 - Train Accuracy: 0.8609, Validation Accuracy: 0.8736, Loss: 0.2162\n",
      "Epoch   7 Batch  253/269 - Train Accuracy: 0.8484, Validation Accuracy: 0.8685, Loss: 0.2273\n",
      "Epoch   7 Batch  254/269 - Train Accuracy: 0.8716, Validation Accuracy: 0.8776, Loss: 0.2170\n",
      "Epoch   7 Batch  255/269 - Train Accuracy: 0.8759, Validation Accuracy: 0.8784, Loss: 0.2194\n",
      "Epoch   7 Batch  256/269 - Train Accuracy: 0.8608, Validation Accuracy: 0.8797, Loss: 0.2208\n",
      "Epoch   7 Batch  257/269 - Train Accuracy: 0.8424, Validation Accuracy: 0.8741, Loss: 0.2346\n",
      "Epoch   7 Batch  258/269 - Train Accuracy: 0.8664, Validation Accuracy: 0.8770, Loss: 0.2250\n",
      "Epoch   7 Batch  259/269 - Train Accuracy: 0.8716, Validation Accuracy: 0.8763, Loss: 0.2257\n",
      "Epoch   7 Batch  260/269 - Train Accuracy: 0.8570, Validation Accuracy: 0.8751, Loss: 0.2317\n",
      "Epoch   7 Batch  261/269 - Train Accuracy: 0.8597, Validation Accuracy: 0.8716, Loss: 0.2249\n",
      "Epoch   7 Batch  262/269 - Train Accuracy: 0.8766, Validation Accuracy: 0.8730, Loss: 0.2152\n",
      "Epoch   7 Batch  263/269 - Train Accuracy: 0.8662, Validation Accuracy: 0.8785, Loss: 0.2245\n",
      "Epoch   7 Batch  264/269 - Train Accuracy: 0.8474, Validation Accuracy: 0.8810, Loss: 0.2269\n",
      "Epoch   7 Batch  265/269 - Train Accuracy: 0.8786, Validation Accuracy: 0.8701, Loss: 0.2240\n",
      "Epoch   7 Batch  266/269 - Train Accuracy: 0.8776, Validation Accuracy: 0.8779, Loss: 0.2158\n",
      "Epoch   7 Batch  267/269 - Train Accuracy: 0.8770, Validation Accuracy: 0.8835, Loss: 0.2226\n",
      "Epoch   8 Batch    1/269 - Train Accuracy: 0.8811, Validation Accuracy: 0.8699, Loss: 0.2141\n",
      "Epoch   8 Batch    2/269 - Train Accuracy: 0.8648, Validation Accuracy: 0.8746, Loss: 0.2209\n",
      "Epoch   8 Batch    3/269 - Train Accuracy: 0.8709, Validation Accuracy: 0.8658, Loss: 0.2141\n",
      "Epoch   8 Batch    4/269 - Train Accuracy: 0.8631, Validation Accuracy: 0.8796, Loss: 0.2196\n",
      "Epoch   8 Batch    5/269 - Train Accuracy: 0.8637, Validation Accuracy: 0.8691, Loss: 0.2120\n",
      "Epoch   8 Batch    6/269 - Train Accuracy: 0.8922, Validation Accuracy: 0.8744, Loss: 0.2047\n",
      "Epoch   8 Batch    7/269 - Train Accuracy: 0.8786, Validation Accuracy: 0.8762, Loss: 0.2073\n",
      "Epoch   8 Batch    8/269 - Train Accuracy: 0.8874, Validation Accuracy: 0.8836, Loss: 0.2222\n",
      "Epoch   8 Batch    9/269 - Train Accuracy: 0.8650, Validation Accuracy: 0.8701, Loss: 0.2190\n",
      "Epoch   8 Batch   10/269 - Train Accuracy: 0.8936, Validation Accuracy: 0.8770, Loss: 0.2069\n",
      "Epoch   8 Batch   11/269 - Train Accuracy: 0.8759, Validation Accuracy: 0.8769, Loss: 0.2186\n",
      "Epoch   8 Batch   12/269 - Train Accuracy: 0.8636, Validation Accuracy: 0.8758, Loss: 0.2202\n",
      "Epoch   8 Batch   13/269 - Train Accuracy: 0.8749, Validation Accuracy: 0.8766, Loss: 0.1930\n",
      "Epoch   8 Batch   14/269 - Train Accuracy: 0.8651, Validation Accuracy: 0.8748, Loss: 0.2088\n",
      "Epoch   8 Batch   15/269 - Train Accuracy: 0.8803, Validation Accuracy: 0.8805, Loss: 0.2066\n",
      "Epoch   8 Batch   16/269 - Train Accuracy: 0.8671, Validation Accuracy: 0.8796, Loss: 0.2143\n",
      "Epoch   8 Batch   17/269 - Train Accuracy: 0.8749, Validation Accuracy: 0.8745, Loss: 0.2034\n",
      "Epoch   8 Batch   18/269 - Train Accuracy: 0.8722, Validation Accuracy: 0.8780, Loss: 0.2150\n",
      "Epoch   8 Batch   19/269 - Train Accuracy: 0.8803, Validation Accuracy: 0.8837, Loss: 0.1938\n",
      "Epoch   8 Batch   20/269 - Train Accuracy: 0.8680, Validation Accuracy: 0.8737, Loss: 0.2167\n",
      "Epoch   8 Batch   21/269 - Train Accuracy: 0.8586, Validation Accuracy: 0.8811, Loss: 0.2369\n",
      "Epoch   8 Batch   22/269 - Train Accuracy: 0.8913, Validation Accuracy: 0.8814, Loss: 0.2043\n",
      "Epoch   8 Batch   23/269 - Train Accuracy: 0.8813, Validation Accuracy: 0.8849, Loss: 0.2132\n",
      "Epoch   8 Batch   24/269 - Train Accuracy: 0.8774, Validation Accuracy: 0.8794, Loss: 0.2157\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch   8 Batch   25/269 - Train Accuracy: 0.8723, Validation Accuracy: 0.8865, Loss: 0.2251\n",
      "Epoch   8 Batch   26/269 - Train Accuracy: 0.8873, Validation Accuracy: 0.8824, Loss: 0.1903\n",
      "Epoch   8 Batch   27/269 - Train Accuracy: 0.8783, Validation Accuracy: 0.8898, Loss: 0.2042\n",
      "Epoch   8 Batch   28/269 - Train Accuracy: 0.8403, Validation Accuracy: 0.8799, Loss: 0.2208\n",
      "Epoch   8 Batch   29/269 - Train Accuracy: 0.8908, Validation Accuracy: 0.8857, Loss: 0.2210\n",
      "Epoch   8 Batch   30/269 - Train Accuracy: 0.8703, Validation Accuracy: 0.8823, Loss: 0.2033\n",
      "Epoch   8 Batch   31/269 - Train Accuracy: 0.8744, Validation Accuracy: 0.8814, Loss: 0.1931\n",
      "Epoch   8 Batch   32/269 - Train Accuracy: 0.8810, Validation Accuracy: 0.8844, Loss: 0.1990\n",
      "Epoch   8 Batch   33/269 - Train Accuracy: 0.8717, Validation Accuracy: 0.8771, Loss: 0.1913\n",
      "Epoch   8 Batch   34/269 - Train Accuracy: 0.8708, Validation Accuracy: 0.8817, Loss: 0.2055\n",
      "Epoch   8 Batch   35/269 - Train Accuracy: 0.8749, Validation Accuracy: 0.8820, Loss: 0.2123\n",
      "Epoch   8 Batch   36/269 - Train Accuracy: 0.8671, Validation Accuracy: 0.8857, Loss: 0.2112\n",
      "Epoch   8 Batch   37/269 - Train Accuracy: 0.8701, Validation Accuracy: 0.8801, Loss: 0.2055\n",
      "Epoch   8 Batch   38/269 - Train Accuracy: 0.8863, Validation Accuracy: 0.8868, Loss: 0.2052\n",
      "Epoch   8 Batch   39/269 - Train Accuracy: 0.8615, Validation Accuracy: 0.8837, Loss: 0.2053\n",
      "Epoch   8 Batch   40/269 - Train Accuracy: 0.8621, Validation Accuracy: 0.8865, Loss: 0.2157\n",
      "Epoch   8 Batch   41/269 - Train Accuracy: 0.8569, Validation Accuracy: 0.8860, Loss: 0.2017\n",
      "Epoch   8 Batch   42/269 - Train Accuracy: 0.8932, Validation Accuracy: 0.8901, Loss: 0.1853\n",
      "Epoch   8 Batch   43/269 - Train Accuracy: 0.8729, Validation Accuracy: 0.8817, Loss: 0.2063\n",
      "Epoch   8 Batch   44/269 - Train Accuracy: 0.8686, Validation Accuracy: 0.8884, Loss: 0.2037\n",
      "Epoch   8 Batch   45/269 - Train Accuracy: 0.8732, Validation Accuracy: 0.8865, Loss: 0.2040\n",
      "Epoch   8 Batch   46/269 - Train Accuracy: 0.8824, Validation Accuracy: 0.8857, Loss: 0.2072\n",
      "Epoch   8 Batch   47/269 - Train Accuracy: 0.8784, Validation Accuracy: 0.8819, Loss: 0.1901\n",
      "Epoch   8 Batch   48/269 - Train Accuracy: 0.8889, Validation Accuracy: 0.8819, Loss: 0.1971\n",
      "Epoch   8 Batch   49/269 - Train Accuracy: 0.8807, Validation Accuracy: 0.8854, Loss: 0.2036\n",
      "Epoch   8 Batch   50/269 - Train Accuracy: 0.8567, Validation Accuracy: 0.8883, Loss: 0.2194\n",
      "Epoch   8 Batch   51/269 - Train Accuracy: 0.8841, Validation Accuracy: 0.8843, Loss: 0.1965\n",
      "Epoch   8 Batch   52/269 - Train Accuracy: 0.8757, Validation Accuracy: 0.8892, Loss: 0.1909\n",
      "Epoch   8 Batch   53/269 - Train Accuracy: 0.8717, Validation Accuracy: 0.8845, Loss: 0.2183\n",
      "Epoch   8 Batch   54/269 - Train Accuracy: 0.8883, Validation Accuracy: 0.8825, Loss: 0.2065\n",
      "Epoch   8 Batch   55/269 - Train Accuracy: 0.8936, Validation Accuracy: 0.8867, Loss: 0.1985\n",
      "Epoch   8 Batch   56/269 - Train Accuracy: 0.8737, Validation Accuracy: 0.8816, Loss: 0.2059\n",
      "Epoch   8 Batch   57/269 - Train Accuracy: 0.8719, Validation Accuracy: 0.8852, Loss: 0.2185\n",
      "Epoch   8 Batch   58/269 - Train Accuracy: 0.8810, Validation Accuracy: 0.8912, Loss: 0.2048\n",
      "Epoch   8 Batch   59/269 - Train Accuracy: 0.8880, Validation Accuracy: 0.8865, Loss: 0.1870\n",
      "Epoch   8 Batch   60/269 - Train Accuracy: 0.8854, Validation Accuracy: 0.8921, Loss: 0.1975\n",
      "Epoch   8 Batch   61/269 - Train Accuracy: 0.8935, Validation Accuracy: 0.8926, Loss: 0.1914\n",
      "Epoch   8 Batch   62/269 - Train Accuracy: 0.8791, Validation Accuracy: 0.8867, Loss: 0.1971\n",
      "Epoch   8 Batch   63/269 - Train Accuracy: 0.8750, Validation Accuracy: 0.8936, Loss: 0.2102\n",
      "Epoch   8 Batch   64/269 - Train Accuracy: 0.8872, Validation Accuracy: 0.8896, Loss: 0.1903\n",
      "Epoch   8 Batch   65/269 - Train Accuracy: 0.8557, Validation Accuracy: 0.8904, Loss: 0.2045\n",
      "Epoch   8 Batch   66/269 - Train Accuracy: 0.8720, Validation Accuracy: 0.8838, Loss: 0.2004\n",
      "Epoch   8 Batch   67/269 - Train Accuracy: 0.8894, Validation Accuracy: 0.8823, Loss: 0.2076\n",
      "Epoch   8 Batch   68/269 - Train Accuracy: 0.8608, Validation Accuracy: 0.8904, Loss: 0.2172\n",
      "Epoch   8 Batch   69/269 - Train Accuracy: 0.8518, Validation Accuracy: 0.8801, Loss: 0.2251\n",
      "Epoch   8 Batch   70/269 - Train Accuracy: 0.8809, Validation Accuracy: 0.8883, Loss: 0.2087\n",
      "Epoch   8 Batch   71/269 - Train Accuracy: 0.8817, Validation Accuracy: 0.8931, Loss: 0.2118\n",
      "Epoch   8 Batch   72/269 - Train Accuracy: 0.8659, Validation Accuracy: 0.8901, Loss: 0.2145\n",
      "Epoch   8 Batch   73/269 - Train Accuracy: 0.8683, Validation Accuracy: 0.8952, Loss: 0.2113\n",
      "Epoch   8 Batch   74/269 - Train Accuracy: 0.8809, Validation Accuracy: 0.8817, Loss: 0.1971\n",
      "Epoch   8 Batch   75/269 - Train Accuracy: 0.8837, Validation Accuracy: 0.8769, Loss: 0.2044\n",
      "Epoch   8 Batch   76/269 - Train Accuracy: 0.8505, Validation Accuracy: 0.8770, Loss: 0.1958\n",
      "Epoch   8 Batch   77/269 - Train Accuracy: 0.8770, Validation Accuracy: 0.8760, Loss: 0.1983\n",
      "Epoch   8 Batch   78/269 - Train Accuracy: 0.8837, Validation Accuracy: 0.8867, Loss: 0.1940\n",
      "Epoch   8 Batch   79/269 - Train Accuracy: 0.8737, Validation Accuracy: 0.8835, Loss: 0.1969\n",
      "Epoch   8 Batch   80/269 - Train Accuracy: 0.8836, Validation Accuracy: 0.8736, Loss: 0.1919\n",
      "Epoch   8 Batch   81/269 - Train Accuracy: 0.8707, Validation Accuracy: 0.8825, Loss: 0.2122\n",
      "Epoch   8 Batch   82/269 - Train Accuracy: 0.8920, Validation Accuracy: 0.8790, Loss: 0.1882\n",
      "Epoch   8 Batch   83/269 - Train Accuracy: 0.8619, Validation Accuracy: 0.8822, Loss: 0.2112\n",
      "Epoch   8 Batch   84/269 - Train Accuracy: 0.8756, Validation Accuracy: 0.8746, Loss: 0.1942\n",
      "Epoch   8 Batch   85/269 - Train Accuracy: 0.8870, Validation Accuracy: 0.8796, Loss: 0.1966\n",
      "Epoch   8 Batch   86/269 - Train Accuracy: 0.8680, Validation Accuracy: 0.8780, Loss: 0.1888\n",
      "Epoch   8 Batch   87/269 - Train Accuracy: 0.8556, Validation Accuracy: 0.8737, Loss: 0.2098\n",
      "Epoch   8 Batch   88/269 - Train Accuracy: 0.8622, Validation Accuracy: 0.8781, Loss: 0.2034\n",
      "Epoch   8 Batch   89/269 - Train Accuracy: 0.8902, Validation Accuracy: 0.8758, Loss: 0.1970\n",
      "Epoch   8 Batch   90/269 - Train Accuracy: 0.8690, Validation Accuracy: 0.8848, Loss: 0.2083\n",
      "Epoch   8 Batch   91/269 - Train Accuracy: 0.8938, Validation Accuracy: 0.8813, Loss: 0.1887\n",
      "Epoch   8 Batch   92/269 - Train Accuracy: 0.8989, Validation Accuracy: 0.8850, Loss: 0.1891\n",
      "Epoch   8 Batch   93/269 - Train Accuracy: 0.8841, Validation Accuracy: 0.8791, Loss: 0.1843\n",
      "Epoch   8 Batch   94/269 - Train Accuracy: 0.8760, Validation Accuracy: 0.8809, Loss: 0.2102\n",
      "Epoch   8 Batch   95/269 - Train Accuracy: 0.8936, Validation Accuracy: 0.8847, Loss: 0.1875\n",
      "Epoch   8 Batch   96/269 - Train Accuracy: 0.8698, Validation Accuracy: 0.8825, Loss: 0.2005\n",
      "Epoch   8 Batch   97/269 - Train Accuracy: 0.8766, Validation Accuracy: 0.8795, Loss: 0.1969\n",
      "Epoch   8 Batch   98/269 - Train Accuracy: 0.8794, Validation Accuracy: 0.8769, Loss: 0.1976\n",
      "Epoch   8 Batch   99/269 - Train Accuracy: 0.8717, Validation Accuracy: 0.8871, Loss: 0.2001\n",
      "Epoch   8 Batch  100/269 - Train Accuracy: 0.8955, Validation Accuracy: 0.8815, Loss: 0.1916\n",
      "Epoch   8 Batch  101/269 - Train Accuracy: 0.8675, Validation Accuracy: 0.8853, Loss: 0.2196\n",
      "Epoch   8 Batch  102/269 - Train Accuracy: 0.8801, Validation Accuracy: 0.8831, Loss: 0.1899\n",
      "Epoch   8 Batch  103/269 - Train Accuracy: 0.8828, Validation Accuracy: 0.8785, Loss: 0.2059\n",
      "Epoch   8 Batch  104/269 - Train Accuracy: 0.8851, Validation Accuracy: 0.8818, Loss: 0.1884\n",
      "Epoch   8 Batch  105/269 - Train Accuracy: 0.8740, Validation Accuracy: 0.8826, Loss: 0.1888\n",
      "Epoch   8 Batch  106/269 - Train Accuracy: 0.8773, Validation Accuracy: 0.8839, Loss: 0.1955\n",
      "Epoch   8 Batch  107/269 - Train Accuracy: 0.8843, Validation Accuracy: 0.8853, Loss: 0.1985\n",
      "Epoch   8 Batch  108/269 - Train Accuracy: 0.8854, Validation Accuracy: 0.8870, Loss: 0.2051\n",
      "Epoch   8 Batch  109/269 - Train Accuracy: 0.8646, Validation Accuracy: 0.8857, Loss: 0.1968\n",
      "Epoch   8 Batch  110/269 - Train Accuracy: 0.8928, Validation Accuracy: 0.8860, Loss: 0.1873\n",
      "Epoch   8 Batch  111/269 - Train Accuracy: 0.8656, Validation Accuracy: 0.8831, Loss: 0.2176\n",
      "Epoch   8 Batch  112/269 - Train Accuracy: 0.8918, Validation Accuracy: 0.8895, Loss: 0.1905\n",
      "Epoch   8 Batch  113/269 - Train Accuracy: 0.8754, Validation Accuracy: 0.8871, Loss: 0.1823\n",
      "Epoch   8 Batch  114/269 - Train Accuracy: 0.8848, Validation Accuracy: 0.8790, Loss: 0.1938\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch   8 Batch  115/269 - Train Accuracy: 0.8674, Validation Accuracy: 0.8729, Loss: 0.1950\n",
      "Epoch   8 Batch  116/269 - Train Accuracy: 0.8863, Validation Accuracy: 0.8771, Loss: 0.1961\n",
      "Epoch   8 Batch  117/269 - Train Accuracy: 0.8687, Validation Accuracy: 0.8843, Loss: 0.1897\n",
      "Epoch   8 Batch  118/269 - Train Accuracy: 0.8936, Validation Accuracy: 0.8878, Loss: 0.1810\n",
      "Epoch   8 Batch  119/269 - Train Accuracy: 0.8643, Validation Accuracy: 0.8819, Loss: 0.2042\n",
      "Epoch   8 Batch  120/269 - Train Accuracy: 0.8914, Validation Accuracy: 0.8851, Loss: 0.1945\n",
      "Epoch   8 Batch  121/269 - Train Accuracy: 0.8848, Validation Accuracy: 0.8921, Loss: 0.1842\n",
      "Epoch   8 Batch  122/269 - Train Accuracy: 0.8783, Validation Accuracy: 0.8859, Loss: 0.1851\n",
      "Epoch   8 Batch  123/269 - Train Accuracy: 0.8820, Validation Accuracy: 0.8829, Loss: 0.2009\n",
      "Epoch   8 Batch  124/269 - Train Accuracy: 0.8718, Validation Accuracy: 0.8838, Loss: 0.1802\n",
      "Epoch   8 Batch  125/269 - Train Accuracy: 0.8911, Validation Accuracy: 0.8875, Loss: 0.1849\n",
      "Epoch   8 Batch  126/269 - Train Accuracy: 0.8670, Validation Accuracy: 0.8831, Loss: 0.1852\n",
      "Epoch   8 Batch  127/269 - Train Accuracy: 0.8715, Validation Accuracy: 0.8838, Loss: 0.1969\n",
      "Epoch   8 Batch  128/269 - Train Accuracy: 0.8853, Validation Accuracy: 0.8817, Loss: 0.1941\n",
      "Epoch   8 Batch  129/269 - Train Accuracy: 0.8699, Validation Accuracy: 0.8838, Loss: 0.1932\n",
      "Epoch   8 Batch  130/269 - Train Accuracy: 0.8811, Validation Accuracy: 0.8841, Loss: 0.1972\n",
      "Epoch   8 Batch  131/269 - Train Accuracy: 0.8611, Validation Accuracy: 0.8767, Loss: 0.1949\n",
      "Epoch   8 Batch  132/269 - Train Accuracy: 0.8700, Validation Accuracy: 0.8848, Loss: 0.1951\n",
      "Epoch   8 Batch  133/269 - Train Accuracy: 0.8842, Validation Accuracy: 0.8887, Loss: 0.1789\n",
      "Epoch   8 Batch  134/269 - Train Accuracy: 0.8616, Validation Accuracy: 0.8860, Loss: 0.1911\n",
      "Epoch   8 Batch  135/269 - Train Accuracy: 0.8753, Validation Accuracy: 0.8927, Loss: 0.2043\n",
      "Epoch   8 Batch  136/269 - Train Accuracy: 0.8614, Validation Accuracy: 0.8888, Loss: 0.1981\n",
      "Epoch   8 Batch  137/269 - Train Accuracy: 0.8751, Validation Accuracy: 0.8985, Loss: 0.2040\n",
      "Epoch   8 Batch  138/269 - Train Accuracy: 0.8828, Validation Accuracy: 0.8893, Loss: 0.1825\n",
      "Epoch   8 Batch  139/269 - Train Accuracy: 0.8812, Validation Accuracy: 0.8958, Loss: 0.1805\n",
      "Epoch   8 Batch  140/269 - Train Accuracy: 0.8788, Validation Accuracy: 0.8979, Loss: 0.2022\n",
      "Epoch   8 Batch  141/269 - Train Accuracy: 0.8914, Validation Accuracy: 0.8967, Loss: 0.1954\n",
      "Epoch   8 Batch  142/269 - Train Accuracy: 0.8715, Validation Accuracy: 0.8748, Loss: 0.1876\n",
      "Epoch   8 Batch  143/269 - Train Accuracy: 0.8928, Validation Accuracy: 0.8865, Loss: 0.1890\n",
      "Epoch   8 Batch  144/269 - Train Accuracy: 0.8897, Validation Accuracy: 0.8931, Loss: 0.1758\n",
      "Epoch   8 Batch  145/269 - Train Accuracy: 0.8816, Validation Accuracy: 0.8935, Loss: 0.1781\n",
      "Epoch   8 Batch  146/269 - Train Accuracy: 0.8872, Validation Accuracy: 0.8845, Loss: 0.1857\n",
      "Epoch   8 Batch  147/269 - Train Accuracy: 0.8900, Validation Accuracy: 0.8845, Loss: 0.1877\n",
      "Epoch   8 Batch  148/269 - Train Accuracy: 0.8837, Validation Accuracy: 0.8893, Loss: 0.1893\n",
      "Epoch   8 Batch  149/269 - Train Accuracy: 0.8550, Validation Accuracy: 0.8888, Loss: 0.2027\n",
      "Epoch   8 Batch  150/269 - Train Accuracy: 0.8781, Validation Accuracy: 0.8918, Loss: 0.1844\n",
      "Epoch   8 Batch  151/269 - Train Accuracy: 0.8766, Validation Accuracy: 0.8916, Loss: 0.1836\n",
      "Epoch   8 Batch  152/269 - Train Accuracy: 0.8837, Validation Accuracy: 0.8910, Loss: 0.1922\n",
      "Epoch   8 Batch  153/269 - Train Accuracy: 0.8932, Validation Accuracy: 0.8837, Loss: 0.1867\n",
      "Epoch   8 Batch  154/269 - Train Accuracy: 0.8925, Validation Accuracy: 0.8888, Loss: 0.1864\n",
      "Epoch   8 Batch  155/269 - Train Accuracy: 0.8748, Validation Accuracy: 0.8950, Loss: 0.1712\n",
      "Epoch   8 Batch  156/269 - Train Accuracy: 0.8686, Validation Accuracy: 0.8911, Loss: 0.2006\n",
      "Epoch   8 Batch  157/269 - Train Accuracy: 0.8703, Validation Accuracy: 0.8890, Loss: 0.1843\n",
      "Epoch   8 Batch  158/269 - Train Accuracy: 0.8851, Validation Accuracy: 0.8881, Loss: 0.1866\n",
      "Epoch   8 Batch  159/269 - Train Accuracy: 0.8713, Validation Accuracy: 0.8902, Loss: 0.1898\n",
      "Epoch   8 Batch  160/269 - Train Accuracy: 0.8858, Validation Accuracy: 0.8896, Loss: 0.1892\n",
      "Epoch   8 Batch  161/269 - Train Accuracy: 0.8793, Validation Accuracy: 0.8973, Loss: 0.1841\n",
      "Epoch   8 Batch  162/269 - Train Accuracy: 0.9010, Validation Accuracy: 0.8888, Loss: 0.1729\n",
      "Epoch   8 Batch  163/269 - Train Accuracy: 0.8951, Validation Accuracy: 0.8861, Loss: 0.1829\n",
      "Epoch   8 Batch  164/269 - Train Accuracy: 0.8903, Validation Accuracy: 0.8912, Loss: 0.1793\n",
      "Epoch   8 Batch  165/269 - Train Accuracy: 0.8899, Validation Accuracy: 0.8928, Loss: 0.1864\n",
      "Epoch   8 Batch  166/269 - Train Accuracy: 0.8902, Validation Accuracy: 0.8858, Loss: 0.1774\n",
      "Epoch   8 Batch  167/269 - Train Accuracy: 0.8835, Validation Accuracy: 0.8809, Loss: 0.1849\n",
      "Epoch   8 Batch  168/269 - Train Accuracy: 0.8761, Validation Accuracy: 0.8924, Loss: 0.1893\n",
      "Epoch   8 Batch  169/269 - Train Accuracy: 0.8829, Validation Accuracy: 0.8962, Loss: 0.1825\n",
      "Epoch   8 Batch  170/269 - Train Accuracy: 0.8740, Validation Accuracy: 0.8841, Loss: 0.1825\n",
      "Epoch   8 Batch  171/269 - Train Accuracy: 0.9036, Validation Accuracy: 0.8808, Loss: 0.1861\n",
      "Epoch   8 Batch  172/269 - Train Accuracy: 0.8742, Validation Accuracy: 0.8827, Loss: 0.1907\n",
      "Epoch   8 Batch  173/269 - Train Accuracy: 0.8956, Validation Accuracy: 0.8890, Loss: 0.1742\n",
      "Epoch   8 Batch  174/269 - Train Accuracy: 0.8956, Validation Accuracy: 0.8782, Loss: 0.1821\n",
      "Epoch   8 Batch  175/269 - Train Accuracy: 0.8818, Validation Accuracy: 0.8788, Loss: 0.1974\n",
      "Epoch   8 Batch  176/269 - Train Accuracy: 0.8608, Validation Accuracy: 0.8902, Loss: 0.1929\n",
      "Epoch   8 Batch  177/269 - Train Accuracy: 0.8870, Validation Accuracy: 0.8889, Loss: 0.1752\n",
      "Epoch   8 Batch  178/269 - Train Accuracy: 0.8917, Validation Accuracy: 0.8856, Loss: 0.1865\n",
      "Epoch   8 Batch  179/269 - Train Accuracy: 0.8560, Validation Accuracy: 0.8819, Loss: 0.1750\n",
      "Epoch   8 Batch  180/269 - Train Accuracy: 0.8943, Validation Accuracy: 0.8892, Loss: 0.1721\n",
      "Epoch   8 Batch  181/269 - Train Accuracy: 0.8792, Validation Accuracy: 0.8892, Loss: 0.1914\n",
      "Epoch   8 Batch  182/269 - Train Accuracy: 0.8843, Validation Accuracy: 0.8883, Loss: 0.1783\n",
      "Epoch   8 Batch  183/269 - Train Accuracy: 0.8996, Validation Accuracy: 0.8819, Loss: 0.1529\n",
      "Epoch   8 Batch  184/269 - Train Accuracy: 0.8846, Validation Accuracy: 0.8854, Loss: 0.1820\n",
      "Epoch   8 Batch  185/269 - Train Accuracy: 0.8955, Validation Accuracy: 0.8907, Loss: 0.1747\n",
      "Epoch   8 Batch  186/269 - Train Accuracy: 0.8800, Validation Accuracy: 0.8915, Loss: 0.1781\n",
      "Epoch   8 Batch  187/269 - Train Accuracy: 0.8822, Validation Accuracy: 0.8924, Loss: 0.1710\n",
      "Epoch   8 Batch  188/269 - Train Accuracy: 0.8940, Validation Accuracy: 0.8869, Loss: 0.1685\n",
      "Epoch   8 Batch  189/269 - Train Accuracy: 0.8876, Validation Accuracy: 0.8928, Loss: 0.1716\n",
      "Epoch   8 Batch  190/269 - Train Accuracy: 0.8896, Validation Accuracy: 0.8851, Loss: 0.1664\n",
      "Epoch   8 Batch  191/269 - Train Accuracy: 0.8662, Validation Accuracy: 0.8829, Loss: 0.1756\n",
      "Epoch   8 Batch  192/269 - Train Accuracy: 0.8910, Validation Accuracy: 0.8875, Loss: 0.1792\n",
      "Epoch   8 Batch  193/269 - Train Accuracy: 0.9050, Validation Accuracy: 0.8969, Loss: 0.1757\n",
      "Epoch   8 Batch  194/269 - Train Accuracy: 0.8815, Validation Accuracy: 0.8960, Loss: 0.1876\n",
      "Epoch   8 Batch  195/269 - Train Accuracy: 0.8810, Validation Accuracy: 0.8975, Loss: 0.1774\n",
      "Epoch   8 Batch  196/269 - Train Accuracy: 0.8797, Validation Accuracy: 0.8888, Loss: 0.1731\n",
      "Epoch   8 Batch  197/269 - Train Accuracy: 0.8819, Validation Accuracy: 0.8934, Loss: 0.1918\n",
      "Epoch   8 Batch  198/269 - Train Accuracy: 0.8818, Validation Accuracy: 0.9007, Loss: 0.1906\n",
      "Epoch   8 Batch  199/269 - Train Accuracy: 0.8910, Validation Accuracy: 0.8958, Loss: 0.1896\n",
      "Epoch   8 Batch  200/269 - Train Accuracy: 0.8804, Validation Accuracy: 0.8868, Loss: 0.1843\n",
      "Epoch   8 Batch  201/269 - Train Accuracy: 0.8747, Validation Accuracy: 0.8856, Loss: 0.1811\n",
      "Epoch   8 Batch  202/269 - Train Accuracy: 0.8802, Validation Accuracy: 0.8948, Loss: 0.1811\n",
      "Epoch   8 Batch  203/269 - Train Accuracy: 0.8843, Validation Accuracy: 0.8929, Loss: 0.1941\n",
      "Epoch   8 Batch  204/269 - Train Accuracy: 0.8774, Validation Accuracy: 0.8803, Loss: 0.1862\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch   8 Batch  205/269 - Train Accuracy: 0.8865, Validation Accuracy: 0.8817, Loss: 0.1777\n",
      "Epoch   8 Batch  206/269 - Train Accuracy: 0.8720, Validation Accuracy: 0.8814, Loss: 0.1906\n",
      "Epoch   8 Batch  207/269 - Train Accuracy: 0.8777, Validation Accuracy: 0.8925, Loss: 0.1782\n",
      "Epoch   8 Batch  208/269 - Train Accuracy: 0.8805, Validation Accuracy: 0.8776, Loss: 0.1895\n",
      "Epoch   8 Batch  209/269 - Train Accuracy: 0.9002, Validation Accuracy: 0.8850, Loss: 0.1742\n",
      "Epoch   8 Batch  210/269 - Train Accuracy: 0.8895, Validation Accuracy: 0.8893, Loss: 0.1700\n",
      "Epoch   8 Batch  211/269 - Train Accuracy: 0.8802, Validation Accuracy: 0.8903, Loss: 0.1869\n",
      "Epoch   8 Batch  212/269 - Train Accuracy: 0.8916, Validation Accuracy: 0.8920, Loss: 0.1822\n",
      "Epoch   8 Batch  213/269 - Train Accuracy: 0.8812, Validation Accuracy: 0.8873, Loss: 0.1799\n",
      "Epoch   8 Batch  214/269 - Train Accuracy: 0.8728, Validation Accuracy: 0.8915, Loss: 0.1928\n",
      "Epoch   8 Batch  215/269 - Train Accuracy: 0.8975, Validation Accuracy: 0.8870, Loss: 0.1658\n",
      "Epoch   8 Batch  216/269 - Train Accuracy: 0.8632, Validation Accuracy: 0.8923, Loss: 0.2066\n",
      "Epoch   8 Batch  217/269 - Train Accuracy: 0.8789, Validation Accuracy: 0.8892, Loss: 0.1870\n",
      "Epoch   8 Batch  218/269 - Train Accuracy: 0.8952, Validation Accuracy: 0.8843, Loss: 0.1822\n",
      "Epoch   8 Batch  219/269 - Train Accuracy: 0.8997, Validation Accuracy: 0.8896, Loss: 0.1822\n",
      "Epoch   8 Batch  220/269 - Train Accuracy: 0.9094, Validation Accuracy: 0.8967, Loss: 0.1689\n",
      "Epoch   8 Batch  221/269 - Train Accuracy: 0.8980, Validation Accuracy: 0.8928, Loss: 0.1801\n",
      "Epoch   8 Batch  222/269 - Train Accuracy: 0.9106, Validation Accuracy: 0.8857, Loss: 0.1669\n",
      "Epoch   8 Batch  223/269 - Train Accuracy: 0.8885, Validation Accuracy: 0.8869, Loss: 0.1727\n",
      "Epoch   8 Batch  224/269 - Train Accuracy: 0.8844, Validation Accuracy: 0.8879, Loss: 0.1878\n",
      "Epoch   8 Batch  225/269 - Train Accuracy: 0.8808, Validation Accuracy: 0.8970, Loss: 0.1683\n",
      "Epoch   8 Batch  226/269 - Train Accuracy: 0.8991, Validation Accuracy: 0.8932, Loss: 0.1755\n",
      "Epoch   8 Batch  227/269 - Train Accuracy: 0.8955, Validation Accuracy: 0.8881, Loss: 0.1749\n",
      "Epoch   8 Batch  228/269 - Train Accuracy: 0.8777, Validation Accuracy: 0.8978, Loss: 0.1794\n",
      "Epoch   8 Batch  229/269 - Train Accuracy: 0.8852, Validation Accuracy: 0.8953, Loss: 0.1767\n",
      "Epoch   8 Batch  230/269 - Train Accuracy: 0.8855, Validation Accuracy: 0.8897, Loss: 0.1710\n",
      "Epoch   8 Batch  231/269 - Train Accuracy: 0.8887, Validation Accuracy: 0.8925, Loss: 0.1785\n",
      "Epoch   8 Batch  232/269 - Train Accuracy: 0.8688, Validation Accuracy: 0.8997, Loss: 0.1796\n",
      "Epoch   8 Batch  233/269 - Train Accuracy: 0.9035, Validation Accuracy: 0.9036, Loss: 0.1844\n",
      "Epoch   8 Batch  234/269 - Train Accuracy: 0.8885, Validation Accuracy: 0.9050, Loss: 0.1737\n",
      "Epoch   8 Batch  235/269 - Train Accuracy: 0.8989, Validation Accuracy: 0.9009, Loss: 0.1658\n",
      "Epoch   8 Batch  236/269 - Train Accuracy: 0.8766, Validation Accuracy: 0.8927, Loss: 0.1678\n",
      "Epoch   8 Batch  237/269 - Train Accuracy: 0.8936, Validation Accuracy: 0.9012, Loss: 0.1702\n",
      "Epoch   8 Batch  238/269 - Train Accuracy: 0.8904, Validation Accuracy: 0.8968, Loss: 0.1695\n",
      "Epoch   8 Batch  239/269 - Train Accuracy: 0.8905, Validation Accuracy: 0.8934, Loss: 0.1716\n",
      "Epoch   8 Batch  240/269 - Train Accuracy: 0.8951, Validation Accuracy: 0.8870, Loss: 0.1574\n",
      "Epoch   8 Batch  241/269 - Train Accuracy: 0.8783, Validation Accuracy: 0.8817, Loss: 0.1952\n",
      "Epoch   8 Batch  242/269 - Train Accuracy: 0.8985, Validation Accuracy: 0.8953, Loss: 0.1634\n",
      "Epoch   8 Batch  243/269 - Train Accuracy: 0.9023, Validation Accuracy: 0.8984, Loss: 0.1618\n",
      "Epoch   8 Batch  244/269 - Train Accuracy: 0.8822, Validation Accuracy: 0.8988, Loss: 0.1724\n",
      "Epoch   8 Batch  245/269 - Train Accuracy: 0.8827, Validation Accuracy: 0.8935, Loss: 0.1871\n",
      "Epoch   8 Batch  246/269 - Train Accuracy: 0.8856, Validation Accuracy: 0.8948, Loss: 0.1730\n",
      "Epoch   8 Batch  247/269 - Train Accuracy: 0.8981, Validation Accuracy: 0.8968, Loss: 0.1739\n",
      "Epoch   8 Batch  248/269 - Train Accuracy: 0.8947, Validation Accuracy: 0.8996, Loss: 0.1666\n",
      "Epoch   8 Batch  249/269 - Train Accuracy: 0.8988, Validation Accuracy: 0.8952, Loss: 0.1633\n",
      "Epoch   8 Batch  250/269 - Train Accuracy: 0.9003, Validation Accuracy: 0.8937, Loss: 0.1716\n",
      "Epoch   8 Batch  251/269 - Train Accuracy: 0.9191, Validation Accuracy: 0.8915, Loss: 0.1698\n",
      "Epoch   8 Batch  252/269 - Train Accuracy: 0.8825, Validation Accuracy: 0.8965, Loss: 0.1631\n",
      "Epoch   8 Batch  253/269 - Train Accuracy: 0.8705, Validation Accuracy: 0.9021, Loss: 0.1759\n",
      "Epoch   8 Batch  254/269 - Train Accuracy: 0.8880, Validation Accuracy: 0.9059, Loss: 0.1669\n",
      "Epoch   8 Batch  255/269 - Train Accuracy: 0.8941, Validation Accuracy: 0.8938, Loss: 0.1665\n",
      "Epoch   8 Batch  256/269 - Train Accuracy: 0.8782, Validation Accuracy: 0.8966, Loss: 0.1721\n",
      "Epoch   8 Batch  257/269 - Train Accuracy: 0.8719, Validation Accuracy: 0.8941, Loss: 0.1779\n",
      "Epoch   8 Batch  258/269 - Train Accuracy: 0.8933, Validation Accuracy: 0.9021, Loss: 0.1778\n",
      "Epoch   8 Batch  259/269 - Train Accuracy: 0.8955, Validation Accuracy: 0.9024, Loss: 0.1704\n",
      "Epoch   8 Batch  260/269 - Train Accuracy: 0.8787, Validation Accuracy: 0.8882, Loss: 0.1859\n",
      "Epoch   8 Batch  261/269 - Train Accuracy: 0.8900, Validation Accuracy: 0.8958, Loss: 0.1818\n",
      "Epoch   8 Batch  262/269 - Train Accuracy: 0.8952, Validation Accuracy: 0.8904, Loss: 0.1703\n",
      "Epoch   8 Batch  263/269 - Train Accuracy: 0.8785, Validation Accuracy: 0.9021, Loss: 0.1834\n",
      "Epoch   8 Batch  264/269 - Train Accuracy: 0.8560, Validation Accuracy: 0.8857, Loss: 0.1836\n",
      "Epoch   8 Batch  265/269 - Train Accuracy: 0.9022, Validation Accuracy: 0.8999, Loss: 0.1646\n",
      "Epoch   8 Batch  266/269 - Train Accuracy: 0.8931, Validation Accuracy: 0.8896, Loss: 0.1596\n",
      "Epoch   8 Batch  267/269 - Train Accuracy: 0.9043, Validation Accuracy: 0.8960, Loss: 0.1790\n",
      "Epoch   9 Batch    1/269 - Train Accuracy: 0.9023, Validation Accuracy: 0.8957, Loss: 0.1675\n",
      "Epoch   9 Batch    2/269 - Train Accuracy: 0.8849, Validation Accuracy: 0.9023, Loss: 0.1751\n",
      "Epoch   9 Batch    3/269 - Train Accuracy: 0.9023, Validation Accuracy: 0.9034, Loss: 0.1699\n",
      "Epoch   9 Batch    4/269 - Train Accuracy: 0.8831, Validation Accuracy: 0.9036, Loss: 0.1754\n",
      "Epoch   9 Batch    5/269 - Train Accuracy: 0.8837, Validation Accuracy: 0.8995, Loss: 0.1782\n",
      "Epoch   9 Batch    6/269 - Train Accuracy: 0.9052, Validation Accuracy: 0.8975, Loss: 0.1593\n",
      "Epoch   9 Batch    7/269 - Train Accuracy: 0.8983, Validation Accuracy: 0.9036, Loss: 0.1617\n",
      "Epoch   9 Batch    8/269 - Train Accuracy: 0.9026, Validation Accuracy: 0.8943, Loss: 0.1745\n",
      "Epoch   9 Batch    9/269 - Train Accuracy: 0.8811, Validation Accuracy: 0.9008, Loss: 0.1752\n",
      "Epoch   9 Batch   10/269 - Train Accuracy: 0.9017, Validation Accuracy: 0.8986, Loss: 0.1647\n",
      "Epoch   9 Batch   11/269 - Train Accuracy: 0.9009, Validation Accuracy: 0.8982, Loss: 0.1733\n",
      "Epoch   9 Batch   12/269 - Train Accuracy: 0.8767, Validation Accuracy: 0.8959, Loss: 0.1791\n",
      "Epoch   9 Batch   13/269 - Train Accuracy: 0.8935, Validation Accuracy: 0.8971, Loss: 0.1509\n",
      "Epoch   9 Batch   14/269 - Train Accuracy: 0.8740, Validation Accuracy: 0.8941, Loss: 0.1707\n",
      "Epoch   9 Batch   15/269 - Train Accuracy: 0.8956, Validation Accuracy: 0.8946, Loss: 0.1534\n",
      "Epoch   9 Batch   16/269 - Train Accuracy: 0.8895, Validation Accuracy: 0.9065, Loss: 0.1680\n",
      "Epoch   9 Batch   17/269 - Train Accuracy: 0.8925, Validation Accuracy: 0.9017, Loss: 0.1571\n",
      "Epoch   9 Batch   18/269 - Train Accuracy: 0.8787, Validation Accuracy: 0.9062, Loss: 0.1631\n",
      "Epoch   9 Batch   19/269 - Train Accuracy: 0.9025, Validation Accuracy: 0.9025, Loss: 0.1506\n",
      "Epoch   9 Batch   20/269 - Train Accuracy: 0.8927, Validation Accuracy: 0.8948, Loss: 0.1668\n",
      "Epoch   9 Batch   21/269 - Train Accuracy: 0.8717, Validation Accuracy: 0.8885, Loss: 0.1819\n",
      "Epoch   9 Batch   22/269 - Train Accuracy: 0.9122, Validation Accuracy: 0.8903, Loss: 0.1591\n",
      "Epoch   9 Batch   23/269 - Train Accuracy: 0.8949, Validation Accuracy: 0.8972, Loss: 0.1645\n",
      "Epoch   9 Batch   24/269 - Train Accuracy: 0.9040, Validation Accuracy: 0.9080, Loss: 0.1731\n",
      "Epoch   9 Batch   25/269 - Train Accuracy: 0.8900, Validation Accuracy: 0.9044, Loss: 0.1775\n",
      "Epoch   9 Batch   26/269 - Train Accuracy: 0.9023, Validation Accuracy: 0.8983, Loss: 0.1507\n",
      "Epoch   9 Batch   27/269 - Train Accuracy: 0.8821, Validation Accuracy: 0.9032, Loss: 0.1578\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch   9 Batch   28/269 - Train Accuracy: 0.8563, Validation Accuracy: 0.9067, Loss: 0.1765\n",
      "Epoch   9 Batch   29/269 - Train Accuracy: 0.8989, Validation Accuracy: 0.8968, Loss: 0.1714\n",
      "Epoch   9 Batch   30/269 - Train Accuracy: 0.8919, Validation Accuracy: 0.9031, Loss: 0.1607\n",
      "Epoch   9 Batch   31/269 - Train Accuracy: 0.9053, Validation Accuracy: 0.8969, Loss: 0.1616\n",
      "Epoch   9 Batch   32/269 - Train Accuracy: 0.8997, Validation Accuracy: 0.8923, Loss: 0.1584\n",
      "Epoch   9 Batch   33/269 - Train Accuracy: 0.8994, Validation Accuracy: 0.8970, Loss: 0.1490\n",
      "Epoch   9 Batch   34/269 - Train Accuracy: 0.8804, Validation Accuracy: 0.8969, Loss: 0.1673\n",
      "Epoch   9 Batch   35/269 - Train Accuracy: 0.8969, Validation Accuracy: 0.8961, Loss: 0.1676\n",
      "Epoch   9 Batch   36/269 - Train Accuracy: 0.8819, Validation Accuracy: 0.8970, Loss: 0.1666\n",
      "Epoch   9 Batch   37/269 - Train Accuracy: 0.8954, Validation Accuracy: 0.8991, Loss: 0.1715\n",
      "Epoch   9 Batch   38/269 - Train Accuracy: 0.8999, Validation Accuracy: 0.9007, Loss: 0.1613\n",
      "Epoch   9 Batch   39/269 - Train Accuracy: 0.8896, Validation Accuracy: 0.8960, Loss: 0.1627\n",
      "Epoch   9 Batch   40/269 - Train Accuracy: 0.8865, Validation Accuracy: 0.8980, Loss: 0.1710\n",
      "Epoch   9 Batch   41/269 - Train Accuracy: 0.8863, Validation Accuracy: 0.8930, Loss: 0.1655\n",
      "Epoch   9 Batch   42/269 - Train Accuracy: 0.9070, Validation Accuracy: 0.8934, Loss: 0.1486\n",
      "Epoch   9 Batch   43/269 - Train Accuracy: 0.8943, Validation Accuracy: 0.8985, Loss: 0.1606\n",
      "Epoch   9 Batch   44/269 - Train Accuracy: 0.8916, Validation Accuracy: 0.8952, Loss: 0.1629\n",
      "Epoch   9 Batch   45/269 - Train Accuracy: 0.8901, Validation Accuracy: 0.8952, Loss: 0.1664\n",
      "Epoch   9 Batch   46/269 - Train Accuracy: 0.9012, Validation Accuracy: 0.8931, Loss: 0.1570\n",
      "Epoch   9 Batch   47/269 - Train Accuracy: 0.9012, Validation Accuracy: 0.8985, Loss: 0.1466\n",
      "Epoch   9 Batch   48/269 - Train Accuracy: 0.8997, Validation Accuracy: 0.9037, Loss: 0.1571\n",
      "Epoch   9 Batch   49/269 - Train Accuracy: 0.8982, Validation Accuracy: 0.8975, Loss: 0.1568\n",
      "Epoch   9 Batch   50/269 - Train Accuracy: 0.8665, Validation Accuracy: 0.8975, Loss: 0.1686\n",
      "Epoch   9 Batch   51/269 - Train Accuracy: 0.8971, Validation Accuracy: 0.9041, Loss: 0.1661\n",
      "Epoch   9 Batch   52/269 - Train Accuracy: 0.8891, Validation Accuracy: 0.8987, Loss: 0.1437\n",
      "Epoch   9 Batch   53/269 - Train Accuracy: 0.8854, Validation Accuracy: 0.8915, Loss: 0.1726\n",
      "Epoch   9 Batch   54/269 - Train Accuracy: 0.9016, Validation Accuracy: 0.8993, Loss: 0.1642\n",
      "Epoch   9 Batch   55/269 - Train Accuracy: 0.9107, Validation Accuracy: 0.9032, Loss: 0.1532\n",
      "Epoch   9 Batch   56/269 - Train Accuracy: 0.9049, Validation Accuracy: 0.8928, Loss: 0.1586\n",
      "Epoch   9 Batch   57/269 - Train Accuracy: 0.8990, Validation Accuracy: 0.8941, Loss: 0.1701\n",
      "Epoch   9 Batch   58/269 - Train Accuracy: 0.8892, Validation Accuracy: 0.9032, Loss: 0.1560\n",
      "Epoch   9 Batch   59/269 - Train Accuracy: 0.8999, Validation Accuracy: 0.9062, Loss: 0.1458\n",
      "Epoch   9 Batch   60/269 - Train Accuracy: 0.8937, Validation Accuracy: 0.8962, Loss: 0.1477\n",
      "Epoch   9 Batch   61/269 - Train Accuracy: 0.9128, Validation Accuracy: 0.8997, Loss: 0.1524\n",
      "Epoch   9 Batch   62/269 - Train Accuracy: 0.8897, Validation Accuracy: 0.9008, Loss: 0.1617\n",
      "Epoch   9 Batch   63/269 - Train Accuracy: 0.9006, Validation Accuracy: 0.8986, Loss: 0.1673\n",
      "Epoch   9 Batch   64/269 - Train Accuracy: 0.9121, Validation Accuracy: 0.9018, Loss: 0.1517\n",
      "Epoch   9 Batch   65/269 - Train Accuracy: 0.8850, Validation Accuracy: 0.9080, Loss: 0.1581\n",
      "Epoch   9 Batch   66/269 - Train Accuracy: 0.8970, Validation Accuracy: 0.9104, Loss: 0.1603\n",
      "Epoch   9 Batch   67/269 - Train Accuracy: 0.9010, Validation Accuracy: 0.9064, Loss: 0.1662\n",
      "Epoch   9 Batch   68/269 - Train Accuracy: 0.8800, Validation Accuracy: 0.9024, Loss: 0.1720\n",
      "Epoch   9 Batch   69/269 - Train Accuracy: 0.8823, Validation Accuracy: 0.9070, Loss: 0.1820\n",
      "Epoch   9 Batch   70/269 - Train Accuracy: 0.8947, Validation Accuracy: 0.9089, Loss: 0.1558\n",
      "Epoch   9 Batch   71/269 - Train Accuracy: 0.9058, Validation Accuracy: 0.9134, Loss: 0.1689\n",
      "Epoch   9 Batch   72/269 - Train Accuracy: 0.8792, Validation Accuracy: 0.9110, Loss: 0.1616\n",
      "Epoch   9 Batch   73/269 - Train Accuracy: 0.8798, Validation Accuracy: 0.9142, Loss: 0.1732\n",
      "Epoch   9 Batch   74/269 - Train Accuracy: 0.8954, Validation Accuracy: 0.9090, Loss: 0.1513\n",
      "Epoch   9 Batch   75/269 - Train Accuracy: 0.9093, Validation Accuracy: 0.9078, Loss: 0.1623\n",
      "Epoch   9 Batch   76/269 - Train Accuracy: 0.8805, Validation Accuracy: 0.9023, Loss: 0.1508\n",
      "Epoch   9 Batch   77/269 - Train Accuracy: 0.8990, Validation Accuracy: 0.9041, Loss: 0.1567\n",
      "Epoch   9 Batch   78/269 - Train Accuracy: 0.8986, Validation Accuracy: 0.9046, Loss: 0.1577\n",
      "Epoch   9 Batch   79/269 - Train Accuracy: 0.8844, Validation Accuracy: 0.9036, Loss: 0.1611\n",
      "Epoch   9 Batch   80/269 - Train Accuracy: 0.8976, Validation Accuracy: 0.9031, Loss: 0.1460\n",
      "Epoch   9 Batch   81/269 - Train Accuracy: 0.8823, Validation Accuracy: 0.9032, Loss: 0.1673\n",
      "Epoch   9 Batch   82/269 - Train Accuracy: 0.9042, Validation Accuracy: 0.8957, Loss: 0.1459\n",
      "Epoch   9 Batch   83/269 - Train Accuracy: 0.8829, Validation Accuracy: 0.8990, Loss: 0.1628\n",
      "Epoch   9 Batch   84/269 - Train Accuracy: 0.9036, Validation Accuracy: 0.8992, Loss: 0.1490\n",
      "Epoch   9 Batch   85/269 - Train Accuracy: 0.8940, Validation Accuracy: 0.8963, Loss: 0.1583\n",
      "Epoch   9 Batch   86/269 - Train Accuracy: 0.8860, Validation Accuracy: 0.8995, Loss: 0.1517\n",
      "Epoch   9 Batch   87/269 - Train Accuracy: 0.8746, Validation Accuracy: 0.9033, Loss: 0.1673\n",
      "Epoch   9 Batch   88/269 - Train Accuracy: 0.8851, Validation Accuracy: 0.9005, Loss: 0.1528\n",
      "Epoch   9 Batch   89/269 - Train Accuracy: 0.9143, Validation Accuracy: 0.9051, Loss: 0.1616\n",
      "Epoch   9 Batch   90/269 - Train Accuracy: 0.8848, Validation Accuracy: 0.8974, Loss: 0.1689\n",
      "Epoch   9 Batch   91/269 - Train Accuracy: 0.9133, Validation Accuracy: 0.9051, Loss: 0.1517\n",
      "Epoch   9 Batch   92/269 - Train Accuracy: 0.9099, Validation Accuracy: 0.9023, Loss: 0.1461\n",
      "Epoch   9 Batch   93/269 - Train Accuracy: 0.9032, Validation Accuracy: 0.8983, Loss: 0.1522\n",
      "Epoch   9 Batch   94/269 - Train Accuracy: 0.8880, Validation Accuracy: 0.8999, Loss: 0.1708\n",
      "Epoch   9 Batch   95/269 - Train Accuracy: 0.8964, Validation Accuracy: 0.9028, Loss: 0.1576\n",
      "Epoch   9 Batch   96/269 - Train Accuracy: 0.8819, Validation Accuracy: 0.8975, Loss: 0.1595\n",
      "Epoch   9 Batch   97/269 - Train Accuracy: 0.8890, Validation Accuracy: 0.9053, Loss: 0.1652\n",
      "Epoch   9 Batch   98/269 - Train Accuracy: 0.8954, Validation Accuracy: 0.9041, Loss: 0.1573\n",
      "Epoch   9 Batch   99/269 - Train Accuracy: 0.8923, Validation Accuracy: 0.9008, Loss: 0.1571\n",
      "Epoch   9 Batch  100/269 - Train Accuracy: 0.9100, Validation Accuracy: 0.8954, Loss: 0.1466\n",
      "Epoch   9 Batch  101/269 - Train Accuracy: 0.8937, Validation Accuracy: 0.9122, Loss: 0.1734\n",
      "Epoch   9 Batch  102/269 - Train Accuracy: 0.8956, Validation Accuracy: 0.9047, Loss: 0.1516\n",
      "Epoch   9 Batch  103/269 - Train Accuracy: 0.9050, Validation Accuracy: 0.9047, Loss: 0.1692\n",
      "Epoch   9 Batch  104/269 - Train Accuracy: 0.9026, Validation Accuracy: 0.9035, Loss: 0.1542\n",
      "Epoch   9 Batch  105/269 - Train Accuracy: 0.8863, Validation Accuracy: 0.8977, Loss: 0.1602\n",
      "Epoch   9 Batch  106/269 - Train Accuracy: 0.8921, Validation Accuracy: 0.9007, Loss: 0.1520\n",
      "Epoch   9 Batch  107/269 - Train Accuracy: 0.8955, Validation Accuracy: 0.9005, Loss: 0.1563\n",
      "Epoch   9 Batch  108/269 - Train Accuracy: 0.9047, Validation Accuracy: 0.9026, Loss: 0.1561\n",
      "Epoch   9 Batch  109/269 - Train Accuracy: 0.8770, Validation Accuracy: 0.8970, Loss: 0.1601\n",
      "Epoch   9 Batch  110/269 - Train Accuracy: 0.8979, Validation Accuracy: 0.8988, Loss: 0.1502\n",
      "Epoch   9 Batch  111/269 - Train Accuracy: 0.8964, Validation Accuracy: 0.8984, Loss: 0.1774\n",
      "Epoch   9 Batch  112/269 - Train Accuracy: 0.9140, Validation Accuracy: 0.8931, Loss: 0.1544\n",
      "Epoch   9 Batch  113/269 - Train Accuracy: 0.8892, Validation Accuracy: 0.8963, Loss: 0.1568\n",
      "Epoch   9 Batch  114/269 - Train Accuracy: 0.8934, Validation Accuracy: 0.8970, Loss: 0.1517\n",
      "Epoch   9 Batch  115/269 - Train Accuracy: 0.8921, Validation Accuracy: 0.9029, Loss: 0.1563\n",
      "Epoch   9 Batch  116/269 - Train Accuracy: 0.9064, Validation Accuracy: 0.8967, Loss: 0.1564\n",
      "Epoch   9 Batch  117/269 - Train Accuracy: 0.8947, Validation Accuracy: 0.8984, Loss: 0.1558\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch   9 Batch  118/269 - Train Accuracy: 0.9062, Validation Accuracy: 0.8975, Loss: 0.1433\n",
      "Epoch   9 Batch  119/269 - Train Accuracy: 0.8882, Validation Accuracy: 0.8914, Loss: 0.1634\n",
      "Epoch   9 Batch  120/269 - Train Accuracy: 0.9106, Validation Accuracy: 0.8992, Loss: 0.1589\n",
      "Epoch   9 Batch  121/269 - Train Accuracy: 0.9002, Validation Accuracy: 0.9056, Loss: 0.1491\n",
      "Epoch   9 Batch  122/269 - Train Accuracy: 0.8995, Validation Accuracy: 0.9105, Loss: 0.1529\n",
      "Epoch   9 Batch  123/269 - Train Accuracy: 0.8960, Validation Accuracy: 0.9083, Loss: 0.1562\n",
      "Epoch   9 Batch  124/269 - Train Accuracy: 0.8892, Validation Accuracy: 0.9059, Loss: 0.1487\n",
      "Epoch   9 Batch  125/269 - Train Accuracy: 0.9045, Validation Accuracy: 0.8978, Loss: 0.1464\n",
      "Epoch   9 Batch  126/269 - Train Accuracy: 0.8790, Validation Accuracy: 0.9031, Loss: 0.1498\n",
      "Epoch   9 Batch  127/269 - Train Accuracy: 0.8823, Validation Accuracy: 0.9002, Loss: 0.1616\n",
      "Epoch   9 Batch  128/269 - Train Accuracy: 0.8961, Validation Accuracy: 0.9011, Loss: 0.1577\n",
      "Epoch   9 Batch  129/269 - Train Accuracy: 0.8855, Validation Accuracy: 0.9019, Loss: 0.1558\n",
      "Epoch   9 Batch  130/269 - Train Accuracy: 0.8907, Validation Accuracy: 0.9042, Loss: 0.1611\n",
      "Epoch   9 Batch  131/269 - Train Accuracy: 0.8775, Validation Accuracy: 0.8937, Loss: 0.1505\n",
      "Epoch   9 Batch  132/269 - Train Accuracy: 0.8869, Validation Accuracy: 0.9022, Loss: 0.1648\n",
      "Epoch   9 Batch  133/269 - Train Accuracy: 0.9039, Validation Accuracy: 0.9007, Loss: 0.1418\n",
      "Epoch   9 Batch  134/269 - Train Accuracy: 0.8959, Validation Accuracy: 0.9024, Loss: 0.1599\n",
      "Epoch   9 Batch  135/269 - Train Accuracy: 0.8925, Validation Accuracy: 0.9014, Loss: 0.1580\n",
      "Epoch   9 Batch  136/269 - Train Accuracy: 0.8700, Validation Accuracy: 0.9090, Loss: 0.1613\n",
      "Epoch   9 Batch  137/269 - Train Accuracy: 0.8893, Validation Accuracy: 0.9077, Loss: 0.1596\n",
      "Epoch   9 Batch  138/269 - Train Accuracy: 0.8933, Validation Accuracy: 0.9049, Loss: 0.1419\n",
      "Epoch   9 Batch  139/269 - Train Accuracy: 0.8890, Validation Accuracy: 0.9070, Loss: 0.1401\n",
      "Epoch   9 Batch  140/269 - Train Accuracy: 0.8914, Validation Accuracy: 0.9025, Loss: 0.1659\n",
      "Epoch   9 Batch  141/269 - Train Accuracy: 0.9035, Validation Accuracy: 0.9038, Loss: 0.1624\n",
      "Epoch   9 Batch  142/269 - Train Accuracy: 0.8837, Validation Accuracy: 0.9073, Loss: 0.1516\n",
      "Epoch   9 Batch  143/269 - Train Accuracy: 0.9001, Validation Accuracy: 0.9022, Loss: 0.1417\n",
      "Epoch   9 Batch  144/269 - Train Accuracy: 0.9076, Validation Accuracy: 0.9000, Loss: 0.1388\n",
      "Epoch   9 Batch  145/269 - Train Accuracy: 0.9035, Validation Accuracy: 0.8922, Loss: 0.1451\n",
      "Epoch   9 Batch  146/269 - Train Accuracy: 0.8960, Validation Accuracy: 0.9025, Loss: 0.1487\n",
      "Epoch   9 Batch  147/269 - Train Accuracy: 0.8993, Validation Accuracy: 0.9028, Loss: 0.1464\n",
      "Epoch   9 Batch  148/269 - Train Accuracy: 0.8918, Validation Accuracy: 0.8996, Loss: 0.1499\n",
      "Epoch   9 Batch  149/269 - Train Accuracy: 0.8735, Validation Accuracy: 0.9008, Loss: 0.1586\n",
      "Epoch   9 Batch  150/269 - Train Accuracy: 0.8900, Validation Accuracy: 0.9032, Loss: 0.1527\n",
      "Epoch   9 Batch  151/269 - Train Accuracy: 0.8919, Validation Accuracy: 0.9039, Loss: 0.1446\n",
      "Epoch   9 Batch  152/269 - Train Accuracy: 0.8936, Validation Accuracy: 0.9043, Loss: 0.1509\n",
      "Epoch   9 Batch  153/269 - Train Accuracy: 0.9068, Validation Accuracy: 0.9040, Loss: 0.1460\n",
      "Epoch   9 Batch  154/269 - Train Accuracy: 0.9184, Validation Accuracy: 0.9095, Loss: 0.1478\n",
      "Epoch   9 Batch  155/269 - Train Accuracy: 0.8902, Validation Accuracy: 0.9033, Loss: 0.1390\n",
      "Epoch   9 Batch  156/269 - Train Accuracy: 0.8900, Validation Accuracy: 0.9073, Loss: 0.1613\n",
      "Epoch   9 Batch  157/269 - Train Accuracy: 0.8929, Validation Accuracy: 0.9062, Loss: 0.1403\n",
      "Epoch   9 Batch  158/269 - Train Accuracy: 0.9073, Validation Accuracy: 0.9054, Loss: 0.1477\n",
      "Epoch   9 Batch  159/269 - Train Accuracy: 0.8810, Validation Accuracy: 0.9039, Loss: 0.1492\n",
      "Epoch   9 Batch  160/269 - Train Accuracy: 0.9016, Validation Accuracy: 0.9030, Loss: 0.1543\n",
      "Epoch   9 Batch  161/269 - Train Accuracy: 0.8933, Validation Accuracy: 0.9039, Loss: 0.1458\n",
      "Epoch   9 Batch  162/269 - Train Accuracy: 0.9113, Validation Accuracy: 0.9094, Loss: 0.1422\n",
      "Epoch   9 Batch  163/269 - Train Accuracy: 0.9157, Validation Accuracy: 0.9050, Loss: 0.1442\n",
      "Epoch   9 Batch  164/269 - Train Accuracy: 0.8973, Validation Accuracy: 0.9002, Loss: 0.1504\n",
      "Epoch   9 Batch  165/269 - Train Accuracy: 0.9012, Validation Accuracy: 0.8994, Loss: 0.1482\n",
      "Epoch   9 Batch  166/269 - Train Accuracy: 0.9069, Validation Accuracy: 0.8975, Loss: 0.1429\n",
      "Epoch   9 Batch  167/269 - Train Accuracy: 0.9036, Validation Accuracy: 0.9064, Loss: 0.1448\n",
      "Epoch   9 Batch  168/269 - Train Accuracy: 0.9098, Validation Accuracy: 0.9074, Loss: 0.1522\n",
      "Epoch   9 Batch  169/269 - Train Accuracy: 0.8931, Validation Accuracy: 0.9012, Loss: 0.1533\n",
      "Epoch   9 Batch  170/269 - Train Accuracy: 0.8861, Validation Accuracy: 0.9056, Loss: 0.1493\n",
      "Epoch   9 Batch  171/269 - Train Accuracy: 0.9148, Validation Accuracy: 0.9071, Loss: 0.1543\n",
      "Epoch   9 Batch  172/269 - Train Accuracy: 0.8815, Validation Accuracy: 0.8900, Loss: 0.1602\n",
      "Epoch   9 Batch  173/269 - Train Accuracy: 0.9055, Validation Accuracy: 0.9059, Loss: 0.1441\n",
      "Epoch   9 Batch  174/269 - Train Accuracy: 0.9020, Validation Accuracy: 0.9048, Loss: 0.1502\n",
      "Epoch   9 Batch  175/269 - Train Accuracy: 0.9029, Validation Accuracy: 0.9094, Loss: 0.1636\n",
      "Epoch   9 Batch  176/269 - Train Accuracy: 0.8756, Validation Accuracy: 0.8904, Loss: 0.1589\n",
      "Epoch   9 Batch  177/269 - Train Accuracy: 0.9007, Validation Accuracy: 0.9047, Loss: 0.1434\n",
      "Epoch   9 Batch  178/269 - Train Accuracy: 0.8989, Validation Accuracy: 0.9108, Loss: 0.1446\n",
      "Epoch   9 Batch  179/269 - Train Accuracy: 0.8962, Validation Accuracy: 0.9071, Loss: 0.1452\n",
      "Epoch   9 Batch  180/269 - Train Accuracy: 0.9080, Validation Accuracy: 0.9002, Loss: 0.1324\n",
      "Epoch   9 Batch  181/269 - Train Accuracy: 0.8894, Validation Accuracy: 0.8982, Loss: 0.1489\n",
      "Epoch   9 Batch  182/269 - Train Accuracy: 0.8955, Validation Accuracy: 0.9041, Loss: 0.1434\n",
      "Epoch   9 Batch  183/269 - Train Accuracy: 0.9177, Validation Accuracy: 0.9048, Loss: 0.1245\n",
      "Epoch   9 Batch  184/269 - Train Accuracy: 0.9058, Validation Accuracy: 0.8955, Loss: 0.1488\n",
      "Epoch   9 Batch  185/269 - Train Accuracy: 0.9102, Validation Accuracy: 0.9003, Loss: 0.1411\n",
      "Epoch   9 Batch  186/269 - Train Accuracy: 0.9001, Validation Accuracy: 0.9093, Loss: 0.1421\n",
      "Epoch   9 Batch  187/269 - Train Accuracy: 0.9009, Validation Accuracy: 0.9057, Loss: 0.1404\n",
      "Epoch   9 Batch  188/269 - Train Accuracy: 0.9128, Validation Accuracy: 0.8952, Loss: 0.1395\n",
      "Epoch   9 Batch  189/269 - Train Accuracy: 0.9023, Validation Accuracy: 0.9046, Loss: 0.1407\n",
      "Epoch   9 Batch  190/269 - Train Accuracy: 0.9090, Validation Accuracy: 0.9007, Loss: 0.1343\n",
      "Epoch   9 Batch  191/269 - Train Accuracy: 0.8864, Validation Accuracy: 0.8983, Loss: 0.1424\n",
      "Epoch   9 Batch  192/269 - Train Accuracy: 0.8976, Validation Accuracy: 0.9022, Loss: 0.1427\n",
      "Epoch   9 Batch  193/269 - Train Accuracy: 0.9049, Validation Accuracy: 0.9023, Loss: 0.1448\n",
      "Epoch   9 Batch  194/269 - Train Accuracy: 0.8876, Validation Accuracy: 0.9058, Loss: 0.1481\n",
      "Epoch   9 Batch  195/269 - Train Accuracy: 0.8956, Validation Accuracy: 0.9021, Loss: 0.1419\n",
      "Epoch   9 Batch  196/269 - Train Accuracy: 0.9026, Validation Accuracy: 0.8964, Loss: 0.1324\n",
      "Epoch   9 Batch  197/269 - Train Accuracy: 0.8934, Validation Accuracy: 0.9064, Loss: 0.1498\n",
      "Epoch   9 Batch  198/269 - Train Accuracy: 0.8979, Validation Accuracy: 0.9049, Loss: 0.1497\n",
      "Epoch   9 Batch  199/269 - Train Accuracy: 0.8949, Validation Accuracy: 0.9058, Loss: 0.1434\n",
      "Epoch   9 Batch  200/269 - Train Accuracy: 0.8959, Validation Accuracy: 0.9093, Loss: 0.1444\n",
      "Epoch   9 Batch  201/269 - Train Accuracy: 0.8996, Validation Accuracy: 0.8975, Loss: 0.1439\n",
      "Epoch   9 Batch  202/269 - Train Accuracy: 0.8890, Validation Accuracy: 0.9006, Loss: 0.1480\n",
      "Epoch   9 Batch  203/269 - Train Accuracy: 0.8979, Validation Accuracy: 0.8966, Loss: 0.1581\n",
      "Epoch   9 Batch  204/269 - Train Accuracy: 0.8863, Validation Accuracy: 0.9024, Loss: 0.1571\n",
      "Epoch   9 Batch  205/269 - Train Accuracy: 0.9070, Validation Accuracy: 0.9055, Loss: 0.1416\n",
      "Epoch   9 Batch  206/269 - Train Accuracy: 0.8758, Validation Accuracy: 0.9023, Loss: 0.1618\n",
      "Epoch   9 Batch  207/269 - Train Accuracy: 0.8934, Validation Accuracy: 0.9051, Loss: 0.1503\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch   9 Batch  208/269 - Train Accuracy: 0.8944, Validation Accuracy: 0.9059, Loss: 0.1557\n",
      "Epoch   9 Batch  209/269 - Train Accuracy: 0.9111, Validation Accuracy: 0.9075, Loss: 0.1362\n",
      "Epoch   9 Batch  210/269 - Train Accuracy: 0.9019, Validation Accuracy: 0.9092, Loss: 0.1468\n",
      "Epoch   9 Batch  211/269 - Train Accuracy: 0.8951, Validation Accuracy: 0.9065, Loss: 0.1461\n",
      "Epoch   9 Batch  212/269 - Train Accuracy: 0.8894, Validation Accuracy: 0.8979, Loss: 0.1552\n",
      "Epoch   9 Batch  213/269 - Train Accuracy: 0.8958, Validation Accuracy: 0.9086, Loss: 0.1456\n",
      "Epoch   9 Batch  214/269 - Train Accuracy: 0.8886, Validation Accuracy: 0.9077, Loss: 0.1482\n",
      "Epoch   9 Batch  215/269 - Train Accuracy: 0.9164, Validation Accuracy: 0.9081, Loss: 0.1434\n",
      "Epoch   9 Batch  216/269 - Train Accuracy: 0.8758, Validation Accuracy: 0.9048, Loss: 0.1598\n",
      "Epoch   9 Batch  217/269 - Train Accuracy: 0.8924, Validation Accuracy: 0.9078, Loss: 0.1539\n",
      "Epoch   9 Batch  218/269 - Train Accuracy: 0.9052, Validation Accuracy: 0.9066, Loss: 0.1407\n",
      "Epoch   9 Batch  219/269 - Train Accuracy: 0.9091, Validation Accuracy: 0.9070, Loss: 0.1497\n",
      "Epoch   9 Batch  220/269 - Train Accuracy: 0.9116, Validation Accuracy: 0.9068, Loss: 0.1360\n",
      "Epoch   9 Batch  221/269 - Train Accuracy: 0.9077, Validation Accuracy: 0.9055, Loss: 0.1489\n",
      "Epoch   9 Batch  222/269 - Train Accuracy: 0.9233, Validation Accuracy: 0.9111, Loss: 0.1343\n",
      "Epoch   9 Batch  223/269 - Train Accuracy: 0.9024, Validation Accuracy: 0.9102, Loss: 0.1349\n",
      "Epoch   9 Batch  224/269 - Train Accuracy: 0.9062, Validation Accuracy: 0.9078, Loss: 0.1557\n",
      "Epoch   9 Batch  225/269 - Train Accuracy: 0.8998, Validation Accuracy: 0.9055, Loss: 0.1340\n",
      "Epoch   9 Batch  226/269 - Train Accuracy: 0.9094, Validation Accuracy: 0.9074, Loss: 0.1424\n",
      "Epoch   9 Batch  227/269 - Train Accuracy: 0.9083, Validation Accuracy: 0.9058, Loss: 0.1468\n",
      "Epoch   9 Batch  228/269 - Train Accuracy: 0.8958, Validation Accuracy: 0.9052, Loss: 0.1404\n",
      "Epoch   9 Batch  229/269 - Train Accuracy: 0.8916, Validation Accuracy: 0.9095, Loss: 0.1379\n",
      "Epoch   9 Batch  230/269 - Train Accuracy: 0.8928, Validation Accuracy: 0.9017, Loss: 0.1371\n",
      "Epoch   9 Batch  231/269 - Train Accuracy: 0.8908, Validation Accuracy: 0.9028, Loss: 0.1454\n",
      "Epoch   9 Batch  232/269 - Train Accuracy: 0.8842, Validation Accuracy: 0.9055, Loss: 0.1441\n",
      "Epoch   9 Batch  233/269 - Train Accuracy: 0.9200, Validation Accuracy: 0.9037, Loss: 0.1441\n",
      "Epoch   9 Batch  234/269 - Train Accuracy: 0.8934, Validation Accuracy: 0.9083, Loss: 0.1348\n",
      "Epoch   9 Batch  235/269 - Train Accuracy: 0.9149, Validation Accuracy: 0.9113, Loss: 0.1243\n",
      "Epoch   9 Batch  236/269 - Train Accuracy: 0.8986, Validation Accuracy: 0.9058, Loss: 0.1374\n",
      "Epoch   9 Batch  237/269 - Train Accuracy: 0.9093, Validation Accuracy: 0.9106, Loss: 0.1444\n",
      "Epoch   9 Batch  238/269 - Train Accuracy: 0.8945, Validation Accuracy: 0.9077, Loss: 0.1342\n",
      "Epoch   9 Batch  239/269 - Train Accuracy: 0.9046, Validation Accuracy: 0.9057, Loss: 0.1409\n",
      "Epoch   9 Batch  240/269 - Train Accuracy: 0.9105, Validation Accuracy: 0.9091, Loss: 0.1296\n",
      "Epoch   9 Batch  241/269 - Train Accuracy: 0.8919, Validation Accuracy: 0.9113, Loss: 0.1564\n",
      "Epoch   9 Batch  242/269 - Train Accuracy: 0.9150, Validation Accuracy: 0.9188, Loss: 0.1326\n",
      "Epoch   9 Batch  243/269 - Train Accuracy: 0.9123, Validation Accuracy: 0.9177, Loss: 0.1289\n",
      "Epoch   9 Batch  244/269 - Train Accuracy: 0.8956, Validation Accuracy: 0.9120, Loss: 0.1421\n",
      "Epoch   9 Batch  245/269 - Train Accuracy: 0.8914, Validation Accuracy: 0.9070, Loss: 0.1419\n",
      "Epoch   9 Batch  246/269 - Train Accuracy: 0.9019, Validation Accuracy: 0.9106, Loss: 0.1512\n",
      "Epoch   9 Batch  247/269 - Train Accuracy: 0.9030, Validation Accuracy: 0.9114, Loss: 0.1421\n",
      "Epoch   9 Batch  248/269 - Train Accuracy: 0.8991, Validation Accuracy: 0.9020, Loss: 0.1340\n",
      "Epoch   9 Batch  249/269 - Train Accuracy: 0.9125, Validation Accuracy: 0.9026, Loss: 0.1313\n",
      "Epoch   9 Batch  250/269 - Train Accuracy: 0.9210, Validation Accuracy: 0.9102, Loss: 0.1399\n",
      "Epoch   9 Batch  251/269 - Train Accuracy: 0.9340, Validation Accuracy: 0.9091, Loss: 0.1366\n",
      "Epoch   9 Batch  252/269 - Train Accuracy: 0.8942, Validation Accuracy: 0.9028, Loss: 0.1281\n",
      "Epoch   9 Batch  253/269 - Train Accuracy: 0.8797, Validation Accuracy: 0.9015, Loss: 0.1470\n",
      "Epoch   9 Batch  254/269 - Train Accuracy: 0.8958, Validation Accuracy: 0.9057, Loss: 0.1372\n",
      "Epoch   9 Batch  255/269 - Train Accuracy: 0.9026, Validation Accuracy: 0.9093, Loss: 0.1438\n",
      "Epoch   9 Batch  256/269 - Train Accuracy: 0.8886, Validation Accuracy: 0.9084, Loss: 0.1368\n",
      "Epoch   9 Batch  257/269 - Train Accuracy: 0.8858, Validation Accuracy: 0.9076, Loss: 0.1469\n",
      "Epoch   9 Batch  258/269 - Train Accuracy: 0.9049, Validation Accuracy: 0.9102, Loss: 0.1412\n",
      "Epoch   9 Batch  259/269 - Train Accuracy: 0.9063, Validation Accuracy: 0.9054, Loss: 0.1335\n",
      "Epoch   9 Batch  260/269 - Train Accuracy: 0.8957, Validation Accuracy: 0.9007, Loss: 0.1498\n",
      "Epoch   9 Batch  261/269 - Train Accuracy: 0.8970, Validation Accuracy: 0.9007, Loss: 0.1350\n",
      "Epoch   9 Batch  262/269 - Train Accuracy: 0.9090, Validation Accuracy: 0.9096, Loss: 0.1426\n",
      "Epoch   9 Batch  263/269 - Train Accuracy: 0.8944, Validation Accuracy: 0.9110, Loss: 0.1420\n",
      "Epoch   9 Batch  264/269 - Train Accuracy: 0.8823, Validation Accuracy: 0.9103, Loss: 0.1476\n",
      "Epoch   9 Batch  265/269 - Train Accuracy: 0.9127, Validation Accuracy: 0.9072, Loss: 0.1304\n",
      "Epoch   9 Batch  266/269 - Train Accuracy: 0.9141, Validation Accuracy: 0.9107, Loss: 0.1269\n",
      "Epoch   9 Batch  267/269 - Train Accuracy: 0.9141, Validation Accuracy: 0.9052, Loss: 0.1476\n",
      "Model Trained and Saved\n"
     ]
    }
   ],
   "source": [
    "def get_accuracy(target, logits):\n",
    "    \"\"\"\n",
    "    Calculate accuracy\n",
    "    \"\"\"\n",
    "    max_seq = max(target.shape[1], logits.shape[1])\n",
    "    if max_seq - target.shape[1]:\n",
    "        target = np.pad(\n",
    "            target,\n",
    "            [(0,0),(0,max_seq - target.shape[1])],\n",
    "            'constant')\n",
    "    if max_seq - logits.shape[1]:\n",
    "        logits = np.pad(\n",
    "            logits,\n",
    "            [(0,0),(0,max_seq - logits.shape[1])],\n",
    "            'constant')\n",
    "\n",
    "    return np.mean(np.equal(target, logits))\n",
    "\n",
    "\n",
    "with tf.Session(graph=train_graph) as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "\n",
    "    for epoch_i in range(epochs):\n",
    "        for batch_i, (source_batch, target_batch, sources_lengths, targets_lengths) in enumerate(\n",
    "                get_batches(train_source, train_target, batch_size,\n",
    "                            source_vocab_to_int['<PAD>'],\n",
    "                            target_vocab_to_int['<PAD>'])):\n",
    "\n",
    "            _, loss = sess.run(\n",
    "                [train_op, cost],\n",
    "                {input_data: source_batch,\n",
    "                 targets: target_batch,\n",
    "                 lr: learning_rate,\n",
    "                 target_sequence_length: targets_lengths,\n",
    "                 source_sequence_length: sources_lengths,\n",
    "                 keep_prob: keep_probability})\n",
    "\n",
    "            if batch_i % display_step == 0 and batch_i > 0:\n",
    "                \n",
    "                batch_train_logits = sess.run(\n",
    "                    inference_logits,\n",
    "                    {input_data: source_batch,\n",
    "                     source_sequence_length: sources_lengths,\n",
    "                     target_sequence_length: targets_lengths,\n",
    "                     keep_prob: 1.0})\n",
    "\n",
    "                batch_valid_logits = sess.run(\n",
    "                    inference_logits,\n",
    "                    {input_data: valid_sources_batch,\n",
    "                     source_sequence_length: valid_sources_lengths,\n",
    "                     target_sequence_length: valid_targets_lengths,\n",
    "                     keep_prob: 1.0})\n",
    "\n",
    "                train_acc = get_accuracy(target_batch, batch_train_logits)\n",
    "\n",
    "                valid_acc = get_accuracy(valid_targets_batch, batch_valid_logits)\n",
    "\n",
    "                print('Epoch {:>3} Batch {:>4}/{} - Train Accuracy: {:>6.4f}, Validation Accuracy: {:>6.4f}, Loss: {:>6.4f}'\n",
    "                      .format(epoch_i, batch_i, len(source_int_text) // batch_size, train_acc, valid_acc, loss))\n",
    "\n",
    "    # Save Model\n",
    "    saver = tf.train.Saver()\n",
    "    saver.save(sess, save_path)\n",
    "    print('Model Trained and Saved')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ApPX0594fDhu"
   },
   "outputs": [],
   "source": [
    "# save_params(save_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2uF1u2EvfIL_"
   },
   "source": [
    "## Checkpoint for testing the sentence to sequence model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gLjRcBEcfEKW"
   },
   "outputs": [],
   "source": [
    "batch_size = 512\n",
    "\n",
    "_, (source_vocab_to_int, target_vocab_to_int), (source_int_to_vocab, target_int_to_vocab) = load_preprocess()\n",
    "load_path = load_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XBE-ZCU5fQIX"
   },
   "outputs": [],
   "source": [
    "def sentence_to_seq(sentence, vocab_to_int):\n",
    "    \"\"\"\n",
    "    Convert a sentence to a sequence of ids\n",
    "    :param sentence: String\n",
    "    :param vocab_to_int: Dictionary to go from the words to an id\n",
    "    :return: List of word ids\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    UNK_id = vocab_to_int['<UNK>']\n",
    "    seq = []\n",
    "    for word in sentence.lower().split():\n",
    "        if word in vocab_to_int:\n",
    "            seq.append(vocab_to_int[word])\n",
    "        else:\n",
    "            seq.append(UNK_id)\n",
    "    return seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 153
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2181,
     "status": "ok",
     "timestamp": 1517979464799,
     "user": {
      "displayName": "Kok Meng Tan",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "113459036002015692798"
     },
     "user_tz": -480
    },
    "id": "dR1EvpcjfTtM",
    "outputId": "23372cbc-3884-4508-a657-2fff2f3aef59"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from checkpoints/dev\n",
      "Input\n",
      "  Word Ids:      [171, 25, 8, 136, 187, 151, 46]\n",
      "  English Words: ['he', 'saw', 'a', 'old', 'yellow', 'truck', '.']\n",
      "\n",
      "Prediction\n",
      "  Word Ids:      [81, 178, 181, 316, 83, 335, 322, 189, 1]\n",
      "  French Words: il a vu un camion jaune brillant . <EOS>\n"
     ]
    }
   ],
   "source": [
    "translate_sentence = 'he saw a old yellow truck .'\n",
    "\n",
    "translate_sentence = sentence_to_seq(translate_sentence, source_vocab_to_int)\n",
    "\n",
    "loaded_graph = tf.Graph()\n",
    "with tf.Session(graph=loaded_graph) as sess:\n",
    "    # Load saved model\n",
    "    loader = tf.train.import_meta_graph(load_path + '.meta')\n",
    "    loader.restore(sess, load_path)\n",
    "\n",
    "    input_data = loaded_graph.get_tensor_by_name('input:0')\n",
    "    logits = loaded_graph.get_tensor_by_name('predictions:0')\n",
    "    target_sequence_length = loaded_graph.get_tensor_by_name('target_sequence_length:0')\n",
    "    source_sequence_length = loaded_graph.get_tensor_by_name('source_sequence_length:0')\n",
    "    keep_prob = loaded_graph.get_tensor_by_name('keep_prob:0')\n",
    "\n",
    "    translate_logits = sess.run(logits, {input_data: [translate_sentence]*batch_size,\n",
    "                                         target_sequence_length: [len(translate_sentence)*2]*batch_size,\n",
    "                                         source_sequence_length: [len(translate_sentence)]*batch_size,\n",
    "                                         keep_prob: 1.0})[0]\n",
    "\n",
    "print('Input')\n",
    "print('  Word Ids:      {}'.format([i for i in translate_sentence]))\n",
    "print('  English Words: {}'.format([source_int_to_vocab[i] for i in translate_sentence]))\n",
    "\n",
    "print('\\nPrediction')\n",
    "print('  Word Ids:      {}'.format([i for i in translate_logits]))\n",
    "print('  French Words: {}'.format(\" \".join([target_int_to_vocab[i] for i in translate_logits])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HRx4d-Nvtf0f"
   },
   "source": [
    "## Download files, models, results, plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1025,
     "status": "ok",
     "timestamp": 1517979479800,
     "user": {
      "displayName": "Kok Meng Tan",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "113459036002015692798"
     },
     "user_tz": -480
    },
    "id": "j9_g2-lakV_R",
    "outputId": "8228efe8-1cb8-429f-f0e2-f9e2f14adfcb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "checkpoints  data  datalab  params.p  preprocess.p\r\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DlSy8gsZXCK4"
   },
   "outputs": [],
   "source": [
    "from google.colab import files\n",
    "\n",
    "files.download('params.p')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-JKmY6ASe8po"
   },
   "source": [
    "## Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1521,
     "status": "ok",
     "timestamp": 1535674627671,
     "user": {
      "displayName": "Kok Meng Tan",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "113459036002015692798"
     },
     "user_tz": -480
    },
    "id": "Stw6z-hefClo",
    "outputId": "f7220ac9-3bcf-4fc8-80e9-0eeefaadecf2"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Model\n",
    "from keras.layers import Input, LSTM, Dense, GRU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SSEObBj8P9Mz"
   },
   "outputs": [],
   "source": [
    "%mkdir data/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KCoNtY0oPfDS"
   },
   "outputs": [],
   "source": [
    "downloaded = drive.CreateFile({'id':'14W_O1I-3g6C6v7CtAqv_bwB9y29sjCaP'})\n",
    "downloaded.GetContentFile('data/fra.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 4178,
     "status": "ok",
     "timestamp": 1535674635530,
     "user": {
      "displayName": "Kok Meng Tan",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "113459036002015692798"
     },
     "user_tz": -480
    },
    "id": "IUEc6XFpP-e1",
    "outputId": "5e5852a5-5bd6-4caa-c0b1-f7b4e5355109"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fra.txt\r\n"
     ]
    }
   ],
   "source": [
    "%ls data/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UnKmYNc0ExU5"
   },
   "outputs": [],
   "source": [
    "num_samples = 10000  # Number of samples to train on.\n",
    "# Path to the data txt file on disk.\n",
    "data_path = 'data/fra.txt'\n",
    "\n",
    "# Vectorize the data.\n",
    "input_texts = []\n",
    "target_texts = []\n",
    "input_characters = set()\n",
    "target_characters = set()\n",
    "with open(data_path, 'r', encoding='utf-8') as f:\n",
    "    lines = f.read().split('\\n')\n",
    "    \n",
    "for line in lines[: min(num_samples, len(lines) - 1)]:\n",
    "    input_text, target_text = line.split('\\t')\n",
    "    # We use \"tab\" as the \"start sequence\" character\n",
    "    # for the targets, and \"\\n\" as \"end sequence\" character.\n",
    "    target_text = '\\t' + target_text + '\\n'\n",
    "    input_texts.append(input_text)\n",
    "    target_texts.append(target_text)\n",
    "    for char in input_text:\n",
    "        if char not in input_characters:\n",
    "            input_characters.add(char)\n",
    "    for char in target_text:\n",
    "        if char not in target_characters:\n",
    "            target_characters.add(char)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 102
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2006,
     "status": "ok",
     "timestamp": 1535674671759,
     "user": {
      "displayName": "Kok Meng Tan",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "113459036002015692798"
     },
     "user_tz": -480
    },
    "id": "Hiyf57pBEfcK",
    "outputId": "fc20a4df-0960-4921-d7d8-9d0c8b715730"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples: 10000\n",
      "Number of unique input tokens: 71\n",
      "Number of unique output tokens: 94\n",
      "Max sequence length for inputs: 16\n",
      "Max sequence length for outputs: 59\n"
     ]
    }
   ],
   "source": [
    "input_characters = sorted(list(input_characters))\n",
    "target_characters = sorted(list(target_characters))\n",
    "num_encoder_tokens = len(input_characters)\n",
    "num_decoder_tokens = len(target_characters)\n",
    "max_encoder_seq_length = max([len(txt) for txt in input_texts])\n",
    "max_decoder_seq_length = max([len(txt) for txt in target_texts])\n",
    "\n",
    "print('Number of samples:', len(input_texts))\n",
    "print('Number of unique input tokens:', num_encoder_tokens)\n",
    "print('Number of unique output tokens:', num_decoder_tokens)\n",
    "print('Max sequence length for inputs:', max_encoder_seq_length)\n",
    "print('Max sequence length for outputs:', max_decoder_seq_length)\n",
    "\n",
    "# Lookup token index to encode sequences.\n",
    "input_token_index = dict(\n",
    "    [(char, i) for i, char in enumerate(input_characters)])\n",
    "target_token_index = dict(\n",
    "    [(char, i) for i, char in enumerate(target_characters)])\n",
    "\n",
    "# Reverse-lookup token index to decode sequences back to\n",
    "# something readable.\n",
    "reverse_input_char_index = dict(\n",
    "    (i, char) for char, i in input_token_index.items())\n",
    "reverse_target_char_index = dict(\n",
    "    (i, char) for char, i in target_token_index.items())\n",
    "\n",
    "\n",
    "# Prepare input and target data for training\n",
    "encoder_input_data = np.zeros(\n",
    "    (len(input_texts), max_encoder_seq_length, num_encoder_tokens),\n",
    "    dtype='float32')\n",
    "decoder_input_data = np.zeros(\n",
    "    (len(input_texts), max_decoder_seq_length, num_decoder_tokens),\n",
    "    dtype='float32')\n",
    "decoder_target_data = np.zeros(\n",
    "    (len(input_texts), max_decoder_seq_length, num_decoder_tokens),\n",
    "    dtype='float32')\n",
    "\n",
    "for i, (input_text, target_text) in enumerate(zip(input_texts, target_texts)):\n",
    "    for t, char in enumerate(input_text):\n",
    "        encoder_input_data[i, t, input_token_index[char]] = 1.\n",
    "    for t, char in enumerate(target_text):\n",
    "        # decoder_target_data is ahead of decoder_input_data by one timestep\n",
    "        decoder_input_data[i, t, target_token_index[char]] = 1.\n",
    "        if t > 0:\n",
    "            # decoder_target_data will be ahead by one timestep\n",
    "            # and will not include the start character.\n",
    "            decoder_target_data[i, t - 1, target_token_index[char]] = 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2031,
     "status": "ok",
     "timestamp": 1535674673811,
     "user": {
      "displayName": "Kok Meng Tan",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "113459036002015692798"
     },
     "user_tz": -480
    },
    "id": "S99EYYmpU8jn",
    "outputId": "722ca6e9-7d6e-4c32-bcf4-eae78e7f4ba5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((10000, 16, 71), (10000, 59, 94), (10000, 59, 94))"
      ]
     },
     "execution_count": 14,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder_input_data.shape, decoder_input_data.shape, decoder_target_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lAXylTfQfQcg"
   },
   "source": [
    "The training model leverages three key features of Keras RNNs:\n",
    "\n",
    "- The return_state contructor argument, configuring a RNN layer to return a list where the first entry is the outputs and the next entries are the internal RNN states. This is used to recover the states of the encoder.\n",
    "- The inital_state call argument, specifying the initial state(s) of a RNN. This is used to pass the encoder states to the decoder as initial states.\n",
    "- The return_sequences constructor argument, configuring a RNN to return its full sequence of outputs (instead of just the last output, which the defaults behavior). This is used in the decoder."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nonsu-kGfk8z"
   },
   "source": [
    "### Training model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vvfZSp7zgfZw"
   },
   "outputs": [],
   "source": [
    "batch_size = 64  # Batch size for training.\n",
    "epochs = 20  # Number of epochs to train for.\n",
    "latent_dim = 256  # Latent dimensionality of the encoding space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "boh43rvU35cZ"
   },
   "outputs": [],
   "source": [
    "def seq2seq_lstm(num_encoder_tokens, num_decoder_tokens, latent_dim=256):\n",
    "    # Define an input sequence and process it.\n",
    "    encoder_inputs = Input(shape=(None, num_encoder_tokens))\n",
    "    encoder = LSTM(latent_dim, return_state=True)\n",
    "    encoder_outputs, state_h, state_c = encoder(encoder_inputs)\n",
    "    # We discard `encoder_outputs` and only keep the states.\n",
    "    encoder_states = [state_h, state_c]\n",
    "    encoder_model = Model(encoder_inputs, encoder_states)\n",
    "    print(encoder_model.summary())\n",
    "\n",
    "    # Set up the decoder, using `encoder_states` as initial state.\n",
    "    decoder_inputs = Input(shape=(None, num_decoder_tokens))\n",
    "    # We set up our decoder to return full output sequences,\n",
    "    # and to return internal states as well. We don't use the \n",
    "    # return states in the training model, but we will use them in inference.\n",
    "    decoder = LSTM(latent_dim, return_sequences=True, return_state=True)\n",
    "    decoder_outputs, _, _ = decoder(decoder_inputs,\n",
    "                                    initial_state=encoder_states)\n",
    "    decoder_dense = Dense(num_decoder_tokens, activation='softmax')\n",
    "    decoder_outputs = decoder_dense(decoder_outputs)\n",
    "\n",
    "    # Define the model that will turn\n",
    "    # `encoder_input_data` & `decoder_input_data` into `decoder_target_data`\n",
    "    model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
    "    print(model.summary())\n",
    "\n",
    "    # Inference decoder model\n",
    "    decoder_state_input_h = Input(shape=(latent_dim, ))\n",
    "    decoder_state_input_c = Input(shape=(latent_dim, ))\n",
    "    decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
    "\n",
    "    decoder_outputs, state_h, state_c = decoder(\n",
    "        decoder_inputs, initial_state=decoder_states_inputs)\n",
    "    decoder_states = [state_h, state_c]\n",
    "    decoder_outputs = decoder_dense(decoder_outputs)\n",
    "    decoder_model = Model(\n",
    "        [decoder_inputs] + decoder_states_inputs,\n",
    "        [decoder_outputs] + decoder_states)\n",
    "    print(decoder_model.summary())\n",
    "    return model, encoder_model, decoder_model\n",
    "\n",
    "\n",
    "def seq2seq_gru(num_encoder_tokens, num_decoder_tokens, latent_dim=256):\n",
    "    # Define an input sequence and process it.\n",
    "    encoder_inputs = Input(shape=(None, num_encoder_tokens))\n",
    "    encoder = GRU(latent_dim, return_state=True)\n",
    "    encoder_outputs, state_h = encoder(encoder_inputs)\n",
    "    # We discard `encoder_outputs` and only keep the states.\n",
    "    encoder_states = [state_h]\n",
    "    encoder_model = Model(encoder_inputs, encoder_states)\n",
    "    print(encoder_model.summary())\n",
    "    \n",
    "    # Set up the decoder, using `encoder_states` as initial state.\n",
    "    decoder_inputs = Input(shape=(None, num_decoder_tokens))\n",
    "    # We set up our decoder to return full output sequences,\n",
    "    # and to return internal states as well. We don't use the \n",
    "    # return states in the training model, but we will use them in inference.\n",
    "    decoder = GRU(latent_dim, return_sequences=True, return_state=True)\n",
    "    decoder_outputs, _ = decoder(decoder_inputs, initial_state=state_h)\n",
    "    decoder_dense = Dense(num_decoder_tokens, activation='softmax')\n",
    "    decoder_outputs = decoder_dense(decoder_outputs)\n",
    "    model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
    "    print(model.summary())\n",
    "    \n",
    "    # Inference decoder model\n",
    "    decoder_state_input_h = Input(shape=(latent_dim, ))\n",
    "    decoder_states_inputs = [decoder_state_input_h]\n",
    "\n",
    "    decoder_outputs, state_h = decoder(\n",
    "        decoder_inputs, initial_state=decoder_states_inputs)\n",
    "    decoder_states = [state_h]\n",
    "    decoder_outputs = decoder_dense(decoder_outputs)\n",
    "    decoder_model = Model(\n",
    "        [decoder_inputs] + decoder_states_inputs,\n",
    "        [decoder_outputs] + decoder_states)\n",
    "    print(decoder_model.summary())\n",
    "    return model, encoder_model, decoder_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vjN5Hqc3DRo5"
   },
   "outputs": [],
   "source": [
    "model2, encoder_model2, decoder_model2 = seq2seq_lstm(num_encoder_tokens, num_decoder_tokens)\n",
    "\n",
    "# Run training\n",
    "model2.compile(optimizer='rmsprop', loss='categorical_crossentropy')\n",
    "model2.fit([encoder_input_data, decoder_input_data], decoder_target_data,\n",
    "          batch_size=batch_size,\n",
    "          epochs=1,\n",
    "          validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "59esvSpoqGWE"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1547
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 367035,
     "status": "ok",
     "timestamp": 1535675106873,
     "user": {
      "displayName": "Kok Meng Tan",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "113459036002015692798"
     },
     "user_tz": -480
    },
    "id": "c47Ygb_O2d-2",
    "outputId": "d0101276-8038-4cd6-95d2-c9a33be5a486"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, None, 71)          0         \n",
      "_________________________________________________________________\n",
      "gru_1 (GRU)                  [(None, 256), (None, 256) 251904    \n",
      "=================================================================\n",
      "Total params: 251,904\n",
      "Trainable params: 251,904\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, None, 71)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            (None, None, 94)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "gru_1 (GRU)                     [(None, 256), (None, 251904      input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "gru_2 (GRU)                     [(None, None, 256),  269568      input_2[0][0]                    \n",
      "                                                                 gru_1[0][1]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, None, 94)     24158       gru_2[0][0]                      \n",
      "==================================================================================================\n",
      "Total params: 545,630\n",
      "Trainable params: 545,630\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            (None, None, 94)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_3 (InputLayer)            (None, 256)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "gru_2 (GRU)                     [(None, None, 256),  269568      input_2[0][0]                    \n",
      "                                                                 input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, None, 94)     24158       gru_2[1][0]                      \n",
      "==================================================================================================\n",
      "Total params: 293,726\n",
      "Trainable params: 293,726\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/20\n",
      "8000/8000 [==============================] - 19s 2ms/step - loss: 0.8652 - val_loss: 0.8478\n",
      "Epoch 2/20\n",
      "8000/8000 [==============================] - 18s 2ms/step - loss: 0.6477 - val_loss: 0.7174\n",
      "Epoch 3/20\n",
      "8000/8000 [==============================] - 18s 2ms/step - loss: 0.5719 - val_loss: 0.6581\n",
      "Epoch 4/20\n",
      "8000/8000 [==============================] - 18s 2ms/step - loss: 0.5277 - val_loss: 0.6214\n",
      "Epoch 5/20\n",
      "8000/8000 [==============================] - 18s 2ms/step - loss: 0.4952 - val_loss: 0.5883\n",
      "Epoch 6/20\n",
      "8000/8000 [==============================] - 18s 2ms/step - loss: 0.4663 - val_loss: 0.5702\n",
      "Epoch 7/20\n",
      "8000/8000 [==============================] - 18s 2ms/step - loss: 0.4426 - val_loss: 0.5516\n",
      "Epoch 8/20\n",
      "8000/8000 [==============================] - 18s 2ms/step - loss: 0.4227 - val_loss: 0.5343\n",
      "Epoch 9/20\n",
      "8000/8000 [==============================] - 18s 2ms/step - loss: 0.4052 - val_loss: 0.5174\n",
      "Epoch 10/20\n",
      "8000/8000 [==============================] - 18s 2ms/step - loss: 0.3898 - val_loss: 0.5074\n",
      "Epoch 11/20\n",
      "8000/8000 [==============================] - 18s 2ms/step - loss: 0.3757 - val_loss: 0.5013\n",
      "Epoch 12/20\n",
      "8000/8000 [==============================] - 18s 2ms/step - loss: 0.3626 - val_loss: 0.4971\n",
      "Epoch 13/20\n",
      "8000/8000 [==============================] - 18s 2ms/step - loss: 0.3511 - val_loss: 0.4803\n",
      "Epoch 14/20\n",
      "8000/8000 [==============================] - 18s 2ms/step - loss: 0.3396 - val_loss: 0.4787\n",
      "Epoch 15/20\n",
      "8000/8000 [==============================] - 18s 2ms/step - loss: 0.3300 - val_loss: 0.4730\n",
      "Epoch 16/20\n",
      "8000/8000 [==============================] - 18s 2ms/step - loss: 0.3202 - val_loss: 0.4701\n",
      "Epoch 17/20\n",
      "8000/8000 [==============================] - 18s 2ms/step - loss: 0.3108 - val_loss: 0.4672\n",
      "Epoch 18/20\n",
      "8000/8000 [==============================] - 18s 2ms/step - loss: 0.3014 - val_loss: 0.4648\n",
      "Epoch 19/20\n",
      "8000/8000 [==============================] - 18s 2ms/step - loss: 0.2926 - val_loss: 0.4643\n",
      "Epoch 20/20\n",
      "8000/8000 [==============================] - 18s 2ms/step - loss: 0.2841 - val_loss: 0.4636\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f8197c73be0>"
      ]
     },
     "execution_count": 18,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model, encoder_model, decoder_model = seq2seq_gru(num_encoder_tokens, num_decoder_tokens)\n",
    "\n",
    "# Run training\n",
    "model.compile(optimizer='rmsprop', loss='categorical_crossentropy')\n",
    "model.fit([encoder_input_data, decoder_input_data], decoder_target_data,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Sm2fHgljfovF"
   },
   "outputs": [],
   "source": [
    "def decode_sequence(input_seq, encoder_model, decoder_model, m='gru'):\n",
    "    # Encode the input as state vectors.\n",
    "    states_value = encoder_model.predict(input_seq)\n",
    "    if m == 'gru':\n",
    "        states_value = [states_value]\n",
    "\n",
    "    # Generate empty target sequence of length 1.\n",
    "    target_seq = np.zeros((1, 1, num_decoder_tokens))\n",
    "    # Populate the first character of target sequence with the start character.\n",
    "    target_seq[0, 0, target_token_index['\\t']] = 1.\n",
    "\n",
    "    # Sampling loop for a batch of sequences\n",
    "    # (to simplify, here we assume a batch of size 1).\n",
    "    stop_condition = False\n",
    "    decoded_sentence = ''\n",
    "    while not stop_condition:\n",
    "        x = decoder_model.predict([target_seq] + states_value)\n",
    "        output_tokens = x[0]\n",
    "\n",
    "        # Sample a token\n",
    "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
    "        sampled_char = reverse_target_char_index[sampled_token_index]\n",
    "        decoded_sentence += sampled_char\n",
    "\n",
    "        # Exit condition: either hit max length\n",
    "        # or find stop character.\n",
    "        if (sampled_char == '\\n' or len(decoded_sentence) > max_decoder_seq_length):\n",
    "            stop_condition = True\n",
    "\n",
    "        # Update the target sequence (of length 1).\n",
    "        target_seq = np.zeros((1, 1, num_decoder_tokens))\n",
    "        target_seq[0, 0, sampled_token_index] = 1.\n",
    "\n",
    "        # Update states\n",
    "        states_value = x[1:]\n",
    "\n",
    "    return decoded_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 697
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2607,
     "status": "ok",
     "timestamp": 1535621159696,
     "user": {
      "displayName": "Kok Meng Tan",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "113459036002015692798"
     },
     "user_tz": -480
    },
    "id": "ZlsKVbhSfe6x",
    "outputId": "a55bd92d-10cf-4c8d-be6d-6c1ea5f85830"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-\n",
      "Input sentence: Go.\n",
      "Decoded sentence: Tous pais pais !\n",
      "\n",
      "-\n",
      "Input sentence: Run!\n",
      "Decoded sentence: Tous pais pais !\n",
      "\n",
      "-\n",
      "Input sentence: Run!\n",
      "Decoded sentence: Tous pais pais !\n",
      "\n",
      "-\n",
      "Input sentence: Fire!\n",
      "Decoded sentence: Tous pais pais !\n",
      "\n",
      "-\n",
      "Input sentence: Help!\n",
      "Decoded sentence: Tous me sois !\n",
      "\n",
      "-\n",
      "Input sentence: Jump.\n",
      "Decoded sentence: Tous me sois !\n",
      "\n",
      "-\n",
      "Input sentence: Stop!\n",
      "Decoded sentence: Tous pais !\n",
      "\n",
      "-\n",
      "Input sentence: Stop!\n",
      "Decoded sentence: Tous pais !\n",
      "\n",
      "-\n",
      "Input sentence: Stop!\n",
      "Decoded sentence: Tous pais !\n",
      "\n",
      "-\n",
      "Input sentence: Wait!\n",
      "Decoded sentence: Tous pais !\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for seq_index in range(10):\n",
    "    # Take one sequence (part of the training set)\n",
    "    # for trying out decoding.\n",
    "    input_seq = encoder_input_data[seq_index: seq_index + 1]\n",
    "    decoded_sentence = decode_sequence(input_seq, encoder_model, decoder_model, m='gru')\n",
    "    print('-')\n",
    "    print('Input sentence:', input_texts[seq_index])\n",
    "    print('Decoded sentence:', decoded_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kSteAloyUK_D"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "keras_seq2seq_translation.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
